{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Lab Documentation and Solutions](https://img.shields.io/badge/Lab%20Documentation%20and%20Solutions-purple)](https://mongodb-developer.github.io/ai-agents-lab/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RM8rg08YhqZe"
   },
   "source": [
    "# Step 1: Setup prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pymongo import MongoClient\n",
    "from langchain.tools import tool\n",
    "import voyageai\n",
    "from typing import List\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict\n",
    "# Add parent directory to path to import from utils\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd())))\n",
    "from utils import track_progress, set_env\n",
    "from utils import create_index, check_index_ready\n",
    "from langchain_core.load import load\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from utils import get_llm\n",
    "from langchain_core.messages import ToolMessage\n",
    "from typing import Dict\n",
    "from pprint import pprint\n",
    "from langgraph.graph import StateGraph, START\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import END\n",
    "\n",
    "# If you are using your own MongoDB Atlas cluster, use the connection string for your cluster here\n",
    "MONGODB_URI = os.environ.get(\"MONGODB_URI\")\n",
    "# Initialize a MongoDB Python client\n",
    "mongodb_client = MongoClient(MONGODB_URI)\n",
    "# Check the connection to the server\n",
    "mongodb_client.admin.command(\"ping\")\n",
    "# Track progress of key steps-- DO NOT CHANGE\n",
    "track_progress(\"cluster_creation\", \"ai_agents_mem_lab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the LLM provider and passkey provided by your workshop instructor\n",
    "# NOTE: LLM_PROVIDER can be set to one of \"aws\"/ \"microsoft\" / \"google\"\n",
    "LLM_PROVIDER = \"aws\"\n",
    "PASSKEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain API keys from our AI model proxy and set them as environment variables-- DO NOT CHANGE\n",
    "set_env([LLM_PROVIDER,\"voyageai\"], PASSKEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Do not change the values assigned to the variables below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#  Database name\n",
    "DB_NAME = \"mongodb_genai_devday_agents\"\n",
    "# Name of the collection with full documents- used for summarization\n",
    "FULL_COLLECTION_NAME = \"mongodb_docs\"\n",
    "# Name of the collection for vector search- used for Q&A\n",
    "VS_COLLECTION_NAME = \"mongodb_docs_embeddings\"\n",
    "# Name of the vector search index\n",
    "VS_INDEX_NAME = \"vector_index\"\n",
    "# Connect to the `VS_COLLECTION_NAME` collection.\n",
    "vs_collection = mongodb_client[DB_NAME][VS_COLLECTION_NAME]\n",
    "# Connect to the `FULL_COLLECTION_NAME` collection.\n",
    "full_collection = mongodb_client[DB_NAME][FULL_COLLECTION_NAME]\n",
    "# Insert a dataset of MongoDB docs with embeddings into the `VS_COLLECTION_NAME` collection\n",
    "with open(f\"../data/{VS_COLLECTION_NAME}.json\", \"r\") as data_file:\n",
    "    json_data = data_file.read()\n",
    "\n",
    "data = json.loads(json_data)\n",
    "\n",
    "print(f\"Deleting existing documents from the {VS_COLLECTION_NAME} collection.\")\n",
    "vs_collection.delete_many({})\n",
    "vs_collection.insert_many(data)\n",
    "print(\n",
    "    f\"{vs_collection.count_documents({})} documents ingested into the {VS_COLLECTION_NAME} collection.\"\n",
    ")\n",
    "# Insert a dataset of MongoDB documentation pages into the `FULL_COLLECTION_NAME` collection\n",
    "with open(f\"../data/{FULL_COLLECTION_NAME}.json\", \"r\") as data_file:\n",
    "    json_data = data_file.read()\n",
    "\n",
    "data = json.loads(json_data)\n",
    "\n",
    "print(f\"Deleting existing documents from the {FULL_COLLECTION_NAME} collection.\")\n",
    "full_collection.delete_many({})\n",
    "full_collection.insert_many(data)\n",
    "print(\n",
    "    f\"{full_collection.count_documents({})} documents ingested into the {FULL_COLLECTION_NAME} collection.\"\n",
    ")\n",
    "# Create vector index definition specifying:\n",
    "# path: Path to the embeddings field\n",
    "# numDimensions: Number of embedding dimensions- depends on the embedding model used\n",
    "# similarity: Similarity metric. One of cosine, euclidean, dotProduct.\n",
    "model = {\n",
    "    \"name\": VS_INDEX_NAME,\n",
    "    \"type\": \"vectorSearch\",\n",
    "    \"definition\": {\n",
    "        \"fields\": [\n",
    "            {\n",
    "                \"type\": \"vector\",\n",
    "                \"path\": \"embedding\",\n",
    "                \"numDimensions\": 1024,\n",
    "                \"similarity\": \"cosine\",\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "}\n",
    "create_index(vs_collection, VS_INDEX_NAME, model)\n",
    "# Use the `check_index_ready` function from the `utils` module to verify that the index was created and is in READY status before proceeding\n",
    "check_index_ready(vs_collection, VS_INDEX_NAME)\n",
    "# Track progress of key steps-- DO NOT CHANGE\n",
    "track_progress(\"vs_index_creation\", \"ai_agents_lab\")\n",
    "# Initialize the Voyage AI client\n",
    "vo = voyageai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Functions and retrieval tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(query: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Get embeddings for an input query.\n",
    "\n",
    "    Args:\n",
    "        query (str): Query string\n",
    "\n",
    "    Returns:\n",
    "        List[float]: Embedding of the query string\n",
    "    \"\"\"\n",
    "    # Use the `contextualized_embed` method of the Voyage AI API to embed the user query with the following arguments:\n",
    "    # inputs: `query` wrapped in a list of lists\n",
    "    # model: `voyage-context-3`\n",
    "    # input_type: \"query\"\n",
    "    embds_obj = vo.contextualized_embed(inputs=[[query]], model=\"voyage-context-3\", input_type=\"query\")\n",
    "    # Extract embeddings from the embeddings object\n",
    "    embeddings = embds_obj.results[0].embeddings[0]\n",
    "    return embeddings\n",
    "# Define a tool to retrieve relevant documents for a user query using vector search\n",
    "@tool\n",
    "def get_information_for_question_answering(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve information using vector search to answer a user query.\n",
    "\n",
    "    Args:\n",
    "    user_query (str): The user's query string.\n",
    "\n",
    "    Returns:\n",
    "    str: The retrieved information formatted as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate embeddings for the `user_query` using the `get_embeddings` function defined above\n",
    "    query_embedding = get_embeddings(user_query)\n",
    "\n",
    "    # Define an aggregation pipeline consisting of a $vectorSearch stage, followed by a $project stage\n",
    "    # Set the number of candidates to 150 and only return the top 5 documents from the vector search\n",
    "    # In the $project stage, exclude the `_id` field and include only the `body` field and `vectorSearchScore`\n",
    "    # NOTE: Use variables defined previously for the `index`, `queryVector` and `path` fields in the $vectorSearch stage\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$vectorSearch\": {\n",
    "                \"index\": VS_INDEX_NAME,\n",
    "                \"path\": \"embedding\",\n",
    "                \"queryVector\": query_embedding,\n",
    "                \"numCandidates\": 150,\n",
    "                \"limit\": 5,\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"_id\": 0,\n",
    "                \"body\": 1,\n",
    "                \"score\": {\"$meta\": \"vectorSearchScore\"},\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Execute the aggregation `pipeline` against the `vs_collection` collection and store the results in `results`\n",
    "    results = vs_collection.aggregate(pipeline)\n",
    "    # Concatenate the results into a string\n",
    "    context = \"\\n\\n\".join([doc.get(\"body\") for doc in results])\n",
    "    return context\n",
    "# Define a tool to retrieve the content of a documentation page for summarization\n",
    "@tool\n",
    "def get_page_content_for_summarization(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve page content based on provided title.\n",
    "\n",
    "    Args:\n",
    "    user_query (str): The user's query string i.e. title of the documentation page.\n",
    "\n",
    "    Returns:\n",
    "    str: The content of the page.\n",
    "    \"\"\"\n",
    "    # Query the documents where the `title` field is equal to the `user_query`\n",
    "    query = {\"title\": user_query}\n",
    "    # Only return the `body` field from the retrieved documents.\n",
    "    # NOTE: Set fields to include to 1, those to exclude to 0. `_id` is included by default, so exclude that.\n",
    "    projection = {\"_id\": 0, \"body\": 1}\n",
    "    # Use the `query` and `projection` with the `find_one` method\n",
    "    # to get the `body` of the document with `title` equal to the `user_query` from the `full_collection` collection\n",
    "    document = full_collection.find_one(query, projection)\n",
    "    if document:\n",
    "        return document[\"body\"]\n",
    "    else:\n",
    "        return \"Document not found\"\n",
    "# Create the list of tools\n",
    "tools = [\n",
    "    get_information_for_question_answering,\n",
    "    get_page_content_for_summarization,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Graph State and Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the graph state\n",
    "# We are only tracking chat messages but you can track other attributes as well\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "# Obtain the Langchain LLM object using the `get_llm` function from the `utils`` module.\n",
    "llm = get_llm(LLM_PROVIDER)\n",
    "# Create a Chain-of-Thought (CoT) prompt template for the agent.\n",
    "# This includes a system prompt with a placeholder for tool names, and a placeholder for messages i.e. user queries and assistant responses\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"You are a helpful AI assistant.\"\n",
    "            \" You are provided with tools to answer questions and summarize technical documentation related to MongoDB.\"\n",
    "            \" Think step-by-step and use these tools to get the information required to answer the user query.\"\n",
    "            \" Do not re-run tools unless absolutely necessary.\"\n",
    "            \" If you are not able to get enough information using the tools, reply with I DON'T KNOW.\"\n",
    "            \" You have access to the following tools: {tool_names}.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "# Fill in the prompt template with the tool names\n",
    "prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "# Bind the `tools` to the `llm` instantiated above\n",
    "bind_tools = llm.bind_tools(tools)\n",
    "# Chain the `prompt` with the tool-augmented llm using the `|` operator\n",
    "llm_with_tools = prompt | bind_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Define graph nodes and compile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the agent node\n",
    "def agent(state: GraphState) -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Agent node\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Graph state\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List]: Updates to messages\n",
    "    \"\"\"\n",
    "    # Get the messages from the graph `state`\n",
    "    messages = state[\"messages\"]\n",
    "    # Invoke `llm_with_tools` with `messages` using the `invoke` method\n",
    "    # HINT: See Step 6 for how to invoke `llm_with_tools`\n",
    "    result = llm_with_tools.invoke(messages)\n",
    "    # Write `result` to the `messages` attribute of the graph state\n",
    "    return {\"messages\": [result]}\n",
    "# Create a map of tool name to tool call\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "# Define tool node\n",
    "def tool_node(state: GraphState) -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Tool node\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Graph state\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List]: Updates to messages\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    # Get the list of tool calls from messages\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    # A tool_call looks as follows:\n",
    "    # {\n",
    "    #     \"name\": \"get_information_for_question_answering\",\n",
    "    #     \"args\": {\"user_query\": \"What are Atlas Triggers\"},\n",
    "    #     \"id\": \"call_H5TttXb423JfoulF1qVfPN3m\",\n",
    "    #     \"type\": \"tool_call\",\n",
    "    # }\n",
    "    # Iterate through `tool_calls`\n",
    "    for tool_call in tool_calls:\n",
    "        # Get the tool from `tools_by_name` using the `name` attribute of the `tool_call`\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        # Invoke the `tool` using the `args` attribute of the `tool_call`\n",
    "        # HINT: See previous line to see how to extract attributes from `tool_call`\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        # Append the result of executing the tool to the `result` list as a ToolMessage\n",
    "        # The `content` of the message is `observation` i.e. result of the tool call\n",
    "        # The `tool_call_id` can be obtained from the `tool_call`\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    # Write `result` to the `messages` attribute of the graph state\n",
    "    return {\"messages\": result}\n",
    "# Define conditional routing function\n",
    "def route_tools(state: GraphState):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the tool node if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    # Get messages from graph state\n",
    "    messages = state.get(\"messages\", [])\n",
    "    if len(messages) > 0:\n",
    "        # Get the last AI message from messages\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    # Check if the last message has tool calls\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        # If yes, return \"tools\"\n",
    "        return \"tools\"\n",
    "    # If no, return END\n",
    "    return END\n",
    "# Instantiate the graph\n",
    "graph = StateGraph(GraphState)\n",
    "# Add nodes to the `graph` using the `add_node` function\n",
    "# Add a `agent` node. The `agent` node should run the `agent` function\n",
    "graph.add_node(\"agent\", agent)\n",
    "# Add a `tools` node. The `tools` node should run the `tool_node` function\n",
    "graph.add_node(\"tools\", tool_node)\n",
    "# Add fixed edges to the `graph` using the `add_edge` method\n",
    "# Add an edge from the START node to the `agent` node\n",
    "graph.add_edge(START, \"agent\")\n",
    "# Add an edge from the `tools` node to the `agent` node\n",
    "graph.add_edge(\"tools\", \"agent\")\n",
    "# Use the `add_conditional_edges` method to add a conditional edge from the `agent` node to the `tools` node\n",
    "# based on the output of the `route_tools` function\n",
    "graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    route_tools,\n",
    "    {\"tools\": \"tools\", END: END},\n",
    ")\n",
    "# Compile the `graph`\n",
    "app = graph.compile()\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_graph(user_input: str) -> None:\n",
    "    \"\"\"\n",
    "    Stream outputs from the graph\n",
    "\n",
    "    Args:\n",
    "        user_input (str): User query string\n",
    "    \"\"\"\n",
    "    # Stream outputs from each step in the graph\n",
    "    for step in app.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        # Stream full value of the state after each step\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        # Print the latest message from the step\n",
    "        step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Step 5: Execute the graph with no memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the graph execution to view end-to-end flow\n",
    "execute_graph(\"What are some best practices for data backups in MongoDB?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_graph(\"What did I just ask you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Add Session memory to the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.mongodb import MongoDBSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a MongoDB checkpointer\n",
    "checkpointer = MongoDBSaver(mongodb_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the graph with the checkpointer\n",
    "app = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìö https://langchain-ai.github.io/langgraph/concepts/persistence/#threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_graph_with_memory(thread_id: str, user_input: str) -> None:\n",
    "    \"\"\"\n",
    "    Stream outputs from the graph\n",
    "\n",
    "    Args:\n",
    "        thread_id (str): Thread ID for the checkpointer\n",
    "        user_input (str): User query string\n",
    "    \"\"\"\n",
    "    # Create a runtime config for the thread ID `thread_id`\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    # Stream outputs from each step in the graph\n",
    "    for step in app.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        # Pass the config as an additional parameter\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        # Print the latest message from the step\n",
    "        step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test graph execution with thread ID\n",
    "execute_graph_with_memory(\n",
    "    \"1\",\n",
    "    \"What are some best practices for data backups in MongoDB?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow-up question to ensure message history works\n",
    "execute_graph_with_memory(\n",
    "    \"1\",\n",
    "    \"What did I just ask you?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_graph_with_memory(\n",
    "    2,\n",
    "    \"Hi! I'm a senior DBA with beginner experience with MongoDB but deep experience with RDBMS. Can you tell me about backup and restore?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Will this tailor the response for the role?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_graph_with_memory(\n",
    "    3,\n",
    "    \"Can you tell me about MongoDB operations?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Implementation: Hot Path (Memory Tools)\n",
    "\n",
    "This implementation uses **Memory Tools** (`create_manage_memory_tool` and `create_search_memory_tool`) \n",
    "which allow the agent to **consciously** manage its own long-term memory.\n",
    "\n",
    "## How it works:\n",
    "1. The agent has access to `manage_memory` tool to save important user information\n",
    "2. The agent has access to `search_memory` tool to retrieve relevant memories\n",
    "3. Memories persist in MongoDB and survive across conversation threads\n",
    "\n",
    "## References:\n",
    "- [LangMem Hot Path Quickstart](https://langchain-ai.github.io/langmem/hot_path_quickstart/)\n",
    "- [LangMem Memory Tools Reference](https://langchain-ai.github.io/langmem/reference/tools/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: langmem inports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS FOR LONG-TERM MEMORY (HOT PATH)\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "from langmem import create_search_memory_tool\n",
    "from langgraph.store.mongodb import MongoDBStore, create_vector_index_config\n",
    "from langchain_voyageai import VoyageAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the memories collection\n",
    "mongodb_client[\"mongodb_genai_devday_agents\"][\"memories\"].drop()\n",
    "print(\"Collection dropped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monkey Patch for [Issue 138](https://github.com/langchain-ai/langmem/issues/138) in langmem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MONKEY-PATCH: HOT PATH TO INCLUDE \"kind\" FIELD\n",
    "# Add this AFTER imports, BEFORE creating memory tools\n",
    "# =============================================================================\n",
    "\n",
    "from langmem.knowledge.tools import _get_store, _ensure_json_serializable\n",
    "from langmem import utils\n",
    "from langchain_core.tools import StructuredTool\n",
    "import typing\n",
    "import uuid\n",
    "\n",
    "def create_manage_memory_tool(\n",
    "    namespace: tuple[str, ...] | str,\n",
    "    *,\n",
    "    instructions: str = \"Proactively call this tool when you:\\n\\n\"\n",
    "    \"1. Identify a new USER preference.\\n\"\n",
    "    \"2. Receive an explicit USER request to remember something or otherwise alter your behavior.\\n\"\n",
    "    \"3. Are working and want to record important context.\\n\"\n",
    "    \"4. Identify that an existing MEMORY is incorrect or outdated.\\n\",\n",
    "    schema: typing.Type = str,\n",
    "    actions_permitted: tuple = (\"create\", \"update\", \"delete\"),\n",
    "    store = None,\n",
    "    name: str = \"manage_memory\",\n",
    "):\n",
    "    \"\"\"Drop-in replacement for langmem.create_manage_memory_tool with cold path compatibility.\"\"\"\n",
    "    \n",
    "    namespacer = utils.NamespaceTemplate(namespace)\n",
    "    action_type = typing.Literal[actions_permitted]\n",
    "    default_action = \"create\" if \"create\" in actions_permitted else actions_permitted[0]\n",
    "    initial_store = store\n",
    "    \n",
    "    # Get schema name for \"kind\" field\n",
    "    schema_name = schema.__name__ if hasattr(schema, \"__name__\") else \"Memory\"\n",
    "\n",
    "    async def amanage_memory(\n",
    "        content: typing.Optional[schema] = None,\n",
    "        action: action_type = default_action,\n",
    "        *,\n",
    "        id: typing.Optional[uuid.UUID] = None,\n",
    "    ):\n",
    "        store = _get_store(initial_store)\n",
    "        if action not in actions_permitted:\n",
    "            raise ValueError(f\"Invalid action {action}. Must be one of {actions_permitted}.\")\n",
    "        if action == \"create\" and id is not None:\n",
    "            raise ValueError(\"Cannot provide ID when creating a memory.\")\n",
    "        if action in (\"delete\", \"update\") and not id:\n",
    "            raise ValueError(\"Must provide ID when deleting or updating.\")\n",
    "        \n",
    "        ns = namespacer()\n",
    "        if action == \"delete\":\n",
    "            await store.adelete(ns, key=str(id))\n",
    "            return f\"Deleted memory {id}\"\n",
    "\n",
    "        id = id or uuid.uuid4()\n",
    "        # PATCHED: Include \"kind\" for cold path compatibility\n",
    "        await store.aput(\n",
    "            ns,\n",
    "            key=str(id),\n",
    "            value={\n",
    "                \"kind\": schema_name,\n",
    "                \"content\": _ensure_json_serializable(content)\n",
    "            },\n",
    "        )\n",
    "        return f\"{action}d memory {id}\"\n",
    "\n",
    "    def manage_memory(\n",
    "        content: typing.Optional[schema] = None,\n",
    "        action: action_type = default_action,\n",
    "        *,\n",
    "        id: typing.Optional[uuid.UUID] = None,\n",
    "    ):\n",
    "        store = _get_store(initial_store)\n",
    "        if action not in actions_permitted:\n",
    "            raise ValueError(f\"Invalid action {action}. Must be one of {actions_permitted}.\")\n",
    "        if action == \"create\" and id is not None:\n",
    "            raise ValueError(\"Cannot provide ID when creating a memory.\")\n",
    "        if action in (\"delete\", \"update\") and not id:\n",
    "            raise ValueError(\"Must provide ID when deleting or updating.\")\n",
    "        \n",
    "        ns = namespacer()\n",
    "        if action == \"delete\":\n",
    "            store.delete(ns, key=str(id))\n",
    "            return f\"Deleted memory {id}\"\n",
    "\n",
    "        id = id or uuid.uuid4()\n",
    "        # PATCHED: Include \"kind\" for cold path compatibility\n",
    "        store.put(\n",
    "            ns,\n",
    "            key=str(id),\n",
    "            value={\n",
    "                \"kind\": schema_name,\n",
    "                \"content\": _ensure_json_serializable(content)\n",
    "            },\n",
    "        )\n",
    "        return f\"{action}d memory {id}\"\n",
    "\n",
    "    description = f\"\"\"Create, update, or delete a memory.\n",
    "Include the MEMORY ID when updating or deleting. Omit when creating.\n",
    "{instructions}\"\"\"\n",
    "\n",
    "    return StructuredTool.from_function(\n",
    "        manage_memory, amanage_memory, name=name, description=description\n",
    "    )\n",
    "\n",
    "print(\"Hot path patched to include 'kind' field\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Setup MongoDB Store for long term memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SETUP MONGODB STORE FOR LONG-TERM MEMORY\n",
    "# =============================================================================\n",
    "\n",
    "MEMORY_DB_NAME = \"mongodb_genai_devday_agents\"\n",
    "MEMORY_COLLECTION_NAME = \"memories\"\n",
    "\n",
    "# Get collection reference for direct queries\n",
    "memory_collection = mongodb_client[MEMORY_DB_NAME][MEMORY_COLLECTION_NAME]\n",
    "\n",
    "# Create vector index configuration for semantic search\n",
    "memory_index_config = create_vector_index_config(\n",
    "    dims=1024,\n",
    "    embed=VoyageAIEmbeddings(model=\"voyage-3\"),\n",
    "    fields=[\"content\"],\n",
    "    name=\"memory_vector_index\"\n",
    ")\n",
    "\n",
    "# Initialize MongoDBStore with collection object (NOT from_conn_string)\n",
    "# IMPORTANT: from_conn_string() returns a context manager, not a store object\n",
    "memory_store = MongoDBStore(\n",
    "    collection=memory_collection,\n",
    "    index_config=memory_index_config\n",
    ")\n",
    "\n",
    "print(f\"MongoDBStore initialized for {MEMORY_DB_NAME}.{MEMORY_COLLECTION_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Create hot path tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool for saving/updating/deleting memories\n",
    "\n",
    "manage_memory_tool = create_manage_memory_tool(\n",
    "    namespace=(\"memories\", \"{langgraph_user_id}\"), \n",
    "     store=memory_store, # User-scoped memories\n",
    "     actions_permitted=(\"create\",), \n",
    "   \n",
    ")\n",
    "\n",
    "# Tool for searching memories\n",
    "search_memory_tool = create_search_memory_tool(\n",
    "   namespace=(\"memories\", \"{langgraph_user_id}\"),\n",
    "   store= memory_store\n",
    ")\n",
    "\n",
    "print(\" Memory tools created:\")\n",
    "print(f\"   - {manage_memory_tool.name}: Save/update/delete memories\")\n",
    "print(f\"   - {search_memory_tool.name}: Search existing memories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMBINE ORIGINAL TOOLS WITH MEMORY TOOLS\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "#To avoid adding duplicates when re-executing the cell\n",
    "tools = tools + [t for t in [manage_memory_tool, search_memory_tool] if t.name not in [x.name for x in tools]]\n",
    "\n",
    "\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "print(f\"‚úÖ Total tools available: {len(tools)}\")\n",
    "for tool in tools:\n",
    "    print(f\"   - {tool.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Create LLM prompt with memory tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE MEMORY-AWARE PROMPT\n",
    "# This prompt instructs the agent to use memory tools\n",
    "# =============================================================================\n",
    "\n",
    "memory_aware_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "       (\n",
    "    \"system\",\n",
    "    \"\"\"You are a helpful AI assistant with persistent memory capabilities.\n",
    "You can answer questions about MongoDB documentation using your tools.\n",
    "\n",
    "## MANDATORY FIRST ACTION:\n",
    "Before responding to ANY user message, you MUST call search_memory first.\n",
    "Do not skip this step. Do not assume you know the user.\n",
    "\n",
    "## CRITICAL RULES:\n",
    "- You have ZERO memory of users unless search_memory returns it\n",
    "- NEVER say \"I remember\" or \"You told me\" without calling search_memory first\n",
    "- If search_memory returns empty, respond with \"I don't have any information about you yet\"\n",
    "\n",
    "## MEMORY INSTRUCTIONS:\n",
    "1. FIRST: Always call search_memory with a relevant query\n",
    "2. THEN: If user shares personal info, use manage_memory to save it\n",
    "3. Acknowledge when you save something to memory\n",
    "\n",
    "## PERSONALIZATION:\n",
    "Based on search_memory results:\n",
    "- Match technical depth to user's expertise level\n",
    "- Focus on topics relevant to their role\n",
    "- Reference their interests naturally\n",
    "\n",
    "## TOOL USAGE:\n",
    "- Do NOT call the same tool more than 2 times\n",
    "- Use documentation tools for technical questions\n",
    "\n",
    "Available tools: {tool_names}\n",
    "\n",
    "REMEMBER: Your FIRST tool call must ALWAYS be search_memory.\"\"\"\n",
    "),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fill in tool names\n",
    "memory_aware_prompt = memory_aware_prompt.partial(\n",
    "    #tool_names=\", \".join([tool.name for tool in tools_with_memory])\n",
    "    tool_names=\", \".join([tool.name for tool in tools])\n",
    ")\n",
    "\n",
    "print(\" Memory-aware prompt created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE MEMORY-AWARE LLM CHAIN\n",
    "# =============================================================================\n",
    "\n",
    "llm_with_tools = memory_aware_prompt | llm.bind_tools(tools)\n",
    "\n",
    "print(\"‚úÖ LLM chain with memory tools created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Recompile the graph with memory_store\n",
    "app_with_memory = graph.compile(\n",
    "    checkpointer=checkpointer,  # Short-term memory (conversation history)\n",
    "    store=memory_store          # Long-term memory (persistent memories)\n",
    ")\n",
    "\n",
    "print(\"Memory-aware graph compiled with:\")\n",
    "print(\"   - Checkpointer: Short-term memory (conversation threads)\")\n",
    "print(\"   - Store: Long-term memory (persistent user memories)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE THE MEMORY-AWARE GRAPH\n",
    "# =============================================================================\n",
    "\n",
    "app_with_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXECUTION FUNCTION WITH MEMORY\n",
    "# =============================================================================\n",
    "\n",
    "def run_agent_with_memory(thread_id: str, user_id: str, user_input: str):\n",
    "    \"\"\"\n",
    "    Execute the memory-aware agent.\n",
    "    \n",
    "    Args:\n",
    "        thread_id: Unique conversation thread ID (short-term memory)\n",
    "        user_id: User identifier for memory scoping (long-term memory)\n",
    "        user_input: User's message\n",
    "    \"\"\"\n",
    "    # Config with both thread_id and langgraph_user_id\n",
    "    # IMPORTANT: langgraph_user_id must match the namespace pattern {langgraph_user_id}\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id,\n",
    "            \"langgraph_user_id\": user_id,  # Required for memory namespace\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Thread: {thread_id} | User: {user_id}\")\n",
    "    print(f\"Input: {user_input}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Stream the response\n",
    "    for step in app_with_memory.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        msg = step[\"messages\"][-1]\n",
    "        if hasattr(msg, 'pretty_print'):\n",
    "            msg.pretty_print()\n",
    "        else:\n",
    "            print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the checkpointing collection to start fresh\n",
    "#mongodb_client[\"checkpointing_db\"][\"checkpoints\"].drop()\n",
    "#print(\"Checkpoints cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Save User Information to Memory\n",
    "\n",
    "In this test, the user introduces themselves. The agent should:\n",
    "1. Recognize this is personal information\n",
    "2. Use `manage_memory` tool to save it\n",
    "3. Acknowledge that it saved the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TEST 1: User introduces themselves - Agent should save to memory\n",
    "# =============================================================================\n",
    "\n",
    "run_agent_with_memory(\n",
    "    \"session-0001\",\n",
    "    \"user-00001\",\n",
    "    \"Hi! I'm a senior DBA focusing on disaster recovery and backup strategies.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VERIFY: Check if memory was saved to MongoDB\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "print(\"=== Checking MongoDB for saved memories ===\")\n",
    "print(f\"\\nCollection: {MEMORY_DB_NAME}.{MEMORY_COLLECTION_NAME}\")\n",
    "\n",
    "# Query memories for user-123\n",
    "user_memories = list(memory_collection.find({}))\n",
    "print(f\"\\nTotal documents in collection: {len(user_memories)}\")\n",
    "\n",
    "for doc in user_memories:\n",
    "    print(f\"\\n--- Memory Document ---\")\n",
    "    print(f\"Namespace: {doc.get('namespace', 'N/A')}\")\n",
    "    print(f\"Key: {doc.get('key', 'N/A')}\")\n",
    "    print(f\"Value: {doc.get('value', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: New Conversation Thread Recalls Memory\n",
    "\n",
    "In this test, we start a NEW conversation thread but with the SAME user.\n",
    "The agent should:\n",
    "1. Search for existing memories about this user\n",
    "2. Find the previously saved information\n",
    "3. Use that context to personalize the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TEST 2: New thread, same user - Agent should recall memory\n",
    "# =============================================================================\n",
    "\n",
    "run_agent_with_memory(\n",
    "    \"session-00002\",  # NEW thread\n",
    "    \"user-00001\",        # SAME user\n",
    "    \"What do you know about me?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Technical Question with User Context\n",
    "\n",
    "Ask a technical question. The agent should:\n",
    "1. Recall that the user is a DBA focused on disaster recovery\n",
    "2. Tailor the response to their expertise level\n",
    "3. Focus on backup/recovery aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TEST 3: Technical question - Agent should use memory context\n",
    "# =============================================================================\n",
    "\n",
    "run_agent_with_memory(\n",
    "    \"session-0023\",\n",
    "    \"user-0123\",\n",
    "    \"I am a Data Engineer interested in Scaling systems. Looking for the best practices for MongoDB Operations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: Different User (Memory Isolation)\n",
    "\n",
    "Test with a different user to verify memory isolation.\n",
    "This user should NOT see user-123's memories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TEST 4: Different user - Should NOT have user-123's memories\n",
    "# =============================================================================\n",
    "\n",
    "run_agent_with_memory(\n",
    "    thread_id=\"session-00044\",\n",
    "    user_id=\"user-456\",  # DIFFERENT user\n",
    "    user_input=\" I'm a Data Engineer. Tell me about  MongoDB Atlas scaling.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 5: Additional memory for the same user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_agent_with_memory(\n",
    "     thread_id=\"session-00045\",\n",
    "    user_id=\"user-456\",  # DIFFERENT user\n",
    "    user_input=\" I'm a DBA   interested in MongoDB Atlas functions.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Adding Cold path for summarization at the end of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmem import create_memory_store_manager\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLD_PATH_INSTRUCTIONS = \"\"\"You are a memory consolidation system. Your job is to MERGE and CLEAN UP memories.\n",
    "\n",
    "STRICT RULES:\n",
    "1. MAXIMUM 1 memory per user - never more\n",
    "2. You MUST DELETE all old memories after merging them\n",
    "3. Create ONE new consolidated memory with ALL information\n",
    "\n",
    "REQUIRED ACTIONS:\n",
    "1. READ all existing memories\n",
    "2. MERGE all information into ONE comprehensive memory  \n",
    "3. DELETE every old memory (use the delete/remove function)\n",
    "4. SAVE the single merged memory\n",
    "\n",
    "FORMAT for the single memory:\n",
    "\"User Profile: [role] at [company]. Works with [technologies]. Preferences: [preferences]. Interests: [interests].\"\n",
    "\n",
    "CRITICAL: If you see 3 existing memories, your output should be:\n",
    "- DELETE mem-001\n",
    "- DELETE mem-002  \n",
    "- DELETE mem-003\n",
    "- CREATE one consolidated memory\n",
    "\n",
    "DO NOT just add a new memory. You MUST delete the old ones.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_store_manager = create_memory_store_manager(\n",
    "    llm,\n",
    "    namespace=(\"memories\", \"{langgraph_user_id}\"),  \n",
    "    store=memory_store,                             \n",
    "    instructions=COLD_PATH_INSTRUCTIONS,\n",
    "    enable_inserts=True,\n",
    "    enable_deletes=True,\n",
    "    query_model=llm,\n",
    "    query_limit=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def queue_memory_consolidation(reason: str = \"conversation_ended\") -> str:\n",
    "    \"\"\"\n",
    "    Consolidate memories for the current user.\n",
    "    Call this tool when the user says goodbye.\n",
    "    \"\"\"\n",
    "    config = {\"configurable\": {\"langgraph_user_id\": _current_user_id}}\n",
    "    \n",
    "    try:\n",
    "        # Synchronous call - no executor needed\n",
    "        result = memory_store_manager.invoke(\n",
    "            {\n",
    "                \"messages\": _current_conversation_messages,\n",
    "                \"max_steps\": 3\n",
    "            },\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        print(f\"üìù Consolidation complete for user: {_current_user_id}\")\n",
    "        print(f\"   Memories created/updated: {len(result)}\")\n",
    "        for r in result:\n",
    "            print(f\"   - {r['value']}\")\n",
    "        \n",
    "        return f\"Memory consolidation complete. Updated {len(result)} memories.\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Consolidation failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return f\"Failed: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tools = tools + [t for t in [queue_memory_consolidation] if t.name not in [x.name for x in tools]]\n",
    "#tools = tools + [queue_memory_consolidation]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "print(f\" Tools updated. Total: {len(tools)}\")\n",
    "for t in tools:\n",
    "    print(f\"   - {t.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "memory_aware_prompt_with_goodbye = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "    \"system\",\n",
    "    \"\"\"You are a helpful AI assistant with persistent memory capabilities.\n",
    "You can answer questions about MongoDB documentation using your tools.\n",
    "\n",
    "## CRITICAL MEMORY RULES:\n",
    "- You have NO built-in memory of users\n",
    "- You ONLY know what search_memory returns\n",
    "- NEVER claim to remember something without calling search_memory first\n",
    "- If search_memory returns empty, say \"I don't have any information about you yet\"\n",
    "\n",
    "## MEMORY INSTRUCTIONS:\n",
    "1. When a user shares personal information (role, expertise, preferences, interests),\n",
    "   ALWAYS use manage_memory to save it immediately\n",
    "2. Acknowledge when you save something to memory\n",
    "3. Tailor your responses based on what search_memory returns:\n",
    "   - Match technical depth to user's expertise level\n",
    "   - Focus on topics relevant to their role\n",
    "   - Use their preferred communication style\n",
    "## GOODBYE INSTRUCTION:\n",
    "When the user says goodbye, ends the conversation, or uses phrases like:\n",
    "- \"bye\", \"goodbye\", \"see you\", \"thanks bye\", \"that's all\", \"gotta go\", \"talk later\"\n",
    "Call the queue_memory_consolidation tool to consolidate their memories, then say a friendly goodbye.\n",
    "\n",
    "## TOOL USAGE:\n",
    "- Do NOT call the same tool more than 2 times per question\n",
    "- Use documentation tools for technical questions\n",
    "\n",
    "Available tools: {tool_names}\"\"\"\n",
    "),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_aware_prompt_with_goodbye = memory_aware_prompt_with_goodbye.partial(\n",
    "    tool_names=\", \".join([tool.name for tool in tools])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = memory_aware_prompt_with_goodbye | llm.bind_tools(tools)\n",
    "\n",
    "# Recompile the graph\n",
    "app_with_memory = graph.compile(\n",
    "    checkpointer=checkpointer,\n",
    "    store=memory_store\n",
    ")\n",
    "\n",
    "print(\"Graph recompiled with LangMem cold path support\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent_with_memory_and_coldpath(\n",
    "    thread_id: str,\n",
    "    user_id: str,\n",
    "    user_input: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Run the agent with memory support and cold path tracking.\n",
    "    \n",
    "    This wrapper:\n",
    "    1. Tracks conversation messages for cold path consolidation\n",
    "    2. Passes user_id for proper namespace scoping\n",
    "    3. Streams and displays the response\n",
    "    \"\"\"\n",
    "    global _current_conversation_messages, _current_user_id\n",
    "    \n",
    "    # Set current user for consolidation tool\n",
    "    _current_user_id = user_id\n",
    "    \n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id,\n",
    "            \"langgraph_user_id\": user_id\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    input_message = HumanMessage(content=user_input)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\" Thread: {thread_id}\")\n",
    "    print(f\" User: {user_id}\")\n",
    "    print(f\" Input: {user_input}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Stream the response\n",
    "    final_response = None\n",
    "    for chunk in app_with_memory.stream(\n",
    "        {\"messages\": [input_message]},\n",
    "        config=config,\n",
    "        stream_mode=\"values\"\n",
    "    ):\n",
    "        if \"messages\" in chunk:\n",
    "            final_response = chunk[\"messages\"][-1]\n",
    "            # Track messages for cold path\n",
    "            _current_conversation_messages = chunk[\"messages\"]\n",
    "    \n",
    "    if final_response:\n",
    "        print(f\"\\n Assistant: {final_response.content}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\\n\")\n",
    "\n",
    "\n",
    "print(\"Agent wrapper updated with cold path tracking\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: TEST - Create some memories first\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 1: Creating some memories...\")\n",
    "\n",
    "run_agent_with_memory_and_coldpath(\n",
    "    \"session-coldpath-test_1\",\n",
    "    \"user-coldpath-dem\",\n",
    "    \"Hi! I'm a senior data engineer at a fintech startup. I work mostly with MongoDB and Kafka.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: TEST - Add more context\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 2: Adding more context...\")\n",
    "\n",
    "run_agent_with_memory_and_coldpath(\n",
    "    \"session-coldpath-test_1\",\n",
    "    \"user-coldpath-dem\",\n",
    "    \"I'm a DBA particularly interested in performance optimization and I prefer detailed technical explanations with code examples.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: VERIFY - Check memories before consolidation\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "time.sleep(5)  # Give executor time to process\n",
    "\n",
    "# Check what's in the memory store for this user\n",
    "print(\"\\n User memories before consolidation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "namespace = (\"memories\", \"user-coldpath-dem\")\n",
    "\n",
    "# Search for all memories\n",
    "try:\n",
    "    results = list(memory_store.search(namespace, query=\"user profile expertise\", limit=10))\n",
    "    \n",
    "    if results:\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"\\n--- Memory {i} ---\")\n",
    "            print(f\"Key: {result.key}\")\n",
    "            print(f\"Value: {result.value}\")\n",
    "            \n",
    "    else:\n",
    "        print(\"No memories found via search. Checking raw collection...\")\n",
    "        \n",
    "        # Fallback: check MongoDB directly\n",
    "        raw_memories = list(memory_collection.find({\"namespace\": list(namespace)}))\n",
    "        print(f\"Found {len(raw_memories)} memories in MongoDB:\")\n",
    "        for mem in raw_memories[:5]:\n",
    "            print(f\"  - {mem.get('key')}: {str(mem.get('value', {}))[:100]}...\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error searching memories: {e}\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 10: TEST - Say goodbye to trigger consolidation\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 3: Triggering cold path consolidation...\")\n",
    "\n",
    "run_agent_with_memory_and_coldpath(\n",
    "    thread_id=\"session-coldpath-test_1\",\n",
    "    user_id=\"user-coldpath-dem\",\n",
    "    user_input=\"Thanks for your help! Goodbye!\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: VERIFY - Check memories after consolidation\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "print(\"Waiting for background consolidation to complete...\")\n",
    "time.sleep(5)  # Give executor time to process\n",
    "\n",
    "# Check what's in the memory store for this user\n",
    "print(\"\\nüìã User memories after consolidation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "namespace = (\"memories\", \"user-coldpath-dem\")\n",
    "\n",
    "# Search for all memories\n",
    "try:\n",
    "    results = list(memory_store.search(namespace, query=\"user profile expertise\", limit=10))\n",
    "    \n",
    "    if results:\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"\\n--- Memory {i} ---\")\n",
    "            print(f\"Key: {result.key}\")\n",
    "            print(f\"Value: {result.value}\")\n",
    "         \n",
    "    else:\n",
    "        print(\"No memories found via search. Checking raw collection...\")\n",
    "        \n",
    "        # Fallback: check MongoDB directly\n",
    "        raw_memories = list(memory_collection.find({\"namespace\": list(namespace)}))\n",
    "        print(f\"Found {len(raw_memories)} memories in MongoDB:\")\n",
    "        for mem in raw_memories[:5]:\n",
    "            print(f\"  - {mem.get('key')}: {str(mem.get('value', {}))[:100]}...\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error searching memories: {e}\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {}
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
