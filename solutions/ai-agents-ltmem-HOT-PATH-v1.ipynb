{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Lab Documentation and Solutions](https://img.shields.io/badge/Lab%20Documentation%20and%20Solutions-purple)](https://mongodb-developer.github.io/ai-agents-lab/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RM8rg08YhqZe"
   },
   "source": [
    "# Step 1: Setup prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking progress for task cluster_creation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pymongo import MongoClient\n",
    "from langchain.tools import tool\n",
    "import voyageai\n",
    "from typing import List\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict\n",
    "# Add parent directory to path to import from utils\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd())))\n",
    "from utils import track_progress, set_env\n",
    "from utils import create_index, check_index_ready\n",
    "from langchain_core.load import load\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from utils import get_llm\n",
    "from langchain_core.messages import ToolMessage\n",
    "from typing import Dict\n",
    "from pprint import pprint\n",
    "from langgraph.graph import StateGraph, START\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import END\n",
    "\n",
    "# If you are using your own MongoDB Atlas cluster, use the connection string for your cluster here\n",
    "MONGODB_URI = os.environ.get(\"MONGODB_URI\")\n",
    "# Initialize a MongoDB Python client\n",
    "mongodb_client = MongoClient(MONGODB_URI)\n",
    "# Check the connection to the server\n",
    "mongodb_client.admin.command(\"ping\")\n",
    "# Track progress of key steps-- DO NOT CHANGE\n",
    "track_progress(\"cluster_creation\", \"ai_agents_mem_lab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the LLM provider and passkey provided by your workshop instructor\n",
    "# NOTE: LLM_PROVIDER can be set to one of \"aws\"/ \"microsoft\" / \"google\"\n",
    "LLM_PROVIDER = \"aws\"\n",
    "PASSKEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully set AWS_ACCESS_KEY_ID environment variable.\n",
      "Successfully set AWS_SECRET_ACCESS_KEY environment variable.\n",
      "Successfully set VOYAGE_API_KEY environment variable.\n"
     ]
    }
   ],
   "source": [
    "# Obtain API keys from our AI model proxy and set them as environment variables-- DO NOT CHANGE\n",
    "set_env([LLM_PROVIDER,\"voyageai\"], PASSKEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUf3jtFzO4-V"
   },
   "source": [
    "# Step 2: Import data into MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Do not change the values assigned to the variables below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting existing documents from the mongodb_docs_embeddings collection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 documents ingested into the mongodb_docs_embeddings collection.\n",
      "Deleting existing documents from the mongodb_docs collection.\n",
      "20 documents ingested into the mongodb_docs collection.\n",
      "Creating the vector_index index\n",
      "vector_index index status: READY\n",
      "vector_index index definition: {'fields': [{'type': 'vector', 'path': 'embedding', 'numDimensions': 1024, 'similarity': 'cosine'}]}\n",
      "Tracking progress for task vs_index_creation\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#  Database name\n",
    "DB_NAME = \"mongodb_genai_devday_agents\"\n",
    "# Name of the collection with full documents- used for summarization\n",
    "FULL_COLLECTION_NAME = \"mongodb_docs\"\n",
    "# Name of the collection for vector search- used for Q&A\n",
    "VS_COLLECTION_NAME = \"mongodb_docs_embeddings\"\n",
    "# Name of the vector search index\n",
    "VS_INDEX_NAME = \"vector_index\"\n",
    "# Connect to the `VS_COLLECTION_NAME` collection.\n",
    "vs_collection = mongodb_client[DB_NAME][VS_COLLECTION_NAME]\n",
    "# Connect to the `FULL_COLLECTION_NAME` collection.\n",
    "full_collection = mongodb_client[DB_NAME][FULL_COLLECTION_NAME]\n",
    "# Insert a dataset of MongoDB docs with embeddings into the `VS_COLLECTION_NAME` collection\n",
    "with open(f\"../data/{VS_COLLECTION_NAME}.json\", \"r\") as data_file:\n",
    "    json_data = data_file.read()\n",
    "\n",
    "data = json.loads(json_data)\n",
    "\n",
    "print(f\"Deleting existing documents from the {VS_COLLECTION_NAME} collection.\")\n",
    "vs_collection.delete_many({})\n",
    "vs_collection.insert_many(data)\n",
    "print(\n",
    "    f\"{vs_collection.count_documents({})} documents ingested into the {VS_COLLECTION_NAME} collection.\"\n",
    ")\n",
    "# Insert a dataset of MongoDB documentation pages into the `FULL_COLLECTION_NAME` collection\n",
    "with open(f\"../data/{FULL_COLLECTION_NAME}.json\", \"r\") as data_file:\n",
    "    json_data = data_file.read()\n",
    "\n",
    "data = json.loads(json_data)\n",
    "\n",
    "print(f\"Deleting existing documents from the {FULL_COLLECTION_NAME} collection.\")\n",
    "full_collection.delete_many({})\n",
    "full_collection.insert_many(data)\n",
    "print(\n",
    "    f\"{full_collection.count_documents({})} documents ingested into the {FULL_COLLECTION_NAME} collection.\"\n",
    ")\n",
    "# Create vector index definition specifying:\n",
    "# path: Path to the embeddings field\n",
    "# numDimensions: Number of embedding dimensions- depends on the embedding model used\n",
    "# similarity: Similarity metric. One of cosine, euclidean, dotProduct.\n",
    "model = {\n",
    "    \"name\": VS_INDEX_NAME,\n",
    "    \"type\": \"vectorSearch\",\n",
    "    \"definition\": {\n",
    "        \"fields\": [\n",
    "            {\n",
    "                \"type\": \"vector\",\n",
    "                \"path\": \"embedding\",\n",
    "                \"numDimensions\": 1024,\n",
    "                \"similarity\": \"cosine\",\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "}\n",
    "create_index(vs_collection, VS_INDEX_NAME, model)\n",
    "# Use the `check_index_ready` function from the `utils` module to verify that the index was created and is in READY status before proceeding\n",
    "check_index_ready(vs_collection, VS_INDEX_NAME)\n",
    "# Track progress of key steps-- DO NOT CHANGE\n",
    "track_progress(\"vs_index_creation\", \"ai_agents_lab\")\n",
    "# Initialize the Voyage AI client\n",
    "vo = voyageai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://docs.voyageai.com/docs/contextualized-chunk-embeddings#approach-2-contextualized-chunk-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(query: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Get embeddings for an input query.\n",
    "\n",
    "    Args:\n",
    "        query (str): Query string\n",
    "\n",
    "    Returns:\n",
    "        List[float]: Embedding of the query string\n",
    "    \"\"\"\n",
    "    # Use the `contextualized_embed` method of the Voyage AI API to embed the user query with the following arguments:\n",
    "    # inputs: `query` wrapped in a list of lists\n",
    "    # model: `voyage-context-3`\n",
    "    # input_type: \"query\"\n",
    "    embds_obj = vo.contextualized_embed(inputs=[[query]], model=\"voyage-context-3\", input_type=\"query\")\n",
    "    # Extract embeddings from the embeddings object\n",
    "    embeddings = embds_obj.results[0].embeddings[0]\n",
    "    return embeddings\n",
    "# Define a tool to retrieve relevant documents for a user query using vector search\n",
    "@tool\n",
    "def get_information_for_question_answering(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve information using vector search to answer a user query.\n",
    "\n",
    "    Args:\n",
    "    user_query (str): The user's query string.\n",
    "\n",
    "    Returns:\n",
    "    str: The retrieved information formatted as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate embeddings for the `user_query` using the `get_embeddings` function defined above\n",
    "    query_embedding = get_embeddings(user_query)\n",
    "\n",
    "    # Define an aggregation pipeline consisting of a $vectorSearch stage, followed by a $project stage\n",
    "    # Set the number of candidates to 150 and only return the top 5 documents from the vector search\n",
    "    # In the $project stage, exclude the `_id` field and include only the `body` field and `vectorSearchScore`\n",
    "    # NOTE: Use variables defined previously for the `index`, `queryVector` and `path` fields in the $vectorSearch stage\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$vectorSearch\": {\n",
    "                \"index\": VS_INDEX_NAME,\n",
    "                \"path\": \"embedding\",\n",
    "                \"queryVector\": query_embedding,\n",
    "                \"numCandidates\": 150,\n",
    "                \"limit\": 5,\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"_id\": 0,\n",
    "                \"body\": 1,\n",
    "                \"score\": {\"$meta\": \"vectorSearchScore\"},\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Execute the aggregation `pipeline` against the `vs_collection` collection and store the results in `results`\n",
    "    results = vs_collection.aggregate(pipeline)\n",
    "    # Concatenate the results into a string\n",
    "    context = \"\\n\\n\".join([doc.get(\"body\") for doc in results])\n",
    "    return context\n",
    "# Define a tool to retrieve the content of a documentation page for summarization\n",
    "@tool\n",
    "def get_page_content_for_summarization(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve page content based on provided title.\n",
    "\n",
    "    Args:\n",
    "    user_query (str): The user's query string i.e. title of the documentation page.\n",
    "\n",
    "    Returns:\n",
    "    str: The content of the page.\n",
    "    \"\"\"\n",
    "    # Query the documents where the `title` field is equal to the `user_query`\n",
    "    query = {\"title\": user_query}\n",
    "    # Only return the `body` field from the retrieved documents.\n",
    "    # NOTE: Set fields to include to 1, those to exclude to 0. `_id` is included by default, so exclude that.\n",
    "    projection = {\"_id\": 0, \"body\": 1}\n",
    "    # Use the `query` and `projection` with the `find_one` method\n",
    "    # to get the `body` of the document with `title` equal to the `user_query` from the `full_collection` collection\n",
    "    document = full_collection.find_one(query, projection)\n",
    "    if document:\n",
    "        return document[\"body\"]\n",
    "    else:\n",
    "        return \"Document not found\"\n",
    "# Create the list of tools\n",
    "tools = [\n",
    "    get_information_for_question_answering,\n",
    "    get_page_content_for_summarization,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#ann-examples (Refer to the \"Basic Example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out the tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Define graph state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the graph state\n",
    "# We are only tracking chat messages but you can track other attributes as well\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "# Obtain the Langchain LLM object using the `get_llm` function from the `utils`` module.\n",
    "llm = get_llm(LLM_PROVIDER)\n",
    "# Create a Chain-of-Thought (CoT) prompt template for the agent.\n",
    "# This includes a system prompt with a placeholder for tool names, and a placeholder for messages i.e. user queries and assistant responses\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"You are a helpful AI assistant.\"\n",
    "            \" You are provided with tools to answer questions and summarize technical documentation related to MongoDB.\"\n",
    "            \" Think step-by-step and use these tools to get the information required to answer the user query.\"\n",
    "            \" Do not re-run tools unless absolutely necessary.\"\n",
    "            \" If you are not able to get enough information using the tools, reply with I DON'T KNOW.\"\n",
    "            \" You have access to the following tools: {tool_names}.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "# Fill in the prompt template with the tool names\n",
    "prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "# Bind the `tools` to the `llm` instantiated above\n",
    "bind_tools = llm.bind_tools(tools)\n",
    "# Chain the `prompt` with the tool-augmented llm using the `|` operator\n",
    "llm_with_tools = prompt | bind_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Define graph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x73403600f850>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the agent node\n",
    "def agent(state: GraphState) -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Agent node\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Graph state\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List]: Updates to messages\n",
    "    \"\"\"\n",
    "    # Get the messages from the graph `state`\n",
    "    messages = state[\"messages\"]\n",
    "    # Invoke `llm_with_tools` with `messages` using the `invoke` method\n",
    "    # HINT: See Step 6 for how to invoke `llm_with_tools`\n",
    "    result = llm_with_tools.invoke(messages)\n",
    "    # Write `result` to the `messages` attribute of the graph state\n",
    "    return {\"messages\": [result]}\n",
    "# Create a map of tool name to tool call\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "# Define tool node\n",
    "def tool_node(state: GraphState) -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Tool node\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Graph state\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List]: Updates to messages\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    # Get the list of tool calls from messages\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    # A tool_call looks as follows:\n",
    "    # {\n",
    "    #     \"name\": \"get_information_for_question_answering\",\n",
    "    #     \"args\": {\"user_query\": \"What are Atlas Triggers\"},\n",
    "    #     \"id\": \"call_H5TttXb423JfoulF1qVfPN3m\",\n",
    "    #     \"type\": \"tool_call\",\n",
    "    # }\n",
    "    # Iterate through `tool_calls`\n",
    "    for tool_call in tool_calls:\n",
    "        # Get the tool from `tools_by_name` using the `name` attribute of the `tool_call`\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        # Invoke the `tool` using the `args` attribute of the `tool_call`\n",
    "        # HINT: See previous line to see how to extract attributes from `tool_call`\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        # Append the result of executing the tool to the `result` list as a ToolMessage\n",
    "        # The `content` of the message is `observation` i.e. result of the tool call\n",
    "        # The `tool_call_id` can be obtained from the `tool_call`\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    # Write `result` to the `messages` attribute of the graph state\n",
    "    return {\"messages\": result}\n",
    "# Define conditional routing function\n",
    "def route_tools(state: GraphState):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the tool node if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    # Get messages from graph state\n",
    "    messages = state.get(\"messages\", [])\n",
    "    if len(messages) > 0:\n",
    "        # Get the last AI message from messages\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    # Check if the last message has tool calls\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        # If yes, return \"tools\"\n",
    "        return \"tools\"\n",
    "    # If no, return END\n",
    "    return END\n",
    "# Instantiate the graph\n",
    "graph = StateGraph(GraphState)\n",
    "# Add nodes to the `graph` using the `add_node` function\n",
    "# Add a `agent` node. The `agent` node should run the `agent` function\n",
    "graph.add_node(\"agent\", agent)\n",
    "# Add a `tools` node. The `tools` node should run the `tool_node` function\n",
    "graph.add_node(\"tools\", tool_node)\n",
    "# Add fixed edges to the `graph` using the `add_edge` method\n",
    "# Add an edge from the START node to the `agent` node\n",
    "graph.add_edge(START, \"agent\")\n",
    "# Add an edge from the `tools` node to the `agent` node\n",
    "graph.add_edge(\"tools\", \"agent\")\n",
    "# Use the `add_conditional_edges` method to add a conditional edge from the `agent` node to the `tools` node\n",
    "# based on the output of the `route_tools` function\n",
    "graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    route_tools,\n",
    "    {\"tools\": \"tools\", END: END},\n",
    ")\n",
    "# Compile the `graph`\n",
    "app = graph.compile()\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_graph(user_input: str) -> None:\n",
    "    \"\"\"\n",
    "    Stream outputs from the graph\n",
    "\n",
    "    Args:\n",
    "        user_input (str): User query string\n",
    "    \"\"\"\n",
    "    # Stream outputs from each step in the graph\n",
    "    for step in app.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        # Stream full value of the state after each step\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        # Print the latest message from the step\n",
    "        step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are some best practices for data backups in MongoDB?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'll help you find information about best practices for data backups in MongoDB.\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_014fPLgFBfRsk8G6Yab4JM45)\n",
      " Call ID: toolu_bdrk_014fPLgFBfRsk8G6Yab4JM45\n",
      "  Args:\n",
      "    user_query: best practices for data backups in MongoDB\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "FTDC data contains certain host machine information such as hostnames, operating system information, and the options or settings used to start the `mongod` or `mongos`. This information may be considered protected or confidential by some organizations or regulatory bodies, but is not typically considered to be Personally Identifiable Information (PII). For clusters where these fields are configured with protected, confidential, or PII data, please notify MongoDB engineers before sending FTDC data to coordinate appropriate security measures.\n",
      "\n",
      "On Windows, to collect system data such as disk, cpu, and memory, FTDC requires Microsoft access permissions from the following groups:\n",
      "\n",
      "- Performance Monitor Users\n",
      "\n",
      "- Performance Log Users\n",
      "\n",
      "If the user running `mongod` and `mongos` is not an administrator, add them to these groups to log FTDC data. For more information, see the Microsoft documentation here.\n",
      "\n",
      "FTDC periodically collects statistics produced by the following commands:\n",
      "\n",
      "- `serverStatus`\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01RAQubaDti9w6o6GvdSoyyw)\n",
      " Call ID: toolu_bdrk_01RAQubaDti9w6o6GvdSoyyw\n",
      "  Args:\n",
      "    user_query: MongoDB backup strategies recommendations mongodump file system snapshots\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_011imezCo2uCGXSyLhMxoaHG)\n",
      " Call ID: toolu_bdrk_011imezCo2uCGXSyLhMxoaHG\n",
      "  Args:\n",
      "    user_query: MongoDB backup methods replica sets point in time recovery backup frequency\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "Just for the sake of it, I also used multi-document ACID transactions in a few methods where it could potentially make sense to use ACID transactions. You can check all the code in the `MongoDBPersonRepository` class.\n",
      "\n",
      "Here is an example:\n",
      "\n",
      "```java\n",
      "private static final TransactionOptions txnOptions = TransactionOptions.builder()\n",
      "    .readPreference(ReadPreference.primary())\n",
      "    .readConcern(ReadConcern.MAJORITY)\n",
      "    .writeConcern(WriteConcern.MAJORITY)\n",
      "    .build();\n",
      "\n",
      "@Override\n",
      "public List saveAll(List personEntities) {\n",
      "    try (ClientSession clientSession = client.startSession()) {\n",
      "        return clientSession.withTransaction(() -> {\n",
      "            personEntities.forEach(p -> p.setId(new ObjectId()));\n",
      "            personCollection.insertMany(clientSession, personEntities);\n",
      "            return personEntities;\n",
      "        }, txnOptions);\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "As you can see, Iâ€™m using an auto-closeable try-with-resources which will automatically close the client session at the end. This helps me to keep the code clean and simple.\n",
      "\n",
      "Some of you may argue that it is actually too simple because transactions (and write operations, in general) can throw exceptions, and Iâ€™m not handling any of them hereâ€¦ You are absolutely right and this is an excellent transition to the next part of this article.\n",
      "\n",
      "## Exception management\n",
      "\n",
      "Transactions in MongoDB can raise exceptions for various reasons, and I donâ€™t want to go into the details too much here, but since MongoDB 3.6, any write operation that fails can be automatically retried once. And the transactions are no different. See the documentation for retryWrites.\n",
      "\n",
      "If retryable writes are disabled or if a write operation fails twice, then MongoDB will send a MongoException (extends RuntimeException) which should be handled properly.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01Ae2hGvauKYAdhtLcym9jwt)\n",
      " Call ID: toolu_bdrk_01Ae2hGvauKYAdhtLcym9jwt\n",
      "  Args:\n",
      "    user_query: backup best practices testing backups offsite storage encryption\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "\n",
      "FTDC data contains certain host machine information such as hostnames, operating system information, and the options or settings used to start the `mongod` or `mongos`. This information may be considered protected or confidential by some organizations or regulatory bodies, but is not typically considered to be Personally Identifiable Information (PII). For clusters where these fields are configured with protected, confidential, or PII data, please notify MongoDB engineers before sending FTDC data to coordinate appropriate security measures.\n",
      "\n",
      "On Windows, to collect system data such as disk, cpu, and memory, FTDC requires Microsoft access permissions from the following groups:\n",
      "\n",
      "- Performance Monitor Users\n",
      "\n",
      "- Performance Log Users\n",
      "\n",
      "If the user running `mongod` and `mongos` is not an administrator, add them to these groups to log FTDC data. For more information, see the Microsoft documentation here.\n",
      "\n",
      "FTDC periodically collects statistics produced by the following commands:\n",
      "\n",
      "- `serverStatus`\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01CnDuxffB2TVYt52f1Waw5z)\n",
      " Call ID: toolu_bdrk_01CnDuxffB2TVYt52f1Waw5z\n",
      "  Args:\n",
      "    user_query: MongoDB backup considerations replica set secondary node snapshot\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "FTDC data contains certain host machine information such as hostnames, operating system information, and the options or settings used to start the `mongod` or `mongos`. This information may be considered protected or confidential by some organizations or regulatory bodies, but is not typically considered to be Personally Identifiable Information (PII). For clusters where these fields are configured with protected, confidential, or PII data, please notify MongoDB engineers before sending FTDC data to coordinate appropriate security measures.\n",
      "\n",
      "On Windows, to collect system data such as disk, cpu, and memory, FTDC requires Microsoft access permissions from the following groups:\n",
      "\n",
      "- Performance Monitor Users\n",
      "\n",
      "- Performance Log Users\n",
      "\n",
      "If the user running `mongod` and `mongos` is not an administrator, add them to these groups to log FTDC data. For more information, see the Microsoft documentation here.\n",
      "\n",
      "FTDC periodically collects statistics produced by the following commands:\n",
      "\n",
      "- `serverStatus`\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_page_content_for_summarization (toolu_bdrk_01MMWvT1iji2UAdQVEL9CGqG)\n",
      " Call ID: toolu_bdrk_01MMWvT1iji2UAdQVEL9CGqG\n",
      "  Args:\n",
      "    user_query: MongoDB backup methods\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Document not found\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_page_content_for_summarization (toolu_bdrk_01PveAgZNnoj5N6LGpSzVA7L)\n",
      " Call ID: toolu_bdrk_01PveAgZNnoj5N6LGpSzVA7L\n",
      "  Args:\n",
      "    user_query: backup and restore\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Document not found\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_016DpeN9fJmd1oiPftqzBFGX)\n",
      " Call ID: toolu_bdrk_016DpeN9fJmd1oiPftqzBFGX\n",
      "  Args:\n",
      "    user_query: mongodump mongorestore backup procedure standalone replica set\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "\n",
      "# Administration\n",
      "\n",
      "The administration documentation addresses the ongoing operation and maintenance of MongoDB instances and deployments. This documentation includes both high level overviews of these concerns as well as tutorials that cover specific procedures and processes for operating MongoDB.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_016QXGQhfa8L8cjj9vnM7woY)\n",
      " Call ID: toolu_bdrk_016QXGQhfa8L8cjj9vnM7woY\n",
      "  Args:\n",
      "    user_query: backup strategies file system snapshot LVM EBS consistent backup\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the information I've gathered from the MongoDB documentation, here are some **best practices for data backups in MongoDB**:\n",
      "\n",
      "## Backup Methods\n",
      "\n",
      "1. **Use Managed Backup Solutions (Recommended)**\n",
      "   - **MongoDB Atlas, Cloud Manager, or Ops Manager** - These provide coordinated backup and restore processes that maintain atomicity guarantees of transactions across shards\n",
      "   - These are particularly recommended for sharded clusters\n",
      "\n",
      "2. **File System Snapshots**\n",
      "   - Can be more efficient than MongoDB tools if your system configuration supports them\n",
      "   - Suitable for backing up each component in a cluster individually\n",
      "   - Requires stopping the cluster balancer during backup operations\n",
      "\n",
      "3. **mongodump and mongorestore**\n",
      "   - Can be used as a backup strategy for various deployment types\n",
      "   - For sharded clusters, requires additional precautions:\n",
      "     - Stop the sharded cluster balancer\n",
      "     - Use the `fsync` command or `db.fsyncLock()` method on `mongos` to block writes during backups\n",
      "   - Back up each component in the cluster individually\n",
      "\n",
      "## Key Best Practices\n",
      "\n",
      "1. **Minimize Impact on Production**\n",
      "   - For sharded clusters, stop or limit the cluster balancer operation to provide a window for regular backup operations\n",
      "   - Use `fsync` or `db.fsyncLock()` to ensure data consistency during backups\n",
      "\n",
      "2. **Maintain Consistency**\n",
      "   - Ensure backups are consistent, especially in sharded environments\n",
      "   - Use coordinated backup processes that maintain atomicity guarantees across shards\n",
      "\n",
      "3. **Plan for Different Deployment Types**\n",
      "   - Backup strategies differ between standalone instances, replica sets, and sharded clusters\n",
      "   - Sharded clusters require more coordination and planning\n",
      "\n",
      "4. **Regular Backup Schedule**\n",
      "   - Establish regular backup windows, especially when using the balancer limitation approach\n",
      "\n",
      "These practices help ensure your MongoDB data is properly protected and can be restored when needed.\n"
     ]
    }
   ],
   "source": [
    "# Test the graph execution to view end-to-end flow\n",
    "execute_graph(\"What are some best practices for data backups in MongoDB?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Give me a summary of the page titled Create a MongoDB Deployment\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'll retrieve the content of the page titled \"Create a MongoDB Deployment\" and provide you with a summary.\n",
      "Tool Calls:\n",
      "  get_page_content_for_summarization (toolu_bdrk_01772dunBwaGk2MyF9eQZcVc)\n",
      " Call ID: toolu_bdrk_01772dunBwaGk2MyF9eQZcVc\n",
      "  Args:\n",
      "    user_query: Create a MongoDB Deployment\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Create a MongoDB Deployment\n",
      "\n",
      "You can create a free tier MongoDB deployment on MongoDB Atlas to store and manage your data. MongoDB Atlas hosts and manages your MongoDB database in the cloud.\n",
      "\n",
      "## Create a Free MongoDB deployment on Atlas\n",
      "\n",
      "Complete the Get Started with Atlas guide to set up a new Atlas account and load sample data into a new free tier MongoDB deployment.\n",
      "\n",
      "## Save your Credentials\n",
      "\n",
      "After you create your database user, save that user's username and password to a safe location for use in an upcoming step.\n",
      "\n",
      "After you complete these steps, you have a new free tier MongoDB deployment on Atlas, database user credentials, and sample data loaded in your database.\n",
      "\n",
      "If you run into issues on this step, ask for help in the MongoDB Community Forums or submit feedback by using the Rate this page tab on the right or bottom right side of this page.\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "## Summary of \"Create a MongoDB Deployment\"\n",
      "\n",
      "This page provides guidance on creating a free MongoDB deployment using MongoDB Atlas, which is MongoDB's cloud-based database hosting and management service.\n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "1. **Free Tier Deployment**: You can create a free tier MongoDB deployment on MongoDB Atlas to store and manage your data in the cloud.\n",
      "\n",
      "2. **Getting Started**: The page directs users to follow the \"Get Started with Atlas\" guide, which walks through:\n",
      "   - Setting up a new Atlas account\n",
      "   - Creating a new free tier MongoDB deployment\n",
      "   - Loading sample data into the deployment\n",
      "\n",
      "3. **Important Security Step**: After creating a database user, you must save the username and password credentials in a safe location for future use.\n",
      "\n",
      "4. **Expected Outcome**: Upon completion, you will have:\n",
      "   - A new free tier MongoDB deployment on Atlas\n",
      "   - Database user credentials\n",
      "   - Sample data loaded in your database\n",
      "\n",
      "5. **Support Resources**: If you encounter issues, you can seek help through the MongoDB Community Forums or submit feedback using the page rating feature.\n",
      "\n",
      "This is an introductory page designed to help new users quickly set up their first MongoDB database in the cloud using Atlas's free tier offering.\n"
     ]
    }
   ],
   "source": [
    "# Test the graph execution to view end-to-end flow\n",
    "execute_graph(\"Give me a summary of the page titled Create a MongoDB Deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11: Add memory to the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.mongodb import MongoDBSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a MongoDB checkpointer\n",
    "checkpointer = MongoDBSaver(mongodb_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the graph with the checkpointer\n",
    "app = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://langchain-ai.github.io/langgraph/concepts/persistence/#threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_graph_with_memory(thread_id: str, user_input: str) -> None:\n",
    "    \"\"\"\n",
    "    Stream outputs from the graph\n",
    "\n",
    "    Args:\n",
    "        thread_id (str): Thread ID for the checkpointer\n",
    "        user_input (str): User query string\n",
    "    \"\"\"\n",
    "    # Create a runtime config for the thread ID `thread_id`\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    # Stream outputs from each step in the graph\n",
    "    for step in app.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        # Pass the config as an additional parameter\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        # Print the latest message from the step\n",
    "        step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are some best practices for data backups in MongoDB?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the MongoDB documentation I've already retrieved, here are the **best practices for data backups in MongoDB**:\n",
      "\n",
      "## Backup Methods\n",
      "\n",
      "1. **Use Managed Backup Solutions (Recommended)**\n",
      "   - **MongoDB Atlas, Cloud Manager, or Ops Manager** - These provide coordinated backup and restore processes that maintain atomicity guarantees of transactions across shards\n",
      "   - These are particularly recommended for sharded clusters\n",
      "\n",
      "2. **File System Snapshots**\n",
      "   - Can be more efficient than MongoDB tools if your system configuration supports them\n",
      "   - Suitable for backing up each component in a cluster individually\n",
      "   - Requires stopping the cluster balancer during backup operations\n",
      "\n",
      "3. **mongodump and mongorestore**\n",
      "   - Can be used as a backup strategy for various deployment types\n",
      "   - For sharded clusters, requires additional precautions:\n",
      "     - Stop the sharded cluster balancer\n",
      "     - Use the `fsync` command or `db.fsyncLock()` method on `mongos` to block writes during backups\n",
      "   - Back up each component in the cluster individually\n",
      "\n",
      "## Key Best Practices\n",
      "\n",
      "1. **Minimize Impact on Production**\n",
      "   - For sharded clusters, stop or limit the cluster balancer operation to provide a window for regular backup operations\n",
      "   - Use `fsync` or `db.fsyncLock()` to ensure data consistency during backups\n",
      "\n",
      "2. **Maintain Consistency**\n",
      "   - Ensure backups are consistent, especially in sharded environments\n",
      "   - Use coordinated backup processes that maintain atomicity guarantees across shards\n",
      "\n",
      "3. **Plan for Different Deployment Types**\n",
      "   - Backup strategies differ between standalone instances, replica sets, and sharded clusters\n",
      "   - Sharded clusters require more coordination and planning\n",
      "\n",
      "4. **Regular Backup Schedule**\n",
      "   - Establish regular backup windows, especially when using the balancer limitation approach\n",
      "\n",
      "These practices help ensure your MongoDB data is properly protected and can be restored when needed.\n"
     ]
    }
   ],
   "source": [
    "# Test graph execution with thread ID\n",
    "execute_graph_with_memory(\n",
    "    \"1\",\n",
    "    \"What are some best practices for data backups in MongoDB?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What did I just ask you?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You just asked me: \"What are some best practices for data backups in MongoDB?\"\n"
     ]
    }
   ],
   "source": [
    "# Follow-up question to ensure message history works\n",
    "execute_graph_with_memory(\n",
    "    \"1\",\n",
    "    \"What did I just ask you?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long-Term Memory Implementation: Hot Path (Memory Tools)\n",
    "\n",
    "This implementation uses **Memory Tools** (`create_manage_memory_tool` and `create_search_memory_tool`) \n",
    "which allow the agent to **consciously** manage its own long-term memory.\n",
    "\n",
    "## How it works:\n",
    "1. The agent has access to `manage_memory` tool to save important user information\n",
    "2. The agent has access to `search_memory` tool to retrieve relevant memories\n",
    "3. Memories persist in MongoDB and survive across conversation threads\n",
    "\n",
    "## References:\n",
    "- [LangMem Hot Path Quickstart](https://langchain-ai.github.io/langmem/hot_path_quickstart/)\n",
    "- [LangMem Memory Tools Reference](https://langchain-ai.github.io/langmem/reference/tools/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS FOR LONG-TERM MEMORY (HOT PATH)\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "from langmem import create_search_memory_tool\n",
    "from langgraph.store.mongodb import MongoDBStore, create_vector_index_config\n",
    "from langchain_voyageai import VoyageAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Collection dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop the memories collection\n",
    "mongodb_client[\"mongodb_genai_devday_agents\"][\"memories\"].drop()\n",
    "print(\"âœ… Collection dropped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hot path patched to include 'kind' field\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MONKEY-PATCH: HOT PATH TO INCLUDE \"kind\" FIELD\n",
    "# Add this AFTER imports, BEFORE creating memory tools\n",
    "# =============================================================================\n",
    "\n",
    "from langmem.knowledge.tools import _get_store, _ensure_json_serializable\n",
    "from langmem import utils\n",
    "from langchain_core.tools import StructuredTool\n",
    "import typing\n",
    "import uuid\n",
    "\n",
    "def create_manage_memory_tool(\n",
    "    namespace: tuple[str, ...] | str,\n",
    "    *,\n",
    "    instructions: str = \"Proactively call this tool when you:\\n\\n\"\n",
    "    \"1. Identify a new USER preference.\\n\"\n",
    "    \"2. Receive an explicit USER request to remember something or otherwise alter your behavior.\\n\"\n",
    "    \"3. Are working and want to record important context.\\n\"\n",
    "    \"4. Identify that an existing MEMORY is incorrect or outdated.\\n\",\n",
    "    schema: typing.Type = str,\n",
    "    actions_permitted: tuple = (\"create\", \"update\", \"delete\"),\n",
    "    store = None,\n",
    "    name: str = \"manage_memory\",\n",
    "):\n",
    "    \"\"\"Drop-in replacement for langmem.create_manage_memory_tool with cold path compatibility.\"\"\"\n",
    "    \n",
    "    namespacer = utils.NamespaceTemplate(namespace)\n",
    "    action_type = typing.Literal[actions_permitted]\n",
    "    default_action = \"create\" if \"create\" in actions_permitted else actions_permitted[0]\n",
    "    initial_store = store\n",
    "    \n",
    "    # Get schema name for \"kind\" field\n",
    "    schema_name = schema.__name__ if hasattr(schema, \"__name__\") else \"Memory\"\n",
    "\n",
    "    async def amanage_memory(\n",
    "        content: typing.Optional[schema] = None,\n",
    "        action: action_type = default_action,\n",
    "        *,\n",
    "        id: typing.Optional[uuid.UUID] = None,\n",
    "    ):\n",
    "        store = _get_store(initial_store)\n",
    "        if action not in actions_permitted:\n",
    "            raise ValueError(f\"Invalid action {action}. Must be one of {actions_permitted}.\")\n",
    "        if action == \"create\" and id is not None:\n",
    "            raise ValueError(\"Cannot provide ID when creating a memory.\")\n",
    "        if action in (\"delete\", \"update\") and not id:\n",
    "            raise ValueError(\"Must provide ID when deleting or updating.\")\n",
    "        \n",
    "        ns = namespacer()\n",
    "        if action == \"delete\":\n",
    "            await store.adelete(ns, key=str(id))\n",
    "            return f\"Deleted memory {id}\"\n",
    "\n",
    "        id = id or uuid.uuid4()\n",
    "        # PATCHED: Include \"kind\" for cold path compatibility\n",
    "        await store.aput(\n",
    "            ns,\n",
    "            key=str(id),\n",
    "            value={\n",
    "                \"kind\": schema_name,\n",
    "                \"content\": _ensure_json_serializable(content)\n",
    "            },\n",
    "        )\n",
    "        return f\"{action}d memory {id}\"\n",
    "\n",
    "    def manage_memory(\n",
    "        content: typing.Optional[schema] = None,\n",
    "        action: action_type = default_action,\n",
    "        *,\n",
    "        id: typing.Optional[uuid.UUID] = None,\n",
    "    ):\n",
    "        store = _get_store(initial_store)\n",
    "        if action not in actions_permitted:\n",
    "            raise ValueError(f\"Invalid action {action}. Must be one of {actions_permitted}.\")\n",
    "        if action == \"create\" and id is not None:\n",
    "            raise ValueError(\"Cannot provide ID when creating a memory.\")\n",
    "        if action in (\"delete\", \"update\") and not id:\n",
    "            raise ValueError(\"Must provide ID when deleting or updating.\")\n",
    "        \n",
    "        ns = namespacer()\n",
    "        if action == \"delete\":\n",
    "            store.delete(ns, key=str(id))\n",
    "            return f\"Deleted memory {id}\"\n",
    "\n",
    "        id = id or uuid.uuid4()\n",
    "        # PATCHED: Include \"kind\" for cold path compatibility\n",
    "        store.put(\n",
    "            ns,\n",
    "            key=str(id),\n",
    "            value={\n",
    "                \"kind\": schema_name,\n",
    "                \"content\": _ensure_json_serializable(content)\n",
    "            },\n",
    "        )\n",
    "        return f\"{action}d memory {id}\"\n",
    "\n",
    "    description = f\"\"\"Create, update, or delete a memory.\n",
    "Include the MEMORY ID when updating or deleting. Omit when creating.\n",
    "{instructions}\"\"\"\n",
    "\n",
    "    return StructuredTool.from_function(\n",
    "        manage_memory, amanage_memory, name=name, description=description\n",
    "    )\n",
    "\n",
    "print(\"Hot path patched to include 'kind' field\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MongoDBStore initialized for mongodb_genai_devday_agents.memories\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SETUP MONGODB STORE FOR LONG-TERM MEMORY\n",
    "# =============================================================================\n",
    "\n",
    "MEMORY_DB_NAME = \"mongodb_genai_devday_agents\"\n",
    "MEMORY_COLLECTION_NAME = \"memories\"\n",
    "\n",
    "# Get collection reference for direct queries\n",
    "memory_collection = mongodb_client[MEMORY_DB_NAME][MEMORY_COLLECTION_NAME]\n",
    "\n",
    "# Create vector index configuration for semantic search\n",
    "memory_index_config = create_vector_index_config(\n",
    "    dims=1024,\n",
    "    embed=VoyageAIEmbeddings(model=\"voyage-3\"),\n",
    "    fields=[\"content\"],\n",
    "    name=\"memory_vector_index\"\n",
    ")\n",
    "\n",
    "# Initialize MongoDBStore with collection object (NOT from_conn_string)\n",
    "# IMPORTANT: from_conn_string() returns a context manager, not a store object\n",
    "memory_store = MongoDBStore(\n",
    "    collection=memory_collection,\n",
    "    index_config=memory_index_config\n",
    ")\n",
    "\n",
    "print(f\"âœ… MongoDBStore initialized for {MEMORY_DB_NAME}.{MEMORY_COLLECTION_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Memory tools created:\n",
      "   - manage_memory: Save/update/delete memories\n",
      "   - search_memory: Search existing memories\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CREATE MEMORY TOOLS (HOT PATH)\n",
    "# These tools allow the agent to consciously manage its memory\n",
    "# =============================================================================\n",
    "\n",
    "# Tool for saving/updating/deleting memories\n",
    "# Note: namespace uses {langgraph_user_id} which must match the config key\n",
    "'''manage_memory_tool = create_manage_memory_tool(\n",
    "    namespace=(\"memories\", \"{langgraph_user_id}\"),  # User-scoped memories\n",
    "    instructions=\"\"\"Save important user information to memory, including:\n",
    "    - User's role or job title (e.g., DBA, developer, architect)\n",
    "    - User's expertise level and areas of focus\n",
    "    - User's preferences for how information should be presented\n",
    "    - Topics the user is interested in\n",
    "    Always save relevant user context when they share it.\"\"\"\n",
    ")'''\n",
    "manage_memory_tool = create_manage_memory_tool(\n",
    "    namespace=(\"memories\", \"{langgraph_user_id}\"), \n",
    "     store=memory_store, # User-scoped memories\n",
    "     actions_permitted=(\"create\",), \n",
    "   \n",
    ")\n",
    "\n",
    "# Tool for searching memories\n",
    "search_memory_tool = create_search_memory_tool(\n",
    "   namespace=(\"memories\", \"{langgraph_user_id}\"),\n",
    "   store= memory_store\n",
    ")\n",
    "\n",
    "print(\"âœ… Memory tools created:\")\n",
    "print(f\"   - {manage_memory_tool.name}: Save/update/delete memories\")\n",
    "print(f\"   - {search_memory_tool.name}: Search existing memories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Total tools available: 4\n",
      "   - get_information_for_question_answering\n",
      "   - get_page_content_for_summarization\n",
      "   - manage_memory\n",
      "   - search_memory\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# COMBINE ORIGINAL TOOLS WITH MEMORY TOOLS\n",
    "# =============================================================================\n",
    "\n",
    "# Add memory tools to the existing tools list\n",
    "'''tools_with_memory = tools + [manage_memory_tool, search_memory_tool]\n",
    "\n",
    "# Update tools_by_name dictionary\n",
    "tools_by_name_with_memory = {tool.name: tool for tool in tools_with_memory}'''\n",
    "\n",
    "tools = tools + [manage_memory_tool, search_memory_tool]\n",
    "#temp\n",
    "tools = [\n",
    "    get_information_for_question_answering,\n",
    "    get_page_content_for_summarization,\n",
    "    manage_memory_tool,\n",
    "    search_memory_tool,\n",
    "]\n",
    "\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "print(f\"âœ… Total tools available: {len(tools)}\")\n",
    "for tool in tools:\n",
    "    print(f\"   - {tool.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Memory-aware prompt created\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CREATE MEMORY-AWARE PROMPT\n",
    "# This prompt instructs the agent to use memory tools\n",
    "# =============================================================================\n",
    "\n",
    "memory_aware_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a helpful AI assistant with persistent memory capabilities.\n",
    "You can answer questions about MongoDB documentation using your tools.\n",
    "\n",
    "IMPORTANT MEMORY INSTRUCTIONS:\n",
    "1. When a user shares personal information (their role, expertise, preferences, interests),\n",
    "   ALWAYS use the manage_memory tool to save it immediately.\n",
    "2. At the start of conversations, ALWAYS use search_memory to check for relevant user context.\n",
    "3. Tailor your responses based on what you remember about the user.\n",
    "4. Acknowledge when you save something to memory.\n",
    "5. CRITICAL: Use only the information provided by tools to respond to user questions. Say you Do not know if you the tools do not provide relevant info\n",
    "## Tool Usage Guidelines\n",
    "- Do NOT call the same retrieval tool more than 2 times for a single user question\n",
    "- If consecutive searches return similar content, stop searching and synthesize what you have\n",
    "- Only search for terms present in or directly implied by the user's question\n",
    "- Do not invent increasingly specific queries hoping for different results\n",
    "\n",
    "Available tools: {tool_names}\n",
    "\n",
    "Think step-by-step:\n",
    "1. First, search memory for relevant user context\n",
    "2. If user shares new info about themselves, save it to memory\n",
    "3. Use documentation tools to answer technical questions\n",
    "4. Provide personalized responses based on user context\"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fill in tool names\n",
    "memory_aware_prompt = memory_aware_prompt.partial(\n",
    "    #tool_names=\", \".join([tool.name for tool in tools_with_memory])\n",
    "    tool_names=\", \".join([tool.name for tool in tools])\n",
    ")\n",
    "\n",
    "print(\"âœ… Memory-aware prompt created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLM chain with memory tools created\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CREATE MEMORY-AWARE LLM CHAIN\n",
    "# =============================================================================\n",
    "\n",
    "# Bind all tools (including memory tools) to the LLM\n",
    "#llm_with_memory_tools = llm.bind_tools(tools_with_memory)\n",
    "llm_with_tools = memory_aware_prompt | llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "# Chain prompt with LLM\n",
    "#llm_chain_with_memory = memory_aware_prompt | llm_with_memory_tools\n",
    "\n",
    "print(\"âœ… LLM chain with memory tools created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def agent_with_memory(state: GraphState) -> Dict[str, List]:\\n    \"\"\"\\n    Agent node with memory capabilities.\\n    Uses the memory-aware prompt and tools.\\n    \"\"\"\\n    messages = state[\"messages\"]\\n    result = llm_chain_with_memory.invoke(messages)\\n    return {\"messages\": [result]}\\n\\n\\ndef tool_node_with_memory(state: GraphState) -> Dict[str, List]:\\n    \"\"\"\\n    Tool node that handles all tools including memory tools.\\n    \"\"\"\\n    result = []\\n    tool_calls = state[\"messages\"][-1].tool_calls\\n    \\n    for tool_call in tool_calls:\\n        tool_name = tool_call[\"name\"]\\n        tool = tools_by_name_with_memory[tool_name]\\n        \\n        try:\\n            observation = tool.invoke(tool_call[\"args\"])\\n            result.append(ToolMessage(\\n                content=str(observation), \\n                tool_call_id=tool_call[\"id\"]\\n            ))\\n        except Exception as e:\\n            result.append(ToolMessage(\\n                content=f\"Error executing {tool_name}: {str(e)}\", \\n                tool_call_id=tool_call[\"id\"]\\n            ))\\n    \\n    return {\"messages\": result}\\n\\nprint(\"âœ… Memory-aware agent and tool nodes defined\")'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DEFINE MEMORY-AWARE AGENT AND TOOL NODES\n",
    "# =============================================================================\n",
    "\n",
    "'''def agent_with_memory(state: GraphState) -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Agent node with memory capabilities.\n",
    "    Uses the memory-aware prompt and tools.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    result = llm_chain_with_memory.invoke(messages)\n",
    "    return {\"messages\": [result]}\n",
    "\n",
    "\n",
    "def tool_node_with_memory(state: GraphState) -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Tool node that handles all tools including memory tools.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    \n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool = tools_by_name_with_memory[tool_name]\n",
    "        \n",
    "        try:\n",
    "            observation = tool.invoke(tool_call[\"args\"])\n",
    "            result.append(ToolMessage(\n",
    "                content=str(observation), \n",
    "                tool_call_id=tool_call[\"id\"]\n",
    "            ))\n",
    "        except Exception as e:\n",
    "            result.append(ToolMessage(\n",
    "                content=f\"Error executing {tool_name}: {str(e)}\", \n",
    "                tool_call_id=tool_call[\"id\"]\n",
    "            ))\n",
    "    \n",
    "    return {\"messages\": result}\n",
    "\n",
    "print(\"âœ… Memory-aware agent and tool nodes defined\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Memory-aware graph compiled with:\n",
      "   - Checkpointer: Short-term memory (conversation threads)\n",
      "   - Store: Long-term memory (persistent user memories)\n"
     ]
    }
   ],
   "source": [
    "##Recompile the graph with memory_store\n",
    "app_with_memory = graph.compile(\n",
    "    checkpointer=checkpointer,  # Short-term memory (conversation history)\n",
    "    store=memory_store          # Long-term memory (persistent memories)\n",
    ")\n",
    "\n",
    "print(\"âœ… Memory-aware graph compiled with:\")\n",
    "print(\"   - Checkpointer: Short-term memory (conversation threads)\")\n",
    "print(\"   - Store: Long-term memory (persistent user memories)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x73403466b850>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE THE MEMORY-AWARE GRAPH\n",
    "# =============================================================================\n",
    "\n",
    "app_with_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXECUTION FUNCTION WITH MEMORY\n",
    "# =============================================================================\n",
    "\n",
    "def run_agent_with_memory(thread_id: str, user_id: str, user_input: str):\n",
    "    \"\"\"\n",
    "    Execute the memory-aware agent.\n",
    "    \n",
    "    Args:\n",
    "        thread_id: Unique conversation thread ID (short-term memory)\n",
    "        user_id: User identifier for memory scoping (long-term memory)\n",
    "        user_input: User's message\n",
    "    \"\"\"\n",
    "    # Config with both thread_id and langgraph_user_id\n",
    "    # IMPORTANT: langgraph_user_id must match the namespace pattern {langgraph_user_id}\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id,\n",
    "            \"langgraph_user_id\": user_id,  # Required for memory namespace\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Thread: {thread_id} | User: {user_id}\")\n",
    "    print(f\"Input: {user_input}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Stream the response\n",
    "    for step in app_with_memory.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        msg = step[\"messages\"][-1]\n",
    "        if hasattr(msg, 'pretty_print'):\n",
    "            msg.pretty_print()\n",
    "        else:\n",
    "            print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoints cleared\n"
     ]
    }
   ],
   "source": [
    "# Drop the checkpointing collection to start fresh\n",
    "mongodb_client[\"checkpointing_db\"][\"checkpoints\"].drop()\n",
    "print(\"Checkpoints cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Save User Information to Memory\n",
    "\n",
    "In this test, the user introduces themselves. The agent should:\n",
    "1. Recognize this is personal information\n",
    "2. Use `manage_memory` tool to save it\n",
    "3. Acknowledge that it saved the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Thread: session-14 | User: user-105\n",
      "Input: Hi! I'm a senior DBA focusing on disaster recovery and backup strategies. Please remember this about me.\n",
      "============================================================\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi! I'm a senior DBA focusing on disaster recovery and backup strategies. Please remember this about me.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  manage_memory (toolu_bdrk_01MkTn58MFFbU8TjAjmFa6P9)\n",
      " Call ID: toolu_bdrk_01MkTn58MFFbU8TjAjmFa6P9\n",
      "  Args:\n",
      "    action: create\n",
      "    content: User is a senior DBA (Database Administrator) with a focus on disaster recovery and backup strategies.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "created memory 37a69637-9211-4800-9469-00f6015a3432\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! Great to meet you! I've saved that you're a senior DBA focusing on disaster recovery and backup strategies. \n",
      "\n",
      "Given your expertise in this critical area, I'm here to help you with any MongoDB-related questions, particularly around backup solutions, disaster recovery planning, replication, point-in-time recovery, and related topics. Feel free to ask me anything about MongoDB documentation, and I'll tailor my responses to your professional context.\n",
      "\n",
      "How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST 1: User introduces themselves - Agent should save to memory\n",
    "# =============================================================================\n",
    "\n",
    "run_agent_with_memory(\n",
    "    thread_id=\"session-14\",\n",
    "    user_id=\"user-105\",\n",
    "    user_input=\"Hi! I'm a senior DBA focusing on disaster recovery and backup strategies. Please remember this about me.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checking MongoDB for saved memories ===\n",
      "\n",
      "Collection: mongodb_genai_devday_agents.memories\n",
      "\n",
      "Total documents in collection: 1\n",
      "\n",
      "--- Memory Document ---\n",
      "Namespace: ['memories', 'user-105']\n",
      "Key: 00fcb406-2cd2-4ed9-a199-61a1c623c8b8\n",
      "Value: {'kind': 'str', 'content': 'User is a senior DBA (Database Administrator) with a focus on disaster recovery and backup strategies.'}\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VERIFY: Check if memory was saved to MongoDB\n",
    "# =============================================================================\n",
    "\n",
    "time.sleep(2)  # Brief pause for write to complete\n",
    "\n",
    "print(\"=== Checking MongoDB for saved memories ===\")\n",
    "print(f\"\\nCollection: {MEMORY_DB_NAME}.{MEMORY_COLLECTION_NAME}\")\n",
    "\n",
    "# Query memories for user-123\n",
    "user_memories = list(memory_collection.find({}))\n",
    "print(f\"\\nTotal documents in collection: {len(user_memories)}\")\n",
    "\n",
    "for doc in user_memories:\n",
    "    print(f\"\\n--- Memory Document ---\")\n",
    "    print(f\"Namespace: {doc.get('namespace', 'N/A')}\")\n",
    "    print(f\"Key: {doc.get('key', 'N/A')}\")\n",
    "    print(f\"Value: {doc.get('value', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: New Conversation Thread Recalls Memory\n",
    "\n",
    "In this test, we start a NEW conversation thread but with the SAME user.\n",
    "The agent should:\n",
    "1. Search for existing memories about this user\n",
    "2. Find the previously saved information\n",
    "3. Use that context to personalize the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Thread: session-14 | User: user-105\n",
      "Input: Can you give me backup advice?\n",
      "============================================================\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you give me backup advice?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_memory (toolu_bdrk_0143d7zUgKXAMCheKSBJk5mG)\n",
      " Call ID: toolu_bdrk_0143d7zUgKXAMCheKSBJk5mG\n",
      "  Args:\n",
      "    query: backup disaster recovery DBA\n",
      "  get_information_for_question_answering (toolu_bdrk_014Pto2jWsVmUMXPJJycVuAA)\n",
      " Call ID: toolu_bdrk_014Pto2jWsVmUMXPJJycVuAA\n",
      "  Args:\n",
      "    user_query: MongoDB backup strategies methods best practices disaster recovery\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Absolutely! As a senior DBA focused on disaster recovery, here's comprehensive MongoDB backup advice:\n",
      "\n",
      "## **Primary Backup Methods for MongoDB**\n",
      "\n",
      "### **1. Managed Backup Solutions (Recommended for Production)**\n",
      "For sharded clusters and enterprise environments, MongoDB offers coordinated backup solutions that maintain **atomicity guarantees across shards**:\n",
      "- **MongoDB Atlas** (cloud-managed)\n",
      "- **MongoDB Cloud Manager**\n",
      "- **MongoDB Ops Manager**\n",
      "\n",
      "These solutions are particularly valuable for your DR strategy as they handle the complexity of distributed backups automatically.\n",
      "\n",
      "### **2. File System Snapshots**\n",
      "- Back up each component in the cluster individually\n",
      "- More efficient than MongoDB tools if your system supports it\n",
      "- **Important**: Requires stopping the cluster balancer during backup operations\n",
      "- Use `fsync` command or `db.fsyncLock()` method on `mongos` to block writes during backups\n",
      "\n",
      "### **3. mongodump/mongorestore**\n",
      "- Can be used for sharded clusters with precautions\n",
      "- **Critical requirements**:\n",
      "  - Stop the sharded cluster balancer\n",
      "  - Use `fsync` or `db.fsyncLock()` to block writes during backup\n",
      "  - Back up each component individually\n",
      "\n",
      "## **Key Considerations for Sharded Clusters**\n",
      "\n",
      "1. **Balancer Management**: Schedule balancer downtime windows for regular backup operations\n",
      "2. **Consistency**: Ensure atomicity across shards, especially if you have multi-shard transactions\n",
      "3. **Component-level backups**: Each shard and config server needs individual attention\n",
      "\n",
      "Would you like me to dive deeper into any specific backup method or discuss point-in-time recovery strategies?\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST 2: New thread, same user - Agent should recall memory\n",
    "# =============================================================================\n",
    "\n",
    "run_agent_with_memory(\n",
    "    thread_id=\"session-14\",  # NEW thread\n",
    "    user_id=\"user-105\",        # SAME user\n",
    "    user_input=\"Can you give me backup advice?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Technical Question with User Context\n",
    "\n",
    "Ask a technical question. The agent should:\n",
    "1. Recall that the user is a DBA focused on disaster recovery\n",
    "2. Tailor the response to their expertise level\n",
    "3. Focus on backup/recovery aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Thread: session-023 | User: user-123\n",
      "Input: I am looking for the best practices for MongoDB Operations\n",
      "============================================================\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I am looking for the best practices for MongoDB Operations\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'll help you find the best practices for MongoDB Operations. Let me search the documentation for you.\n",
      "Tool Calls:\n",
      "  search_memory (toolu_bdrk_01PEfscVQmHzFEuubrJqhaKn)\n",
      " Call ID: toolu_bdrk_01PEfscVQmHzFEuubrJqhaKn\n",
      "  Args:\n",
      "    query: MongoDB Operations best practices\n",
      "  get_information_for_question_answering (toolu_bdrk_012VAnp5h32rFxvF5s57ak92)\n",
      " Call ID: toolu_bdrk_012VAnp5h32rFxvF5s57ak92\n",
      "  Args:\n",
      "    user_query: best practices for MongoDB Operations\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Just for the sake of it, I also used multi-document ACID transactions in a few methods where it could potentially make sense to use ACID transactions. You can check all the code in the `MongoDBPersonRepository` class.\n",
      "\n",
      "Here is an example:\n",
      "\n",
      "```java\n",
      "private static final TransactionOptions txnOptions = TransactionOptions.builder()\n",
      "    .readPreference(ReadPreference.primary())\n",
      "    .readConcern(ReadConcern.MAJORITY)\n",
      "    .writeConcern(WriteConcern.MAJORITY)\n",
      "    .build();\n",
      "\n",
      "@Override\n",
      "public List saveAll(List personEntities) {\n",
      "    try (ClientSession clientSession = client.startSession()) {\n",
      "        return clientSession.withTransaction(() -> {\n",
      "            personEntities.forEach(p -> p.setId(new ObjectId()));\n",
      "            personCollection.insertMany(clientSession, personEntities);\n",
      "            return personEntities;\n",
      "        }, txnOptions);\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "As you can see, Iâ€™m using an auto-closeable try-with-resources which will automatically close the client session at the end. This helps me to keep the code clean and simple.\n",
      "\n",
      "Some of you may argue that it is actually too simple because transactions (and write operations, in general) can throw exceptions, and Iâ€™m not handling any of them hereâ€¦ You are absolutely right and this is an excellent transition to the next part of this article.\n",
      "\n",
      "## Exception management\n",
      "\n",
      "Transactions in MongoDB can raise exceptions for various reasons, and I donâ€™t want to go into the details too much here, but since MongoDB 3.6, any write operation that fails can be automatically retried once. And the transactions are no different. See the documentation for retryWrites.\n",
      "\n",
      "If retryable writes are disabled or if a write operation fails twice, then MongoDB will send a MongoException (extends RuntimeException) which should be handled properly.\n",
      "\n",
      "The important section here is the MongoDB configuration, of course. Firstly, you will notice the connection string is automatically retrieved from the `application.properties` file, and secondly, you will notice the configuration of the `MongoClient` bean.\n",
      "\n",
      "A `Codec` is the interface that abstracts the processes of decoding a BSON value into a Java object and encoding a Java object into a BSON value.\n",
      "\n",
      "A `CodecRegistry` contains a set of `Codec` instances that are accessed according to the Java classes that they encode from and decode to.\n",
      "\n",
      "The MongoDB driver is capable of encoding and decoding BSON for us, so we do not have to take care of this anymore. All the configuration we need for this project to run is here and nowhere else.\n",
      "\n",
      "You can read [the driver documentation if you want to know more about this topic.\n",
      "\n",
      "## Multi-document ACID transactions\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "Luckily, Spring provides the annotation `ExceptionHandler` to help us do that. See the code in my controller `PersonController`. Of course, you will need to adapt and enhance this in your real project, but you have the main idea here.\n",
      "\n",
      "```java\n",
      "@ExceptionHandler(RuntimeException.class)\n",
      "public final ResponseEntity handleAllExceptions(RuntimeException e) {\n",
      "    logger.error(\"Internal server error.\", e);\n",
      "    return new ResponseEntity<>(e, HttpStatus.INTERNAL_SERVER_ERROR);\n",
      "}\n",
      "```\n",
      "\n",
      "## Aggregation pipeline\n",
      "\n",
      "MongoDB's aggregation pipeline is a very powerful and efficient way to run your complex queries as close as possible to your data for maximum efficiency. Using it can ease the computational load on your application.\n",
      "\n",
      "Just to give you a small example, I implemented the `/api/persons/averageAge` route to show you how I can retrieve the average age of the persons in my collection.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Let me search for more comprehensive information about MongoDB operational best practices.\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01Cp1zpvF4H5167hdzSCgsuB)\n",
      " Call ID: toolu_bdrk_01Cp1zpvF4H5167hdzSCgsuB\n",
      "  Args:\n",
      "    user_query: MongoDB operational best practices configuration maintenance monitoring\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "# Administration\n",
      "\n",
      "The administration documentation addresses the ongoing operation and maintenance of MongoDB instances and deployments. This documentation includes both high level overviews of these concerns as well as tutorials that cover specific procedures and processes for operating MongoDB.\n",
      "\n",
      "You can view the FTDC source code on the MongoDB Github Repository. The `ftdc_system_stats_*.ccp` files specifically define any system-specific diagnostic data captured.\n",
      "\n",
      "FTDC runs with the following defaults:\n",
      "\n",
      "- Data capture every 1 second\n",
      "\n",
      "- 200MB maximum `diagnostic.data` folder size.\n",
      "\n",
      "These defaults are designed to provide useful data to MongoDB engineers with minimal impact on performance or storage size. These values only require modifications if requested by MongoDB engineers for specific diagnostic purposes.\n",
      "\n",
      "To disable FTDC, start up the `mongod` or `mongos` with the `diagnosticDataCollectionEnabled: false` option in the `setParameter` settings of your configuration file:\n",
      "\n",
      "```yaml\n",
      "setParameter:\n",
      "  diagnosticDataCollectionEnabled: false\n",
      "```\n",
      "\n",
      "Disabling FTDC may increase the time or resources required when analyzing or debugging issues with support from MongoDB engineers. For information on MongoDB Support, visit Get Started With MongoDB Support.\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "Configure the alert settings to send an alert if these metrics drop below 30 for at least a few minutes. You want to avoid false positives triggered by relatively harmless short-term drops, but catch issues when these metrics stay low for a while.\n",
      "\n",
      "To configure these alert conditions, see Configure Alert Settings.\n",
      "\n",
      "### Queues\n",
      "\n",
      "Configure the alert settings to send an alert if these metrics rise above 100 for a minute. You want to avoid false positives triggered by relatively harmless short-term spikes, but catch issues when these metrics stay elevated for a while.\n",
      "\n",
      "To configure these alert conditions, see Configure Alert Settings.\n",
      "\n",
      "### CPU Steal\n",
      "\n",
      "Configure the alert settings to send an alert if this metric rises above 10%.\n",
      "\n",
      "To configure this alert condition, see Configure Alert Settings.\n",
      "\n",
      "### Query Targeting\n",
      "\n",
      "Configure the alert settings to send an alert if this metric rises above 50 or 100.\n",
      "\n",
      "To configure these alert conditions, see Configure Alert Settings.\n",
      "\n",
      "### Connection Limits\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the MongoDB documentation, here are the **best practices for MongoDB Operations**:\n",
      "\n",
      "## Configuration and Maintenance\n",
      "\n",
      "### 1. **Routine Management Operations**\n",
      "- Regularly update your MongoDB deployment's configuration\n",
      "- Upgrade deployments to different patch releases within the same major release series\n",
      "- Properly start, configure, and manage running `mongod` processes\n",
      "\n",
      "### 2. **Process Management**\n",
      "- Stop in-progress MongoDB client operations using:\n",
      "  - `db.killOp()` for killing specific operations\n",
      "  - `maxTimeMS()` for setting operation timeouts\n",
      "- Archive current log files and start new ones regularly\n",
      "\n",
      "### 3. **Full Time Diagnostic Data Capture (FTDC)**\n",
      "FTDC runs with recommended defaults:\n",
      "- **Data capture**: Every 1 second\n",
      "- **Maximum folder size**: 200MB for `diagnostic.data` folder\n",
      "\n",
      "**Note**: Only disable FTDC if absolutely necessary, as it helps MongoDB engineers diagnose issues with minimal performance impact.\n",
      "\n",
      "### 4. **Monitoring Best Practices**\n",
      "\n",
      "Configure alerts for key metrics:\n",
      "\n",
      "- **Connections**: Alert if metrics drop below 30 for several minutes\n",
      "- **Queues**: Alert if metrics rise above 100 for a minute\n",
      "- **CPU Steal**: Alert if this rises above 10%\n",
      "- **Query Targeting**: Alert if this rises above 50 or 100\n",
      "\n",
      "### 5. **Exception Management**\n",
      "- Handle `MongoException` properly in write operations\n",
      "- Enable **retryable writes** (available since MongoDB 3.6) - failed write operations can be automatically retried once\n",
      "- Implement proper exception handling in your application code\n",
      "\n",
      "### 6. **Transaction Best Practices**\n",
      "When using multi-document ACID transactions:\n",
      "- Use appropriate transaction options (read preference, read concern, write concern)\n",
      "- Use auto-closeable sessions (try-with-resources pattern)\n",
      "- Handle transaction exceptions appropriately\n",
      "\n",
      "Would you like more detailed information about any specific aspect of MongoDB operations?\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST 3: Technical question - Agent should use memory context\n",
    "# =============================================================================\n",
    "\n",
    "run_agent_with_memory(\n",
    "    thread_id=\"session-023\",\n",
    "    user_id=\"user-123\",\n",
    "    user_input=\"I am looking for the best practices for MongoDB Operations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: Different User (Memory Isolation)\n",
    "\n",
    "Test with a different user to verify memory isolation.\n",
    "This user should NOT see user-123's memories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Thread: session-0044 | User: user-456\n",
      "Input:  I'm a Data Engineer. Tell me about  MongoDB Atlas scaling.\n",
      "============================================================\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      " I'm a Data Engineer. Tell me about  MongoDB Atlas scaling.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_memory (toolu_bdrk_01KMfcvRPA3EcacTvyHbFYKP)\n",
      " Call ID: toolu_bdrk_01KMfcvRPA3EcacTvyHbFYKP\n",
      "  Args:\n",
      "    query: Data Engineer role preferences\n",
      "  manage_memory (toolu_bdrk_0122qcz8Qf9R4pS2ZvJ5JWjp)\n",
      " Call ID: toolu_bdrk_0122qcz8Qf9R4pS2ZvJ5JWjp\n",
      "  Args:\n",
      "    action: create\n",
      "    content: User is a Data Engineer\n",
      "  get_information_for_question_answering (toolu_bdrk_018cSb9juj9Uv5FcbRcs3sw1)\n",
      " Call ID: toolu_bdrk_018cSb9juj9Uv5FcbRcs3sw1\n",
      "  Args:\n",
      "    user_query: MongoDB Atlas scaling\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Percentage of used disk space on a partition reaches a specified threshold.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Query Targeting Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Indicates inefficient queries.\n",
      "\n",
      "The change streams cursors that the Atlas Search process (`mongot`) uses to keep Atlas Search indexes updated can contribute to the query targeting ratio and trigger query targeting alerts if the ratio is high.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Replica Set Has No Primary\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "No primary is detected in replica set.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Replication Oplog Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Amount of oplog data generated on a primary cluster member is larger than the cluster's configured oplog size.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "System CPU Usage Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "CPU usage of the MongoDB process reaches a specified threshold.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "</table>\n",
      "\n",
      "You can view these metrics on the Query Targeting chart, accessed through cluster monitoring.\n",
      "\n",
      "To learn more, see the Query Targeting alert conditions.\n",
      "\n",
      "### Connection Limits\n",
      "\n",
      "Each Atlas instance has a connection limit. These alert conditions help you proactively address scaling needs or potential issues related to connection availability.\n",
      "\n",
      "You can view these metrics on the Connections chart, accessed through cluster monitoring.\n",
      "\n",
      "To learn more, see the Connection alert conditions.\n",
      "\n",
      "## Configure Alerts\n",
      "\n",
      "To set which conditions trigger alerts and how users are notified, Configure Alert Settings. You can configure alerts at the organization or project level. Atlas provides default alerts at the project level. You can clone existing alerts and configure maintenance window alerts.\n",
      "\n",
      "Experiment with alert condition values based on your specific requirements. Periodically reassess these values for optimal performance.\n",
      "\n",
      "### Tickets Available\n",
      "\n",
      "<Tab name=\"Project Alerts\">\n",
      "\n",
      "You can retrieve events for a project using the get all API (Application Programming Interface) resource.\n",
      "\n",
      "</Tab>\n",
      "\n",
      "</Tabs>\n",
      "\n",
      "## Resolutions for Specific Alerts\n",
      "\n",
      "The following sections describe Atlas\n",
      "alert conditions and suggest steps for resolving them.\n",
      "\n",
      "<table>\n",
      "<tr>\n",
      "<th id=\"Alert%20Type\">\n",
      "Alert Type\n",
      "\n",
      "</th>\n",
      "<th id=\"Description\">\n",
      "Description\n",
      "\n",
      "</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Atlas Search Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Amount of CPU and memory used by Atlas Search processes reach a specified threshold.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Connection Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Number of connections to a MongoDB process exceeds the allowable maximum.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Disk Space % Used Alerts\n",
      "\n",
      "# Create a MongoDB Deployment\n",
      "\n",
      "You can create a free tier MongoDB deployment on MongoDB Atlas to store and manage your data. MongoDB Atlas hosts and manages your MongoDB database in the cloud.\n",
      "\n",
      "## Create a Free MongoDB deployment on Atlas\n",
      "\n",
      "Complete the Get Started with Atlas guide to set up a new Atlas account and load sample data into a new free tier MongoDB deployment.\n",
      "\n",
      "## Save your Credentials\n",
      "\n",
      "After you create your database user, save that user's username and password to a safe location for use in an upcoming step.\n",
      "\n",
      "After you complete these steps, you have a new free tier MongoDB deployment on Atlas, database user credentials, and sample data loaded in your database.\n",
      "\n",
      "If you run into issues on this step, ask for help in the MongoDB Community Forums or submit feedback by using the Rate this page tab on the right or bottom right side of this page.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've saved that you're a Data Engineer to memory!\n",
      "\n",
      "Let me get you more specific information about MongoDB Atlas scaling options:\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_019nFrF2hPwk3PxtXETAjGL8)\n",
      " Call ID: toolu_bdrk_019nFrF2hPwk3PxtXETAjGL8\n",
      "  Args:\n",
      "    user_query: MongoDB Atlas cluster scaling vertical horizontal auto-scaling\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Percentage of used disk space on a partition reaches a specified threshold.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Query Targeting Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Indicates inefficient queries.\n",
      "\n",
      "The change streams cursors that the Atlas Search process (`mongot`) uses to keep Atlas Search indexes updated can contribute to the query targeting ratio and trigger query targeting alerts if the ratio is high.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Replica Set Has No Primary\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "No primary is detected in replica set.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Replication Oplog Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Amount of oplog data generated on a primary cluster member is larger than the cluster's configured oplog size.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "System CPU Usage Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "CPU usage of the MongoDB process reaches a specified threshold.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "</table>\n",
      "\n",
      "<Tab name=\"Project Alerts\">\n",
      "\n",
      "You can retrieve events for a project using the get all API (Application Programming Interface) resource.\n",
      "\n",
      "</Tab>\n",
      "\n",
      "</Tabs>\n",
      "\n",
      "## Resolutions for Specific Alerts\n",
      "\n",
      "The following sections describe Atlas\n",
      "alert conditions and suggest steps for resolving them.\n",
      "\n",
      "<table>\n",
      "<tr>\n",
      "<th id=\"Alert%20Type\">\n",
      "Alert Type\n",
      "\n",
      "</th>\n",
      "<th id=\"Description\">\n",
      "Description\n",
      "\n",
      "</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Atlas Search Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Amount of CPU and memory used by Atlas Search processes reach a specified threshold.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Connection Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Number of connections to a MongoDB process exceeds the allowable maximum.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Disk Space % Used Alerts\n",
      "\n",
      "You can view these metrics on the Query Targeting chart, accessed through cluster monitoring.\n",
      "\n",
      "To learn more, see the Query Targeting alert conditions.\n",
      "\n",
      "### Connection Limits\n",
      "\n",
      "Each Atlas instance has a connection limit. These alert conditions help you proactively address scaling needs or potential issues related to connection availability.\n",
      "\n",
      "You can view these metrics on the Connections chart, accessed through cluster monitoring.\n",
      "\n",
      "To learn more, see the Connection alert conditions.\n",
      "\n",
      "## Configure Alerts\n",
      "\n",
      "To set which conditions trigger alerts and how users are notified, Configure Alert Settings. You can configure alerts at the organization or project level. Atlas provides default alerts at the project level. You can clone existing alerts and configure maintenance window alerts.\n",
      "\n",
      "Experiment with alert condition values based on your specific requirements. Periodically reassess these values for optimal performance.\n",
      "\n",
      "### Tickets Available\n",
      "\n",
      "When you configure alerts, you specify alert conditions and thresholds. Review the possible alert conditions for which you can trigger alerts related to your clusters.\n",
      "\n",
      "`M0` free clusters and `M2/M5` shared clusters only trigger alerts related to the metrics supported by those clusters. See Atlas M0 (Free Cluster), M2, and M5 Limits for complete documentation on `M0/M2/M5` alert and metric limitations.\n",
      "\n",
      "Consistently monitor metrics to help ensure efficient clusters.\n",
      "\n",
      "### Tickets Available\n",
      "\n",
      "These alert conditions help you monitor the number of concurrent read or write operations that can occur. When all tickets are claimed, operations must wait and enter the queue.\n",
      "\n",
      "You can view these metrics on the Tickets Available chart, accessed through cluster monitoring.\n",
      "\n",
      "To learn more, see the Tickets Available alert conditions.\n",
      "\n",
      "### Queues\n",
      "\n",
      "These alert conditions measure operations waiting on locks.\n",
      "\n",
      "You can view these metrics on the Queues chart, accessed through cluster monitoring.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the MongoDB Atlas documentation, here's what you need to know about **MongoDB Atlas scaling** as a Data Engineer:\n",
      "\n",
      "## Key Scaling Considerations\n",
      "\n",
      "### **Monitoring & Alerts for Scaling Decisions**\n",
      "\n",
      "Atlas provides several alert types that help you identify when scaling is needed:\n",
      "\n",
      "1. **System CPU Usage Alerts** - Triggers when CPU usage of the MongoDB process reaches a specified threshold\n",
      "2. **Disk Space % Used Alerts** - Alerts when disk space on a partition reaches a threshold\n",
      "3. **Connection Alerts** - Notifies when connections exceed the allowable maximum (each Atlas instance has connection limits)\n",
      "4. **Tickets Available Alerts** - Monitors concurrent read/write operations capacity\n",
      "5. **Query Targeting Alerts** - Indicates inefficient queries that may require optimization or scaling\n",
      "\n",
      "### **Proactive Scaling Approach**\n",
      "\n",
      "- **Connection Limits**: Each Atlas instance has specific connection limits. Connection alerts help you proactively address scaling needs before hitting capacity\n",
      "- **Performance Metrics**: You can monitor metrics through cluster monitoring charts including:\n",
      "  - Connections chart\n",
      "  - Query Targeting chart\n",
      "  - Tickets Available chart\n",
      "  - Queues chart (for operations waiting on locks)\n",
      "\n",
      "### **Alert Configuration**\n",
      "\n",
      "- Configure alerts at the organization or project level\n",
      "- Atlas provides default alerts at the project level\n",
      "- You can experiment with alert condition values and periodically reassess them for optimal performance\n",
      "- Alerts can be configured for maintenance windows\n",
      "\n",
      "**Note**: M0 (free), M2, and M5 shared clusters have limitations on which alerts and metrics are supported.\n",
      "\n",
      "Would you like more specific information about auto-scaling features, cluster tier options, or scaling strategies for production workloads?\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST 4: Different user - Should NOT have user-123's memories\n",
    "# =============================================================================\n",
    "\n",
    "run_agent_with_memory(\n",
    "    thread_id=\"session-0044\",\n",
    "    user_id=\"user-456\",  # DIFFERENT user\n",
    "    user_input=\" I'm a Data Engineer. Tell me about  MongoDB Atlas scaling.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Thread: session-0044 | User: user-456\n",
      "Input:  I'm a DBA  also interested in MongoDB Atlas functions.\n",
      "============================================================\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      " I'm a DBA  also interested in MongoDB Atlas functions.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  manage_memory (toolu_bdrk_01CTYL9Utuo5gKnRAMwjanmG)\n",
      " Call ID: toolu_bdrk_01CTYL9Utuo5gKnRAMwjanmG\n",
      "  Args:\n",
      "    action: create\n",
      "    content: User is also a DBA (Database Administrator) in addition to being a Data Engineer\n",
      "  get_information_for_question_answering (toolu_bdrk_01NFw1pgJUrCiuFbv5XTqXax)\n",
      " Call ID: toolu_bdrk_01NFw1pgJUrCiuFbv5XTqXax\n",
      "  Args:\n",
      "    user_query: MongoDB Atlas Functions\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "// Access the _id of the changed document:\n",
      "  const docId = changeEvent.documentKey._id;\n",
      "  const doc= changeEvent.fullDocument;\n",
      "  \n",
      "\n",
      "  // Get the MongoDB service you want to use (see \"Linked Data Sources\" tab)\n",
      "  const serviceName = \"mongodb-atlas\";\n",
      "  const databaseName = \"sample_airbnb\";\n",
      "  const collection = context.services.get(serviceName).db(databaseName).collection(changeEvent.ns.coll);\n",
      "\n",
      " // This function is the endpoint's request handler. \n",
      "    // URL to make the request to the OpenAI API.\n",
      "    const url = 'https://api.openai.com/v1/chat/completions';\n",
      "\n",
      "    // Fetch the OpenAI key stored in the context values.\n",
      "    const openai_key = context.values.get(\"openAIKey\");\n",
      "\n",
      "    const reviews = doc.reviews.map((review) => {return {\"comments\" : review.comments}});\n",
      "    \n",
      "    const sampledReviews= sampleReviews(reviews);\n",
      "\n",
      "### Main trigger logic\n",
      "\n",
      "The main trigger logic is invoked when an update change event is detected with a `\"process\" : false` field.\n",
      "```javascript\n",
      "exports = async function(changeEvent) {\n",
      "  // A Database Trigger will always call a function with a changeEvent.\n",
      "  // Documentation on ChangeEvents: https://www.mongodb.com/docs/manual/reference/change-events\n",
      "\n",
      "  // This sample function will listen for events and replicate them to a collection in a different Database\n",
      "function sampleReviews(reviews) {\n",
      "// Logic above...\n",
      "   if (reviews.length <= 50) {\n",
      "        return reviews;\n",
      "    }\n",
      "    const sampledReviews = [];\n",
      "    const seenIndices = new Set();\n",
      "\n",
      "    while (sampledReviews.length < 50) {\n",
      "        const randomIndex = Math.floor(Math.random() * reviews.length);\n",
      "        if (!seenIndices.has(randomIndex)) {\n",
      "            seenIndices.add(randomIndex);\n",
      "            sampledReviews.push(reviews[randomIndex]);\n",
      "        }\n",
      "    }\n",
      "\n",
      "    return sampledReviews;\n",
      "}\n",
      "\n",
      "const code = responseData.choices[0].message.content;\n",
      "        // Get the required data to be added into the document\n",
      "        const updateDoc = JSON.parse(code)\n",
      "        // Set a flag that this document does not need further re-processing \n",
      "        updateDoc.process = true\n",
      "        await collection.updateOne({_id : docId}, {$set : updateDoc});\n",
      "      \n",
      "\n",
      "    } else {\n",
      "        console.error(\"Failed to generate filter JSON.\");\n",
      "        console.log(JSON.stringify(responseData));\n",
      "        return {};\n",
      "    }\n",
      "};\n",
      "```\n",
      "\n",
      "Key steps include:\n",
      "\n",
      "// Call OpenAI API to get the response.\n",
      "    \n",
      "    let resp = await context.http.post({\n",
      "        url: url,\n",
      "        headers: {\n",
      "            'Authorization': [`Bearer ${openai_key}`],\n",
      "            'Content-Type': ['application/json']\n",
      "        },\n",
      "        body: JSON.stringify({\n",
      "            model: \"gpt-4\",\n",
      "            temperature: 0,\n",
      "            messages: [\n",
      "                {\n",
      "                    \"role\": \"system\",\n",
      "                    \"content\": \"Output json generator follow only provided example on the current reviews\"\n",
      "                },\n",
      "                {\n",
      "                    \"role\": \"user\",\n",
      "                    \"content\": reqString\n",
      "                }\n",
      "            ]\n",
      "        })\n",
      "    });\n",
      "\n",
      "    // Parse the JSON response\n",
      "    let responseData = JSON.parse(resp.body.text());\n",
      "\n",
      "    // Check the response status.\n",
      "    if(resp.statusCode === 200) {\n",
      "        console.log(\"Successfully received code.\");\n",
      "        console.log(JSON.stringify(responseData));\n",
      "\n",
      "```javascript\n",
      "\"reviews\":  { \"_id\": \"2663437\", \n",
      "\"date\": { \"$date\": \"2012-10-20T04:00:00.000Z\" }, \\\n",
      "\"listing_id\": \"664017\",\n",
      " \"reviewer_id\": \"633940\", \n",
      "\"reviewer_name\": \"Patricia\", \n",
      "\"comments\": \"I booked the room at Marinete's apartment for my husband. He was staying in Rio for a week because he was studying Portuguese. He loved the place. Marinete was very helpfull, the room was nice and clean. \\r\\nThe location is perfect. He loved the time there. \\r\\n\\r\\n\" },\n",
      " { \"_id\": \"2741592\", \n",
      "\"date\": { \"$date\": \"2012-10-28T04:00:00.000Z\" }, \n",
      "\"listing_id\": \"664017\",\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great! I've updated my memory to note you're also a DBA. Let me get you more comprehensive information about Atlas Functions:\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01JeTK3dGBHDw8tPS9PQvogX)\n",
      " Call ID: toolu_bdrk_01JeTK3dGBHDw8tPS9PQvogX\n",
      "  Args:\n",
      "    user_query: Atlas Functions create deploy triggers HTTP endpoints authentication\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "## Prerequisites\n",
      "- App Services application (e.g., application-0). Ensure linkage to the cluster with the Airbnb data.\n",
      "- OpenAI account with API access. \n",
      "\n",
      "![Open AI Key\n",
      "\n",
      "### Secrets and Values\n",
      "\n",
      "1. Navigate to your App Services application.\n",
      "2. Under \"Values,\" create a secret named `openAIKey` with your OPEN AI API key.\n",
      "\n",
      "3. Create a linked value named OpenAIKey and link to the secret.\n",
      "\n",
      "## The trigger code\n",
      "\n",
      "The provided trigger listens for changes in the sample_airbnb.listingsAndReviews collection. Upon detecting a new review, it samples up to 50 reviews, sends them to OpenAI's API for summarization, and updates the original document with the summarized content and tags.\n",
      "\n",
      "Please notice that the trigger reacts to updates that were marked with `\"process\" : false` flag. This field indicates that there were no summary created for this batch of reviews yet.\n",
      "\n",
      "// Call OpenAI API to get the response.\n",
      "    \n",
      "    let resp = await context.http.post({\n",
      "        url: url,\n",
      "        headers: {\n",
      "            'Authorization': [`Bearer ${openai_key}`],\n",
      "            'Content-Type': ['application/json']\n",
      "        },\n",
      "        body: JSON.stringify({\n",
      "            model: \"gpt-4\",\n",
      "            temperature: 0,\n",
      "            messages: [\n",
      "                {\n",
      "                    \"role\": \"system\",\n",
      "                    \"content\": \"Output json generator follow only provided example on the current reviews\"\n",
      "                },\n",
      "                {\n",
      "                    \"role\": \"user\",\n",
      "                    \"content\": reqString\n",
      "                }\n",
      "            ]\n",
      "        })\n",
      "    });\n",
      "\n",
      "    // Parse the JSON response\n",
      "    let responseData = JSON.parse(resp.body.text());\n",
      "\n",
      "    // Check the response status.\n",
      "    if(resp.statusCode === 200) {\n",
      "        console.log(\"Successfully received code.\");\n",
      "        console.log(JSON.stringify(responseData));\n",
      "\n",
      "// Access the _id of the changed document:\n",
      "  const docId = changeEvent.documentKey._id;\n",
      "  const doc= changeEvent.fullDocument;\n",
      "  \n",
      "\n",
      "  // Get the MongoDB service you want to use (see \"Linked Data Sources\" tab)\n",
      "  const serviceName = \"mongodb-atlas\";\n",
      "  const databaseName = \"sample_airbnb\";\n",
      "  const collection = context.services.get(serviceName).db(databaseName).collection(changeEvent.ns.coll);\n",
      "\n",
      " // This function is the endpoint's request handler. \n",
      "    // URL to make the request to the OpenAI API.\n",
      "    const url = 'https://api.openai.com/v1/chat/completions';\n",
      "\n",
      "    // Fetch the OpenAI key stored in the context values.\n",
      "    const openai_key = context.values.get(\"openAIKey\");\n",
      "\n",
      "    const reviews = doc.reviews.map((review) => {return {\"comments\" : review.comments}});\n",
      "    \n",
      "    const sampledReviews= sampleReviews(reviews);\n",
      "\n",
      "If authentication requests occur during a period when logs are not collected, they will not appear in the database access history.\n",
      "\n",
      "## Required Access\n",
      "\n",
      "To view database access history, you must have `Project Owner` or `Organization Owner` access to Atlas.\n",
      "\n",
      "## Procedure\n",
      "\n",
      "<Tabs>\n",
      "\n",
      "<Tab name=\"Atlas CLI\">\n",
      "\n",
      "To return the access logs for a cluster using the Atlas CLI, run the following command:\n",
      "\n",
      "```sh\n",
      "\n",
      "atlas accessLogs list [options]\n",
      "\n",
      "```\n",
      "\n",
      "To learn more about the command syntax and parameters, see the Atlas CLI documentation for atlas accessLogs list.\n",
      "\n",
      "- Install the Atlas CLI\n",
      "\n",
      "- Connect to the Atlas CLI\n",
      "\n",
      "</Tab>\n",
      "\n",
      "<Tab name=\"Atlas Administration API\">\n",
      "\n",
      "To view the database access history using the API, see Access Tracking.\n",
      "\n",
      "</Tab>\n",
      "\n",
      "<Tab name=\"Atlas UI\">\n",
      "\n",
      "Use the following procedure to view your database access history using the Atlas UI:\n",
      "\n",
      "- API request preparation: Reviews from the changed document are sampled and prepared into a request string for the OpenAI API. The format and instructions are tailored to ensure the API returns a valid JSON with summarized content and tags.\n",
      "- API interaction: Using the context.http.post method, the trigger sends the prepared data to the OpenAI API.\n",
      "- Updating the original document: Upon a successful response from the API, the trigger updates the original document with the summarized content, negative tags (neg_tags), positive tags (pos_tags), and a process flag set to true.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Perfect! As a DBA and Data Engineer, here's what you need to know about **MongoDB Atlas Functions**:\n",
      "\n",
      "## Overview\n",
      "\n",
      "Atlas Functions are serverless JavaScript functions that run in the context of an App Services application. They're particularly useful for automating database operations and integrating with external services.\n",
      "\n",
      "## Key Capabilities\n",
      "\n",
      "### **1. Database Triggers**\n",
      "Functions can be triggered by database change events:\n",
      "- **Change Event Handling**: Functions receive `changeEvent` objects when documents are inserted, updated, or deleted\n",
      "- **Access Document Data**: You can access the changed document's `_id` via `changeEvent.documentKey._id` and full document via `changeEvent.fullDocument`\n",
      "- **Collection Operations**: Functions can perform CRUD operations on collections\n",
      "\n",
      "**Example Use Case**: Automatically process new reviews, generate summaries, or update related documents\n",
      "\n",
      "### **2. Data Source Integration**\n",
      "```javascript\n",
      "// Access MongoDB Atlas from within a function\n",
      "const serviceName = \"mongodb-atlas\";\n",
      "const databaseName = \"sample_airbnb\";\n",
      "const collection = context.services.get(serviceName)\n",
      "  .db(databaseName)\n",
      "  .collection(changeEvent.ns.coll);\n",
      "```\n",
      "\n",
      "### **3. HTTP Endpoints**\n",
      "- Functions can act as **HTTP endpoint handlers**\n",
      "- Make external API calls using `context.http.post()` or other HTTP methods\n",
      "- Integrate with third-party services (e.g., OpenAI, payment processors, notification services)\n",
      "\n",
      "**Example**:\n",
      "```javascript\n",
      "let resp = await context.http.post({\n",
      "    url: url,\n",
      "    headers: {\n",
      "        'Authorization': [`Bearer ${api_key}`],\n",
      "        'Content-Type': ['application/json']\n",
      "    },\n",
      "    body: JSON.stringify({...})\n",
      "});\n",
      "```\n",
      "\n",
      "### **4. Secrets and Values Management**\n",
      "- **Secrets**: Store sensitive data like API keys securely\n",
      "- **Values**: Create linked values that reference secrets\n",
      "- Access in functions: `context.values.get(\"secretName\")`\n",
      "\n",
      "**Setup**:\n",
      "1. Navigate to App Services application\n",
      "2. Under \"Values,\" create a secret (e.g., `openAIKey`)\n",
      "3. Create a linked value to reference the secret\n",
      "\n",
      "### **5. Authentication & Access Control**\n",
      "- Functions respect MongoDB authentication and authorization\n",
      "- Access logs track database access history\n",
      "- Requires `Project Owner` or `Organization Owner` access to view logs\n",
      "- Can view access logs via Atlas UI, Atlas CLI, or Administration API\n",
      "\n",
      "## Prerequisites for Using Atlas Functions\n",
      "\n",
      "1. **App Services Application**: Must be created and linked to your Atlas cluster\n",
      "2. **Linked Data Sources**: Connect your MongoDB Atlas cluster to the App Services app\n",
      "3. **Proper Permissions**: Appropriate access levels for deployment and monitoring\n",
      "\n",
      "## Common DBA Use Cases\n",
      "\n",
      "- **Automated Data Processing**: Process incoming data, validate, transform, or enrich documents\n",
      "- **Event-Driven Workflows**: Trigger actions based on database changes\n",
      "- **External Integrations**: Connect to APIs, webhooks, or third-party services\n",
      "- **Data Validation**: Implement custom validation logic beyond schema validation\n",
      "- **Audit Logging**: Track and log specific database operations\n",
      "- **Scheduled Jobs**: Automate maintenance tasks or data cleanup\n",
      "\n",
      "## Monitoring & Debugging\n",
      "\n",
      "- Functions provide console logging: `console.log()` and `console.error()`\n",
      "- Access logs available through Atlas CLI: `atlas accessLogs list`\n",
      "- Database access history tracking for security and compliance\n",
      "\n",
      "Would you like more details on creating specific types of triggers, HTTP endpoints, or best practices for function deployment and monitoring?\n"
     ]
    }
   ],
   "source": [
    "run_agent_with_memory(\n",
    "     thread_id=\"session-0044\",\n",
    "    user_id=\"user-456\",  # DIFFERENT user\n",
    "    user_input=\" I'm a DBA  also interested in MongoDB Atlas functions.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ALL STORED MEMORIES IN MONGODB\n",
      "============================================================\n",
      "\n",
      "Total memories: 3\n",
      "\n",
      "--- Memory 1 ---\n",
      "Namespace: ['memories', 'user-104']\n",
      "Key: 9d811dbe-e2af-42c9-8732-8ab6ee7ce103\n",
      "Content: User is a senior DBA (Database Administrator) with a focus on disaster recovery and backup strategies\n",
      "\n",
      "--- Memory 2 ---\n",
      "Namespace: ['memories', 'user-456']\n",
      "Key: 7c5be609-c32c-44b5-909e-eb4339fb4728\n",
      "Content: User is a cloud architect with interest in MongoDB Atlas scaling\n",
      "\n",
      "--- Memory 3 ---\n",
      "Namespace: ['memories', 'user-456']\n",
      "Key: eddfd6b8-09b7-4b52-aa29-abb7cb21c540\n",
      "Content: User is interested in Oracle-related technologies and Java programming\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VIEW ALL STORED MEMORIES\n",
    "# =============================================================================\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ALL STORED MEMORIES IN MONGODB\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_memories = list(memory_collection.find({}))\n",
    "print(f\"\\nTotal memories: {len(all_memories)}\\n\")\n",
    "\n",
    "for i, doc in enumerate(all_memories, 1):\n",
    "    print(f\"--- Memory {i} ---\")\n",
    "    print(f\"Namespace: {doc.get('namespace', 'N/A')}\")\n",
    "    print(f\"Key: {doc.get('key', 'N/A')}\")\n",
    "    value = doc.get('value', {})\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"Content: {value.get('content', value)}\")\n",
    "    else:\n",
    "        print(f\"Value: {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run_agent_with_memory(\\n    thread_id=\"session-110000\",\\n    user_id=\"user-456\",  # DIFFERENT user\\n    user_input=\"Tell me about MongoDB backups based on my programming language expertise\"\\n)'"
      ]
     },
     "execution_count": 1277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''run_agent_with_memory(\n",
    "    thread_id=\"session-110000\",\n",
    "    user_id=\"user-456\",  # DIFFERENT user\n",
    "    user_input=\"Tell me about MongoDB backups based on my programming language expertise\"\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x= mongodb_client[\"checkpointing_db\"][\"checkpoints\"].drop()\n",
    "#x= mongodb_client[\"mongodb_genai_devday_agents\"][\"memories\"].drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmem import create_memory_store_manager\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLD_PATH_INSTRUCTIONS = \"\"\"You are a memory consolidation system. Your job is to MERGE and CLEAN UP memories.\n",
    "\n",
    "STRICT RULES:\n",
    "1. MAXIMUM 1 memory per user - never more\n",
    "2. You MUST DELETE all old memories after merging them\n",
    "3. Create ONE new consolidated memory with ALL information\n",
    "\n",
    "REQUIRED ACTIONS:\n",
    "1. READ all existing memories\n",
    "2. MERGE all information into ONE comprehensive memory  \n",
    "3. DELETE every old memory (use the delete/remove function)\n",
    "4. SAVE the single merged memory\n",
    "\n",
    "FORMAT for the single memory:\n",
    "\"User Profile: [role] at [company]. Works with [technologies]. Preferences: [preferences]. Interests: [interests].\"\n",
    "\n",
    "CRITICAL: If you see 3 existing memories, your output should be:\n",
    "- DELETE mem-001\n",
    "- DELETE mem-002  \n",
    "- DELETE mem-003\n",
    "- CREATE one consolidated memory\n",
    "\n",
    "DO NOT just add a new memory. You MUST delete the old ones.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… CORRECT - create_memory_store_manager has full storage integration\n",
    "memory_store_manager = create_memory_store_manager(\n",
    "    llm,\n",
    "    namespace=(\"memories\", \"{langgraph_user_id}\"),  # âœ… Valid\n",
    "    store=memory_store,                              # âœ… Valid\n",
    "    instructions=COLD_PATH_INSTRUCTIONS,\n",
    "    enable_inserts=True,\n",
    "    enable_deletes=True,\n",
    "    query_model=llm,\n",
    "    query_limit=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "_current_conversation_messages = []\n",
    "_current_user_id = None\n",
    "\n",
    "@tool\n",
    "def queue_memory_consolidation(reason: str = \"conversation_ended\") -> str:\n",
    "    \"\"\"\n",
    "    Consolidate memories for the current user.\n",
    "    Call this tool when the user says goodbye.\n",
    "    \"\"\"\n",
    "    global _current_conversation_messages, _current_user_id\n",
    "    \n",
    "    if not _current_conversation_messages:\n",
    "        return \"No conversation messages to consolidate.\"\n",
    "    \n",
    "    if not _current_user_id:\n",
    "        return \"No user ID available for consolidation.\"\n",
    "    \n",
    "    config = {\"configurable\": {\"langgraph_user_id\": _current_user_id}}\n",
    "    \n",
    "    try:\n",
    "        # Synchronous call - no executor needed\n",
    "        result = memory_store_manager.invoke(\n",
    "            {\n",
    "                \"messages\": _current_conversation_messages,\n",
    "                \"max_steps\": 3\n",
    "            },\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        print(f\"ðŸ“ Consolidation complete for user: {_current_user_id}\")\n",
    "        print(f\"   Memories created/updated: {len(result)}\")\n",
    "        for r in result:\n",
    "            print(f\"   - {r['value']}\")\n",
    "        \n",
    "        return f\"Memory consolidation complete. Updated {len(result)} memories.\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Consolidation failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return f\"Failed: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tools updated. Total: 5\n",
      "   - get_information_for_question_answering\n",
      "   - get_page_content_for_summarization\n",
      "   - manage_memory\n",
      "   - search_memory\n",
      "   - queue_memory_consolidation\n"
     ]
    }
   ],
   "source": [
    "# ADD THE TOOL TO THE LIST - THIS WAS MISSING!\n",
    "tools = tools + [queue_memory_consolidation]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "print(f\"âœ… Tools updated. Total: {len(tools)}\")\n",
    "for t in tools:\n",
    "    print(f\"   - {t.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_aware_prompt_with_goodbye = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a helpful AI assistant with persistent memory capabilities.\n",
    "You can answer questions about MongoDB documentation using your tools.\n",
    "\n",
    "IMPORTANT MEMORY INSTRUCTIONS:\n",
    "1. When a user shares personal information (their role, expertise, preferences, interests),\n",
    "   ALWAYS use the manage_memory tool to save it immediately.\n",
    "2. At the start of conversations, use search_memory to check for relevant user context.\n",
    "3. Tailor your responses based on what you remember about the user.\n",
    "\n",
    "GOODBYE INSTRUCTION:\n",
    "When the user says goodbye, ends the conversation, or uses phrases like:\n",
    "- \"bye\", \"goodbye\", \"see you\", \"thanks bye\", \"that's all\", \"gotta go\", \"talk later\"\n",
    "Call the queue_memory_consolidation tool to consolidate their memories, then say a friendly goodbye.\n",
    "\n",
    "CRITICAL: Use only the information provided by tools to respond to user questions.\n",
    "\n",
    "## Tool Usage Guidelines\n",
    "- Do NOT call the same retrieval tool more than 2 times for a single user question\n",
    "- If consecutive searches return similar content, stop searching and synthesize what you have\n",
    "\n",
    "Available tools: {tool_names}\"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_aware_prompt_with_goodbye = memory_aware_prompt_with_goodbye.partial(\n",
    "    tool_names=\", \".join([tool.name for tool in tools])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Graph recompiled with LangMem cold path support\n"
     ]
    }
   ],
   "source": [
    "llm_with_tools = memory_aware_prompt_with_goodbye | llm.bind_tools(tools)\n",
    "\n",
    "# Recompile the graph\n",
    "app_with_memory = graph.compile(\n",
    "    checkpointer=checkpointer,\n",
    "    store=memory_store\n",
    ")\n",
    "\n",
    "print(\"âœ… Graph recompiled with LangMem cold path support\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent wrapper updated with cold path tracking\n"
     ]
    }
   ],
   "source": [
    "def run_agent_with_memory_and_coldpath(\n",
    "    thread_id: str,\n",
    "    user_id: str,\n",
    "    user_input: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Run the agent with memory support and cold path tracking.\n",
    "    \n",
    "    This wrapper:\n",
    "    1. Tracks conversation messages for cold path consolidation\n",
    "    2. Passes user_id for proper namespace scoping\n",
    "    3. Streams and displays the response\n",
    "    \"\"\"\n",
    "    global _current_conversation_messages, _current_user_id\n",
    "    \n",
    "    # Set current user for consolidation tool\n",
    "    _current_user_id = user_id\n",
    "    \n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id,\n",
    "            \"langgraph_user_id\": user_id\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    input_message = HumanMessage(content=user_input)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ðŸ§µ Thread: {thread_id}\")\n",
    "    print(f\"ðŸ‘¤ User: {user_id}\")\n",
    "    print(f\"ðŸ’¬ Input: {user_input}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Stream the response\n",
    "    final_response = None\n",
    "    for chunk in app_with_memory.stream(\n",
    "        {\"messages\": [input_message]},\n",
    "        config=config,\n",
    "        stream_mode=\"values\"\n",
    "    ):\n",
    "        if \"messages\" in chunk:\n",
    "            final_response = chunk[\"messages\"][-1]\n",
    "            # Track messages for cold path\n",
    "            _current_conversation_messages = chunk[\"messages\"]\n",
    "    \n",
    "    if final_response:\n",
    "        print(f\"\\nðŸ¤– Assistant: {final_response.content}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\\n\")\n",
    "\n",
    "\n",
    "print(\"âœ… Agent wrapper updated with cold path tracking\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Creating some memories...\n",
      "\n",
      "============================================================\n",
      "ðŸ§µ Thread: session-coldpath-test_1\n",
      "ðŸ‘¤ User: user-coldpath-dem\n",
      "ðŸ’¬ Input: Hi! I'm a senior data engineer at a fintech startup. I work mostly with MongoDB and Kafka.\n",
      "============================================================\n",
      "\n",
      "\n",
      "ðŸ¤– Assistant: Hello! Great to meet you! As a senior data engineer working with MongoDB and Kafka at a fintech startup, you're dealing with some powerful technologies for handling data pipelines and real-time data processing.\n",
      "\n",
      "I'm here to help you with any MongoDB-related questions you might have - whether it's about:\n",
      "- Performance optimization and indexing strategies\n",
      "- Data modeling for financial data\n",
      "- Aggregation pipelines\n",
      "- Replication and sharding\n",
      "- Integration patterns with Kafka\n",
      "- Or anything else MongoDB-related!\n",
      "\n",
      "What can I help you with today?\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: TEST - Create some memories first\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 1: Creating some memories...\")\n",
    "\n",
    "run_agent_with_memory_and_coldpath(\n",
    "    thread_id=\"session-coldpath-test_1\",\n",
    "    user_id=\"user-coldpath-dem\",\n",
    "    user_input=\"Hi! I'm a senior data engineer at a fintech startup. I work mostly with MongoDB and Kafka.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Adding more context...\n",
      "\n",
      "============================================================\n",
      "ðŸ§µ Thread: session-coldpath-test_1\n",
      "ðŸ‘¤ User: user-coldpath-dem\n",
      "ðŸ’¬ Input: I'm particularly interested in performance optimization and I prefer detailed technical explanations with code examples.\n",
      "============================================================\n",
      "\n",
      "\n",
      "ðŸ¤– Assistant: Perfect! I've noted that you're focused on performance optimization and prefer detailed technical explanations with code examples. That's exactly the kind of depth that's valuable for a senior data engineer working in fintech where performance and efficiency are critical.\n",
      "\n",
      "I can help you with detailed technical guidance on:\n",
      "\n",
      "- **Index optimization strategies** - compound indexes, covered queries, index intersection, ESR rule\n",
      "- **Query performance analysis** - using explain plans, execution stats, query profiling\n",
      "- **Aggregation pipeline optimization** - stage ordering, $match/$project placement, memory usage\n",
      "- **Schema design patterns** - for optimal read/write performance in your specific use cases\n",
      "- **Connection pooling and driver settings** - for high-throughput applications\n",
      "- **Write concern and read preference tuning** - balancing consistency and performance\n",
      "- **Monitoring and profiling** - identifying bottlenecks in production\n",
      "\n",
      "What specific performance optimization topic would you like to dive into? Or do you have a particular performance challenge you're currently facing?\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: TEST - Add more context\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 2: Adding more context...\")\n",
    "\n",
    "run_agent_with_memory_and_coldpath(\n",
    "    thread_id=\"session-coldpath-test_1\",\n",
    "    user_id=\"user-coldpath-dem\",\n",
    "    user_input=\"I'm particularly interested in performance optimization and I prefer detailed technical explanations with code examples.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for background consolidation to complete...\n",
      "\n",
      "ðŸ“‹ User memories after consolidation:\n",
      "==================================================\n",
      "\n",
      "--- Memory 1 ---\n",
      "Key: 27175401-5b74-4124-90b2-cae816447619\n",
      "Value: {'content': 'User is a senior data engineer at a fintech startup'}\n",
      "Score: 0.680\n",
      "\n",
      "--- Memory 2 ---\n",
      "Key: cca3f50b-8bad-444c-8bfe-9071e8b10640\n",
      "Value: {'content': 'User works primarily with MongoDB and Kafka'}\n",
      "Score: 0.677\n",
      "\n",
      "--- Memory 3 ---\n",
      "Key: 4f38e350-da7e-4b95-901f-d05c3d421546\n",
      "Value: {'content': 'User prefers detailed technical explanations with code examples'}\n",
      "Score: 0.663\n",
      "\n",
      "--- Memory 4 ---\n",
      "Key: e29b8dc5-77cf-41a2-a581-e84a79e7ac20\n",
      "Value: {'content': 'User is particularly interested in MongoDB performance optimization'}\n",
      "Score: 0.634\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: VERIFY - Check memories after consolidation\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "print(\"Waiting for background consolidation to complete...\")\n",
    "time.sleep(5)  # Give executor time to process\n",
    "\n",
    "# Check what's in the memory store for this user\n",
    "print(\"\\nðŸ“‹ User memories after consolidation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "namespace = (\"memories\", \"user-coldpath-dem\")\n",
    "\n",
    "# Search for all memories\n",
    "try:\n",
    "    results = list(memory_store.search(namespace, query=\"user profile expertise\", limit=10))\n",
    "    \n",
    "    if results:\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"\\n--- Memory {i} ---\")\n",
    "            print(f\"Key: {result.key}\")\n",
    "            print(f\"Value: {result.value}\")\n",
    "            if hasattr(result, 'score'):\n",
    "                print(f\"Score: {result.score:.3f}\")\n",
    "    else:\n",
    "        print(\"No memories found via search. Checking raw collection...\")\n",
    "        \n",
    "        # Fallback: check MongoDB directly\n",
    "        raw_memories = list(memory_collection.find({\"namespace\": list(namespace)}))\n",
    "        print(f\"Found {len(raw_memories)} memories in MongoDB:\")\n",
    "        for mem in raw_memories[:5]:\n",
    "            print(f\"  - {mem.get('key')}: {str(mem.get('value', {}))[:100]}...\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error searching memories: {e}\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Triggering cold path consolidation...\n",
      "\n",
      "============================================================\n",
      "ðŸ§µ Thread: session-coldpath-test_1\n",
      "ðŸ‘¤ User: user-coldpath-dem\n",
      "ðŸ’¬ Input: Thanks for your help! Goodbye!\n",
      "============================================================\n",
      "\n",
      "ðŸ“ Consolidation complete for user: user-coldpath-dem\n",
      "   Memories created/updated: 1\n",
      "   - {'kind': 'Memory', 'content': {'content': 'User Profile: Senior data engineer at a fintech startup. Works with MongoDB and Kafka. Preferences: Prefers detailed technical explanations with code examples. Interests: Particularly interested in MongoDB performance optimization.'}}\n",
      "\n",
      "ðŸ¤– Assistant: You're welcome! It was great meeting you. Feel free to come back anytime you need help with MongoDB performance optimization or any other technical questions. Good luck with your work at the fintech startup! Goodbye! ðŸ‘‹\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 10: TEST - Say goodbye to trigger consolidation\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 3: Triggering cold path consolidation...\")\n",
    "\n",
    "run_agent_with_memory_and_coldpath(\n",
    "    thread_id=\"session-coldpath-test_1\",\n",
    "    user_id=\"user-coldpath-dem\",\n",
    "    user_input=\"Thanks for your help! Goodbye!\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for background consolidation to complete...\n",
      "\n",
      "ðŸ“‹ User memories after consolidation:\n",
      "==================================================\n",
      "\n",
      "--- Memory 1 ---\n",
      "Key: e38df230-f0cd-4411-aa23-c6d7e7c18827\n",
      "Value: {'kind': 'Memory', 'content': {'content': 'User Profile: Senior data engineer at a fintech startup. Works with MongoDB and Kafka. Preferences: Prefers detailed technical explanations with code examples. Interests: Particularly interested in MongoDB performance optimization.'}}\n",
      "Score: 0.684\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: VERIFY - Check memories after consolidation\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "print(\"Waiting for background consolidation to complete...\")\n",
    "time.sleep(5)  # Give executor time to process\n",
    "\n",
    "# Check what's in the memory store for this user\n",
    "print(\"\\nðŸ“‹ User memories after consolidation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "namespace = (\"memories\", \"user-coldpath-dem\")\n",
    "\n",
    "# Search for all memories\n",
    "try:\n",
    "    results = list(memory_store.search(namespace, query=\"user profile expertise\", limit=10))\n",
    "    \n",
    "    if results:\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"\\n--- Memory {i} ---\")\n",
    "            print(f\"Key: {result.key}\")\n",
    "            print(f\"Value: {result.value}\")\n",
    "            if hasattr(result, 'score'):\n",
    "                print(f\"Score: {result.score:.3f}\")\n",
    "    else:\n",
    "        print(\"No memories found via search. Checking raw collection...\")\n",
    "        \n",
    "        # Fallback: check MongoDB directly\n",
    "        raw_memories = list(memory_collection.find({\"namespace\": list(namespace)}))\n",
    "        print(f\"Found {len(raw_memories)} memories in MongoDB:\")\n",
    "        for mem in raw_memories[:5]:\n",
    "            print(f\"  - {mem.get('key')}: {str(mem.get('value', {}))[:100]}...\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error searching memories: {e}\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {}
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
