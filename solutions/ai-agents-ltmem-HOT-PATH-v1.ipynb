{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Lab Documentation and Solutions](https://img.shields.io/badge/Lab%20Documentation%20and%20Solutions-purple)](https://mongodb-developer.github.io/ai-agents-lab/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RM8rg08YhqZe"
   },
   "source": [
    "# Step 1: Setup prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking progress for task cluster_creation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pymongo import MongoClient\n",
    "from langchain.tools import tool\n",
    "import voyageai\n",
    "from typing import List\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict\n",
    "# Add parent directory to path to import from utils\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd())))\n",
    "from utils import track_progress, set_env\n",
    "from utils import create_index, check_index_ready\n",
    "from langchain_core.load import load\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from utils import get_llm\n",
    "from langchain_core.messages import ToolMessage\n",
    "from typing import Dict\n",
    "from pprint import pprint\n",
    "from langgraph.graph import StateGraph, START\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import END\n",
    "\n",
    "# If you are using your own MongoDB Atlas cluster, use the connection string for your cluster here\n",
    "MONGODB_URI = os.environ.get(\"MONGODB_URI\")\n",
    "# Initialize a MongoDB Python client\n",
    "mongodb_client = MongoClient(MONGODB_URI)\n",
    "# Check the connection to the server\n",
    "mongodb_client.admin.command(\"ping\")\n",
    "# Track progress of key steps-- DO NOT CHANGE\n",
    "track_progress(\"cluster_creation\", \"ai_agents_mem_lab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the LLM provider and passkey provided by your workshop instructor\n",
    "# NOTE: LLM_PROVIDER can be set to one of \"aws\"/ \"microsoft\" / \"google\"\n",
    "LLM_PROVIDER = \"aws\"\n",
    "PASSKEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully set AWS_ACCESS_KEY_ID environment variable.\n",
      "Successfully set AWS_SECRET_ACCESS_KEY environment variable.\n",
      "Successfully set VOYAGE_API_KEY environment variable.\n"
     ]
    }
   ],
   "source": [
    "# Obtain API keys from our AI model proxy and set them as environment variables-- DO NOT CHANGE\n",
    "set_env([LLM_PROVIDER,\"voyageai\"], PASSKEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Do not change the values assigned to the variables below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting existing documents from the mongodb_docs_embeddings collection.\n",
      "101 documents ingested into the mongodb_docs_embeddings collection.\n",
      "Deleting existing documents from the mongodb_docs collection.\n",
      "20 documents ingested into the mongodb_docs collection.\n",
      "Creating the vector_index index\n",
      "vector_index index status: READY\n",
      "vector_index index definition: {'fields': [{'type': 'vector', 'path': 'embedding', 'numDimensions': 1024, 'similarity': 'cosine'}]}\n",
      "Tracking progress for task vs_index_creation\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#  Database name\n",
    "DB_NAME = \"mongodb_genai_devday_agents\"\n",
    "# Name of the collection with full documents- used for summarization\n",
    "FULL_COLLECTION_NAME = \"mongodb_docs\"\n",
    "# Name of the collection for vector search- used for Q&A\n",
    "VS_COLLECTION_NAME = \"mongodb_docs_embeddings\"\n",
    "# Name of the vector search index\n",
    "VS_INDEX_NAME = \"vector_index\"\n",
    "# Connect to the `VS_COLLECTION_NAME` collection.\n",
    "vs_collection = mongodb_client[DB_NAME][VS_COLLECTION_NAME]\n",
    "# Connect to the `FULL_COLLECTION_NAME` collection.\n",
    "full_collection = mongodb_client[DB_NAME][FULL_COLLECTION_NAME]\n",
    "# Insert a dataset of MongoDB docs with embeddings into the `VS_COLLECTION_NAME` collection\n",
    "with open(f\"../data/{VS_COLLECTION_NAME}.json\", \"r\") as data_file:\n",
    "    json_data = data_file.read()\n",
    "\n",
    "data = json.loads(json_data)\n",
    "\n",
    "print(f\"Deleting existing documents from the {VS_COLLECTION_NAME} collection.\")\n",
    "vs_collection.delete_many({})\n",
    "vs_collection.insert_many(data)\n",
    "print(\n",
    "    f\"{vs_collection.count_documents({})} documents ingested into the {VS_COLLECTION_NAME} collection.\"\n",
    ")\n",
    "# Insert a dataset of MongoDB documentation pages into the `FULL_COLLECTION_NAME` collection\n",
    "with open(f\"../data/{FULL_COLLECTION_NAME}.json\", \"r\") as data_file:\n",
    "    json_data = data_file.read()\n",
    "\n",
    "data = json.loads(json_data)\n",
    "\n",
    "print(f\"Deleting existing documents from the {FULL_COLLECTION_NAME} collection.\")\n",
    "full_collection.delete_many({})\n",
    "full_collection.insert_many(data)\n",
    "print(\n",
    "    f\"{full_collection.count_documents({})} documents ingested into the {FULL_COLLECTION_NAME} collection.\"\n",
    ")\n",
    "# Create vector index definition specifying:\n",
    "# path: Path to the embeddings field\n",
    "# numDimensions: Number of embedding dimensions- depends on the embedding model used\n",
    "# similarity: Similarity metric. One of cosine, euclidean, dotProduct.\n",
    "model = {\n",
    "    \"name\": VS_INDEX_NAME,\n",
    "    \"type\": \"vectorSearch\",\n",
    "    \"definition\": {\n",
    "        \"fields\": [\n",
    "            {\n",
    "                \"type\": \"vector\",\n",
    "                \"path\": \"embedding\",\n",
    "                \"numDimensions\": 1024,\n",
    "                \"similarity\": \"cosine\",\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "}\n",
    "create_index(vs_collection, VS_INDEX_NAME, model)\n",
    "# Use the `check_index_ready` function from the `utils` module to verify that the index was created and is in READY status before proceeding\n",
    "check_index_ready(vs_collection, VS_INDEX_NAME)\n",
    "# Track progress of key steps-- DO NOT CHANGE\n",
    "track_progress(\"vs_index_creation\", \"ai_agents_lab\")\n",
    "# Initialize the Voyage AI client\n",
    "vo = voyageai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Functions and retrieval tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(query: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Get embeddings for an input query.\n",
    "\n",
    "    Args:\n",
    "        query (str): Query string\n",
    "\n",
    "    Returns:\n",
    "        List[float]: Embedding of the query string\n",
    "    \"\"\"\n",
    "    # Use the `contextualized_embed` method of the Voyage AI API to embed the user query with the following arguments:\n",
    "    # inputs: `query` wrapped in a list of lists\n",
    "    # model: `voyage-context-3`\n",
    "    # input_type: \"query\"\n",
    "    embds_obj = vo.contextualized_embed(inputs=[[query]], model=\"voyage-context-3\", input_type=\"query\")\n",
    "    # Extract embeddings from the embeddings object\n",
    "    embeddings = embds_obj.results[0].embeddings[0]\n",
    "    return embeddings\n",
    "# Define a tool to retrieve relevant documents for a user query using vector search\n",
    "@tool\n",
    "def get_information_for_question_answering(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve information using vector search to answer a user query.\n",
    "\n",
    "    Args:\n",
    "    user_query (str): The user's query string.\n",
    "\n",
    "    Returns:\n",
    "    str: The retrieved information formatted as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate embeddings for the `user_query` using the `get_embeddings` function defined above\n",
    "    query_embedding = get_embeddings(user_query)\n",
    "\n",
    "    # Define an aggregation pipeline consisting of a $vectorSearch stage, followed by a $project stage\n",
    "    # Set the number of candidates to 150 and only return the top 5 documents from the vector search\n",
    "    # In the $project stage, exclude the `_id` field and include only the `body` field and `vectorSearchScore`\n",
    "    # NOTE: Use variables defined previously for the `index`, `queryVector` and `path` fields in the $vectorSearch stage\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$vectorSearch\": {\n",
    "                \"index\": VS_INDEX_NAME,\n",
    "                \"path\": \"embedding\",\n",
    "                \"queryVector\": query_embedding,\n",
    "                \"numCandidates\": 150,\n",
    "                \"limit\": 5,\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"_id\": 0,\n",
    "                \"body\": 1,\n",
    "                \"score\": {\"$meta\": \"vectorSearchScore\"},\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Execute the aggregation `pipeline` against the `vs_collection` collection and store the results in `results`\n",
    "    results = vs_collection.aggregate(pipeline)\n",
    "    # Concatenate the results into a string\n",
    "    context = \"\\n\\n\".join([doc.get(\"body\") for doc in results])\n",
    "    return context\n",
    "# Define a tool to retrieve the content of a documentation page for summarization\n",
    "@tool\n",
    "def get_page_content_for_summarization(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve page content based on provided title.\n",
    "\n",
    "    Args:\n",
    "    user_query (str): The user's query string i.e. title of the documentation page.\n",
    "\n",
    "    Returns:\n",
    "    str: The content of the page.\n",
    "    \"\"\"\n",
    "    # Query the documents where the `title` field is equal to the `user_query`\n",
    "    query = {\"title\": user_query}\n",
    "    # Only return the `body` field from the retrieved documents.\n",
    "    # NOTE: Set fields to include to 1, those to exclude to 0. `_id` is included by default, so exclude that.\n",
    "    projection = {\"_id\": 0, \"body\": 1}\n",
    "    # Use the `query` and `projection` with the `find_one` method\n",
    "    # to get the `body` of the document with `title` equal to the `user_query` from the `full_collection` collection\n",
    "    document = full_collection.find_one(query, projection)\n",
    "    if document:\n",
    "        return document[\"body\"]\n",
    "    else:\n",
    "        return \"Document not found\"\n",
    "# Create the list of tools\n",
    "tools = [\n",
    "    get_information_for_question_answering,\n",
    "    get_page_content_for_summarization,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Graph State and Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the graph state\n",
    "# We are only tracking chat messages but you can track other attributes as well\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "# Obtain the Langchain LLM object using the `get_llm` function from the `utils`` module.\n",
    "llm = get_llm(LLM_PROVIDER)\n",
    "# Create a Chain-of-Thought (CoT) prompt template for the agent.\n",
    "# This includes a system prompt with a placeholder for tool names, and a placeholder for messages i.e. user queries and assistant responses\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"You are a helpful AI assistant.\"\n",
    "            \" You are provided with tools to answer questions and summarize technical documentation related to MongoDB.\"\n",
    "            \" Think step-by-step and use these tools to get the information required to answer the user query.\"\n",
    "            \" Do not re-run tools unless absolutely necessary.\"\n",
    "            \" If you are not able to get enough information using the tools, reply with I DON'T KNOW.\"\n",
    "            \" You have access to the following tools: {tool_names}.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "# Fill in the prompt template with the tool names\n",
    "prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "# Bind the `tools` to the `llm` instantiated above\n",
    "bind_tools = llm.bind_tools(tools)\n",
    "# Chain the `prompt` with the tool-augmented llm using the `|` operator\n",
    "llm_with_tools = prompt | bind_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Define graph nodes and compile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x783465591710>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the agent node\n",
    "def agent(state: GraphState) -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Agent node\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Graph state\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List]: Updates to messages\n",
    "    \"\"\"\n",
    "    # Get the messages from the graph `state`\n",
    "    messages = state[\"messages\"]\n",
    "    # Invoke `llm_with_tools` with `messages` using the `invoke` method\n",
    "    # HINT: See Step 6 for how to invoke `llm_with_tools`\n",
    "    result = llm_with_tools.invoke(messages)\n",
    "    # Write `result` to the `messages` attribute of the graph state\n",
    "    return {\"messages\": [result]}\n",
    "# Create a map of tool name to tool call\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "# Define tool node\n",
    "def tool_node(state: GraphState) -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Tool node\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Graph state\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List]: Updates to messages\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    # Get the list of tool calls from messages\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    # A tool_call looks as follows:\n",
    "    # {\n",
    "    #     \"name\": \"get_information_for_question_answering\",\n",
    "    #     \"args\": {\"user_query\": \"What are Atlas Triggers\"},\n",
    "    #     \"id\": \"call_H5TttXb423JfoulF1qVfPN3m\",\n",
    "    #     \"type\": \"tool_call\",\n",
    "    # }\n",
    "    # Iterate through `tool_calls`\n",
    "    for tool_call in tool_calls:\n",
    "        # Get the tool from `tools_by_name` using the `name` attribute of the `tool_call`\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        # Invoke the `tool` using the `args` attribute of the `tool_call`\n",
    "        # HINT: See previous line to see how to extract attributes from `tool_call`\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        # Append the result of executing the tool to the `result` list as a ToolMessage\n",
    "        # The `content` of the message is `observation` i.e. result of the tool call\n",
    "        # The `tool_call_id` can be obtained from the `tool_call`\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    # Write `result` to the `messages` attribute of the graph state\n",
    "    return {\"messages\": result}\n",
    "# Define conditional routing function\n",
    "def route_tools(state: GraphState):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the tool node if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    # Get messages from graph state\n",
    "    messages = state.get(\"messages\", [])\n",
    "    if len(messages) > 0:\n",
    "        # Get the last AI message from messages\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    # Check if the last message has tool calls\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        # If yes, return \"tools\"\n",
    "        return \"tools\"\n",
    "    # If no, return END\n",
    "    return END\n",
    "# Instantiate the graph\n",
    "graph = StateGraph(GraphState)\n",
    "# Add nodes to the `graph` using the `add_node` function\n",
    "# Add a `agent` node. The `agent` node should run the `agent` function\n",
    "graph.add_node(\"agent\", agent)\n",
    "# Add a `tools` node. The `tools` node should run the `tool_node` function\n",
    "graph.add_node(\"tools\", tool_node)\n",
    "# Add fixed edges to the `graph` using the `add_edge` method\n",
    "# Add an edge from the START node to the `agent` node\n",
    "graph.add_edge(START, \"agent\")\n",
    "# Add an edge from the `tools` node to the `agent` node\n",
    "graph.add_edge(\"tools\", \"agent\")\n",
    "# Use the `add_conditional_edges` method to add a conditional edge from the `agent` node to the `tools` node\n",
    "# based on the output of the `route_tools` function\n",
    "graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    route_tools,\n",
    "    {\"tools\": \"tools\", END: END},\n",
    ")\n",
    "# Compile the `graph`\n",
    "app = graph.compile()\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_graph(user_input: str) -> None:\n",
    "    \"\"\"\n",
    "    Stream outputs from the graph\n",
    "\n",
    "    Args:\n",
    "        user_input (str): User query string\n",
    "    \"\"\"\n",
    "    # Stream outputs from each step in the graph\n",
    "    for step in app.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        # Stream full value of the state after each step\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        # Print the latest message from the step\n",
    "        step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Step 5: Execute the graph with Short or Long term memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are some best practices for data backups in MongoDB?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'll help you find information about best practices for data backups in MongoDB.\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01BQKbKD2AFa7PZKwFzswJJf)\n",
      " Call ID: toolu_bdrk_01BQKbKD2AFa7PZKwFzswJJf\n",
      "  Args:\n",
      "    user_query: best practices for data backups in MongoDB\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "FTDC data contains certain host machine information such as hostnames, operating system information, and the options or settings used to start the `mongod` or `mongos`. This information may be considered protected or confidential by some organizations or regulatory bodies, but is not typically considered to be Personally Identifiable Information (PII). For clusters where these fields are configured with protected, confidential, or PII data, please notify MongoDB engineers before sending FTDC data to coordinate appropriate security measures.\n",
      "\n",
      "On Windows, to collect system data such as disk, cpu, and memory, FTDC requires Microsoft access permissions from the following groups:\n",
      "\n",
      "- Performance Monitor Users\n",
      "\n",
      "- Performance Log Users\n",
      "\n",
      "If the user running `mongod` and `mongos` is not an administrator, add them to these groups to log FTDC data. For more information, see the Microsoft documentation here.\n",
      "\n",
      "FTDC periodically collects statistics produced by the following commands:\n",
      "\n",
      "- `serverStatus`\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_018dmHCNndzxdTJiPCEJ3gNb)\n",
      " Call ID: toolu_bdrk_018dmHCNndzxdTJiPCEJ3gNb\n",
      "  Args:\n",
      "    user_query: MongoDB backup strategies recommendations mongodump file system snapshots\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01JGwG8KQZvK8X9rNTTAzn65)\n",
      " Call ID: toolu_bdrk_01JGwG8KQZvK8X9rNTTAzn65\n",
      "  Args:\n",
      "    user_query: MongoDB backup methods replica sets point in time recovery backup frequency\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "Just for the sake of it, I also used multi-document ACID transactions in a few methods where it could potentially make sense to use ACID transactions. You can check all the code in the `MongoDBPersonRepository` class.\n",
      "\n",
      "Here is an example:\n",
      "\n",
      "```java\n",
      "private static final TransactionOptions txnOptions = TransactionOptions.builder()\n",
      "    .readPreference(ReadPreference.primary())\n",
      "    .readConcern(ReadConcern.MAJORITY)\n",
      "    .writeConcern(WriteConcern.MAJORITY)\n",
      "    .build();\n",
      "\n",
      "@Override\n",
      "public List saveAll(List personEntities) {\n",
      "    try (ClientSession clientSession = client.startSession()) {\n",
      "        return clientSession.withTransaction(() -> {\n",
      "            personEntities.forEach(p -> p.setId(new ObjectId()));\n",
      "            personCollection.insertMany(clientSession, personEntities);\n",
      "            return personEntities;\n",
      "        }, txnOptions);\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "As you can see, I’m using an auto-closeable try-with-resources which will automatically close the client session at the end. This helps me to keep the code clean and simple.\n",
      "\n",
      "Some of you may argue that it is actually too simple because transactions (and write operations, in general) can throw exceptions, and I’m not handling any of them here… You are absolutely right and this is an excellent transition to the next part of this article.\n",
      "\n",
      "## Exception management\n",
      "\n",
      "Transactions in MongoDB can raise exceptions for various reasons, and I don’t want to go into the details too much here, but since MongoDB 3.6, any write operation that fails can be automatically retried once. And the transactions are no different. See the documentation for retryWrites.\n",
      "\n",
      "If retryable writes are disabled or if a write operation fails twice, then MongoDB will send a MongoException (extends RuntimeException) which should be handled properly.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_015fMurG2mNttVGZRtRVhDDE)\n",
      " Call ID: toolu_bdrk_015fMurG2mNttVGZRtRVhDDE\n",
      "  Args:\n",
      "    user_query: backup best practices testing backups offsite storage encryption\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "\n",
      "FTDC data contains certain host machine information such as hostnames, operating system information, and the options or settings used to start the `mongod` or `mongos`. This information may be considered protected or confidential by some organizations or regulatory bodies, but is not typically considered to be Personally Identifiable Information (PII). For clusters where these fields are configured with protected, confidential, or PII data, please notify MongoDB engineers before sending FTDC data to coordinate appropriate security measures.\n",
      "\n",
      "On Windows, to collect system data such as disk, cpu, and memory, FTDC requires Microsoft access permissions from the following groups:\n",
      "\n",
      "- Performance Monitor Users\n",
      "\n",
      "- Performance Log Users\n",
      "\n",
      "If the user running `mongod` and `mongos` is not an administrator, add them to these groups to log FTDC data. For more information, see the Microsoft documentation here.\n",
      "\n",
      "FTDC periodically collects statistics produced by the following commands:\n",
      "\n",
      "- `serverStatus`\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_012MMyfUzXUkykDWdHXbvZPG)\n",
      " Call ID: toolu_bdrk_012MMyfUzXUkykDWdHXbvZPG\n",
      "  Args:\n",
      "    user_query: MongoDB backup considerations replica set secondary node snapshot\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "FTDC data contains certain host machine information such as hostnames, operating system information, and the options or settings used to start the `mongod` or `mongos`. This information may be considered protected or confidential by some organizations or regulatory bodies, but is not typically considered to be Personally Identifiable Information (PII). For clusters where these fields are configured with protected, confidential, or PII data, please notify MongoDB engineers before sending FTDC data to coordinate appropriate security measures.\n",
      "\n",
      "On Windows, to collect system data such as disk, cpu, and memory, FTDC requires Microsoft access permissions from the following groups:\n",
      "\n",
      "- Performance Monitor Users\n",
      "\n",
      "- Performance Log Users\n",
      "\n",
      "If the user running `mongod` and `mongos` is not an administrator, add them to these groups to log FTDC data. For more information, see the Microsoft documentation here.\n",
      "\n",
      "FTDC periodically collects statistics produced by the following commands:\n",
      "\n",
      "- `serverStatus`\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_page_content_for_summarization (toolu_bdrk_01BBWE9baQ4HNSvmChS1WVYo)\n",
      " Call ID: toolu_bdrk_01BBWE9baQ4HNSvmChS1WVYo\n",
      "  Args:\n",
      "    user_query: MongoDB backup methods\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Document not found\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_page_content_for_summarization (toolu_bdrk_01W7SdCdz4KGrgmBAQLwQQp2)\n",
      " Call ID: toolu_bdrk_01W7SdCdz4KGrgmBAQLwQQp2\n",
      "  Args:\n",
      "    user_query: backup and restore\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Document not found\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01WErQydCCQgtuw12BEAc37X)\n",
      " Call ID: toolu_bdrk_01WErQydCCQgtuw12BEAc37X\n",
      "  Args:\n",
      "    user_query: mongodump mongorestore backup procedure standalone replica set\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "\n",
      "# Administration\n",
      "\n",
      "The administration documentation addresses the ongoing operation and maintenance of MongoDB instances and deployments. This documentation includes both high level overviews of these concerns as well as tutorials that cover specific procedures and processes for operating MongoDB.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01Qswfnnq1YdXGaaAYoGUruq)\n",
      " Call ID: toolu_bdrk_01Qswfnnq1YdXGaaAYoGUruq\n",
      "  Args:\n",
      "    user_query: backup strategies file system snapshot LVM EBS consistent backup\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the information I've gathered from the MongoDB documentation, here are some **best practices for data backups in MongoDB**:\n",
      "\n",
      "## Backup Methods\n",
      "\n",
      "1. **Use Managed Backup Solutions (Recommended)**\n",
      "   - **MongoDB Atlas, Cloud Manager, or Ops Manager** - These provide coordinated backup and restore processes that maintain atomicity guarantees of transactions across shards\n",
      "   - These are particularly recommended for sharded clusters\n",
      "\n",
      "2. **File System Snapshots**\n",
      "   - Can be more efficient than MongoDB tools if your system configuration supports them\n",
      "   - Suitable for backing up each component in a cluster individually\n",
      "   - Requires stopping the cluster balancer during backup operations\n",
      "\n",
      "3. **mongodump and mongorestore**\n",
      "   - Can be used as a backup strategy for various deployment types\n",
      "   - For sharded clusters, requires additional precautions:\n",
      "     - Stop the sharded cluster balancer\n",
      "     - Use the `fsync` command or `db.fsyncLock()` method on `mongos` to block writes during backups\n",
      "   - Back up each component in the cluster individually\n",
      "\n",
      "## Key Best Practices\n",
      "\n",
      "1. **Minimize Impact on Production**\n",
      "   - For sharded clusters, stop or limit the cluster balancer operation to provide a window for regular backup operations\n",
      "   - Use `fsync` or `db.fsyncLock()` to ensure data consistency during backups\n",
      "\n",
      "2. **Maintain Consistency**\n",
      "   - Ensure backups are consistent, especially in sharded environments\n",
      "   - Use coordinated backup processes that maintain atomicity guarantees across shards\n",
      "\n",
      "3. **Plan for Different Deployment Types**\n",
      "   - Backup strategies differ between standalone instances, replica sets, and sharded clusters\n",
      "   - Sharded clusters require more coordination and planning\n",
      "\n",
      "4. **Regular Backup Schedule**\n",
      "   - Establish regular backup windows, especially when using the balancer limitation approach\n",
      "\n",
      "These practices help ensure your MongoDB data is properly protected and can be restored when needed.\n"
     ]
    }
   ],
   "source": [
    "# Test the graph execution to view end-to-end flow\n",
    "execute_graph(\"What are some best practices for data backups in MongoDB?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What did I just ask you?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You just asked me: \"What did I just ask you?\"\n",
      "\n",
      "This is a self-referential question where you're asking me to repeat back the question you just posed to me.\n"
     ]
    }
   ],
   "source": [
    "execute_graph(\"What did I just ask you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Add Session memory (Short term) to the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.mongodb import MongoDBSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a MongoDB checkpointer\n",
    "checkpointer = MongoDBSaver(mongodb_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the graph with the checkpointer\n",
    "app = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📚 https://langchain-ai.github.io/langgraph/concepts/persistence/#threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_graph_with_memory(thread_id: str, user_input: str) -> None:\n",
    "    \"\"\"\n",
    "    Stream outputs from the graph\n",
    "\n",
    "    Args:\n",
    "        thread_id (str): Thread ID for the checkpointer\n",
    "        user_input (str): User query string\n",
    "    \"\"\"\n",
    "    # Create a runtime config for the thread ID `thread_id`\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    # Stream outputs from each step in the graph\n",
    "    for step in app.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        # Pass the config as an additional parameter\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        # Print the latest message from the step\n",
    "        step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are some best practices for data backups in MongoDB?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'll help you find information about best practices for data backups in MongoDB.\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01JWBUNeg3XTQkJfJ5pGk5CY)\n",
      " Call ID: toolu_bdrk_01JWBUNeg3XTQkJfJ5pGk5CY\n",
      "  Args:\n",
      "    user_query: best practices for data backups in MongoDB\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "FTDC data contains certain host machine information such as hostnames, operating system information, and the options or settings used to start the `mongod` or `mongos`. This information may be considered protected or confidential by some organizations or regulatory bodies, but is not typically considered to be Personally Identifiable Information (PII). For clusters where these fields are configured with protected, confidential, or PII data, please notify MongoDB engineers before sending FTDC data to coordinate appropriate security measures.\n",
      "\n",
      "On Windows, to collect system data such as disk, cpu, and memory, FTDC requires Microsoft access permissions from the following groups:\n",
      "\n",
      "- Performance Monitor Users\n",
      "\n",
      "- Performance Log Users\n",
      "\n",
      "If the user running `mongod` and `mongos` is not an administrator, add them to these groups to log FTDC data. For more information, see the Microsoft documentation here.\n",
      "\n",
      "FTDC periodically collects statistics produced by the following commands:\n",
      "\n",
      "- `serverStatus`\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_016oh2juevPt7pjQswwE4Rjp)\n",
      " Call ID: toolu_bdrk_016oh2juevPt7pjQswwE4Rjp\n",
      "  Args:\n",
      "    user_query: MongoDB backup strategies recommendations mongodump file system snapshots\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01BTMaQoeLrPtfUsEJv3ynaa)\n",
      " Call ID: toolu_bdrk_01BTMaQoeLrPtfUsEJv3ynaa\n",
      "  Args:\n",
      "    user_query: MongoDB backup methods replica sets point in time recovery backup frequency\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "Just for the sake of it, I also used multi-document ACID transactions in a few methods where it could potentially make sense to use ACID transactions. You can check all the code in the `MongoDBPersonRepository` class.\n",
      "\n",
      "Here is an example:\n",
      "\n",
      "```java\n",
      "private static final TransactionOptions txnOptions = TransactionOptions.builder()\n",
      "    .readPreference(ReadPreference.primary())\n",
      "    .readConcern(ReadConcern.MAJORITY)\n",
      "    .writeConcern(WriteConcern.MAJORITY)\n",
      "    .build();\n",
      "\n",
      "@Override\n",
      "public List saveAll(List personEntities) {\n",
      "    try (ClientSession clientSession = client.startSession()) {\n",
      "        return clientSession.withTransaction(() -> {\n",
      "            personEntities.forEach(p -> p.setId(new ObjectId()));\n",
      "            personCollection.insertMany(clientSession, personEntities);\n",
      "            return personEntities;\n",
      "        }, txnOptions);\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "As you can see, I’m using an auto-closeable try-with-resources which will automatically close the client session at the end. This helps me to keep the code clean and simple.\n",
      "\n",
      "Some of you may argue that it is actually too simple because transactions (and write operations, in general) can throw exceptions, and I’m not handling any of them here… You are absolutely right and this is an excellent transition to the next part of this article.\n",
      "\n",
      "## Exception management\n",
      "\n",
      "Transactions in MongoDB can raise exceptions for various reasons, and I don’t want to go into the details too much here, but since MongoDB 3.6, any write operation that fails can be automatically retried once. And the transactions are no different. See the documentation for retryWrites.\n",
      "\n",
      "If retryable writes are disabled or if a write operation fails twice, then MongoDB will send a MongoException (extends RuntimeException) which should be handled properly.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01Xpsbi4nBc2uBZwwAKsYyC3)\n",
      " Call ID: toolu_bdrk_01Xpsbi4nBc2uBZwwAKsYyC3\n",
      "  Args:\n",
      "    user_query: backup best practices testing backups offsite storage encryption\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "\n",
      "FTDC data contains certain host machine information such as hostnames, operating system information, and the options or settings used to start the `mongod` or `mongos`. This information may be considered protected or confidential by some organizations or regulatory bodies, but is not typically considered to be Personally Identifiable Information (PII). For clusters where these fields are configured with protected, confidential, or PII data, please notify MongoDB engineers before sending FTDC data to coordinate appropriate security measures.\n",
      "\n",
      "On Windows, to collect system data such as disk, cpu, and memory, FTDC requires Microsoft access permissions from the following groups:\n",
      "\n",
      "- Performance Monitor Users\n",
      "\n",
      "- Performance Log Users\n",
      "\n",
      "If the user running `mongod` and `mongos` is not an administrator, add them to these groups to log FTDC data. For more information, see the Microsoft documentation here.\n",
      "\n",
      "FTDC periodically collects statistics produced by the following commands:\n",
      "\n",
      "- `serverStatus`\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01JASQrFMMZ6qT9ydmi2kJEP)\n",
      " Call ID: toolu_bdrk_01JASQrFMMZ6qT9ydmi2kJEP\n",
      "  Args:\n",
      "    user_query: MongoDB backup considerations replica set secondary node snapshot\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "FTDC data contains certain host machine information such as hostnames, operating system information, and the options or settings used to start the `mongod` or `mongos`. This information may be considered protected or confidential by some organizations or regulatory bodies, but is not typically considered to be Personally Identifiable Information (PII). For clusters where these fields are configured with protected, confidential, or PII data, please notify MongoDB engineers before sending FTDC data to coordinate appropriate security measures.\n",
      "\n",
      "On Windows, to collect system data such as disk, cpu, and memory, FTDC requires Microsoft access permissions from the following groups:\n",
      "\n",
      "- Performance Monitor Users\n",
      "\n",
      "- Performance Log Users\n",
      "\n",
      "If the user running `mongod` and `mongos` is not an administrator, add them to these groups to log FTDC data. For more information, see the Microsoft documentation here.\n",
      "\n",
      "FTDC periodically collects statistics produced by the following commands:\n",
      "\n",
      "- `serverStatus`\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_page_content_for_summarization (toolu_bdrk_01XsBKyHgCC8Dy2v5uebCdDP)\n",
      " Call ID: toolu_bdrk_01XsBKyHgCC8Dy2v5uebCdDP\n",
      "  Args:\n",
      "    user_query: MongoDB backup methods\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Document not found\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_page_content_for_summarization (toolu_bdrk_01BY4GcrfDJYmCA9ftP261pV)\n",
      " Call ID: toolu_bdrk_01BY4GcrfDJYmCA9ftP261pV\n",
      "  Args:\n",
      "    user_query: backup and restore\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Document not found\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01CYtycRu7ZQAF78S9XGLPKf)\n",
      " Call ID: toolu_bdrk_01CYtycRu7ZQAF78S9XGLPKf\n",
      "  Args:\n",
      "    user_query: mongodump mongorestore backup procedure standalone replica set\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "\n",
      "# Administration\n",
      "\n",
      "The administration documentation addresses the ongoing operation and maintenance of MongoDB instances and deployments. This documentation includes both high level overviews of these concerns as well as tutorials that cover specific procedures and processes for operating MongoDB.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01Je1kiPsn95uz4YiMTkwuw9)\n",
      " Call ID: toolu_bdrk_01Je1kiPsn95uz4YiMTkwuw9\n",
      "  Args:\n",
      "    user_query: backup strategies file system snapshot LVM EBS consistent backup\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the information I've gathered from the MongoDB documentation, here are some **best practices for data backups in MongoDB**:\n",
      "\n",
      "## Backup Methods\n",
      "\n",
      "1. **Use Managed Backup Solutions (Recommended)**\n",
      "   - **MongoDB Atlas, Cloud Manager, or Ops Manager** - These provide coordinated backup and restore processes that maintain atomicity guarantees of transactions across shards\n",
      "   - These are particularly recommended for sharded clusters\n",
      "\n",
      "2. **File System Snapshots**\n",
      "   - Can be more efficient than MongoDB tools if your system configuration supports them\n",
      "   - Suitable for backing up each component in a cluster individually\n",
      "   - Requires stopping the cluster balancer during backup operations\n",
      "\n",
      "3. **mongodump and mongorestore**\n",
      "   - Can be used as a backup strategy for various deployment types\n",
      "   - For sharded clusters, requires additional precautions:\n",
      "     - Stop the sharded cluster balancer\n",
      "     - Use the `fsync` command or `db.fsyncLock()` method on `mongos` to block writes during backups\n",
      "   - Back up each component in the cluster individually\n",
      "\n",
      "## Key Best Practices\n",
      "\n",
      "1. **Minimize Impact on Production**\n",
      "   - For sharded clusters, stop or limit the cluster balancer operation to provide a window for regular backup operations\n",
      "   - Use `fsync` or `db.fsyncLock()` to ensure data consistency during backups\n",
      "\n",
      "2. **Maintain Consistency**\n",
      "   - Ensure backups are consistent, especially in sharded environments\n",
      "   - Use coordinated backup processes that maintain atomicity guarantees across shards\n",
      "\n",
      "3. **Plan for Different Deployment Types**\n",
      "   - Backup strategies differ between standalone instances, replica sets, and sharded clusters\n",
      "   - Sharded clusters require more coordination and planning\n",
      "\n",
      "4. **Regular Backup Schedule**\n",
      "   - Establish regular backup windows, especially when using the balancer limitation approach\n",
      "\n",
      "These practices help ensure your MongoDB data is properly protected and can be restored when needed.\n"
     ]
    }
   ],
   "source": [
    "# Test graph execution with thread ID\n",
    "execute_graph_with_memory(\n",
    "    \"1\",\n",
    "    \"What are some best practices for data backups in MongoDB?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What did I just ask you?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You just asked me: \"What are some best practices for data backups in MongoDB?\"\n"
     ]
    }
   ],
   "source": [
    "# Follow-up question to ensure message history works\n",
    "execute_graph_with_memory(\n",
    "    \"1\",\n",
    "    \"What did I just ask you?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi! I'm a senior DBA focusing on disaster recovery and backup strategies. Can you tell me about backup and restore?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'll help you with information about backup and restore strategies in MongoDB. Let me retrieve the relevant documentation for you.\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01GfVo6A8G4FfBtqJfnu5zjw)\n",
      " Call ID: toolu_bdrk_01GfVo6A8G4FfBtqJfnu5zjw\n",
      "  Args:\n",
      "    user_query: backup and restore strategies disaster recovery\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_017K8WHkuj39uYaCpHkCvm2U)\n",
      " Call ID: toolu_bdrk_017K8WHkuj39uYaCpHkCvm2U\n",
      "  Args:\n",
      "    user_query: MongoDB backup methods mongodump filesystem snapshots backup strategies\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_015bN7gbWm7m9PRBY7u6pSRR)\n",
      " Call ID: toolu_bdrk_015bN7gbWm7m9PRBY7u6pSRR\n",
      "  Args:\n",
      "    user_query: backup restore replica sets standalone mongodump mongorestore point in time recovery\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "Just for the sake of it, I also used multi-document ACID transactions in a few methods where it could potentially make sense to use ACID transactions. You can check all the code in the `MongoDBPersonRepository` class.\n",
      "\n",
      "Here is an example:\n",
      "\n",
      "```java\n",
      "private static final TransactionOptions txnOptions = TransactionOptions.builder()\n",
      "    .readPreference(ReadPreference.primary())\n",
      "    .readConcern(ReadConcern.MAJORITY)\n",
      "    .writeConcern(WriteConcern.MAJORITY)\n",
      "    .build();\n",
      "\n",
      "@Override\n",
      "public List saveAll(List personEntities) {\n",
      "    try (ClientSession clientSession = client.startSession()) {\n",
      "        return clientSession.withTransaction(() -> {\n",
      "            personEntities.forEach(p -> p.setId(new ObjectId()));\n",
      "            personCollection.insertMany(clientSession, personEntities);\n",
      "            return personEntities;\n",
      "        }, txnOptions);\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "The configuration can be found in the MongoDBConfiguration.java class.\n",
      "\n",
      "```java\n",
      "package com.mongodb.starter;\n",
      "\n",
      "import ...]\n",
      "\n",
      "import static org.bson.codecs.configuration.CodecRegistries.fromProviders;\n",
      "import static org.bson.codecs.configuration.CodecRegistries.fromRegistries;\n",
      "\n",
      "@Configuration\n",
      "public class MongoDBConfiguration {\n",
      "\n",
      "    @Value(\"${spring.data.mongodb.uri}\")\n",
      "    private String connectionString;\n",
      "\n",
      "    @Bean\n",
      "    public MongoClient mongoClient() {\n",
      "        CodecRegistry pojoCodecRegistry = fromProviders(PojoCodecProvider.builder().automatic(true).build());\n",
      "        CodecRegistry codecRegistry = fromRegistries(MongoClientSettings.getDefaultCodecRegistry(), pojoCodecRegistry);\n",
      "        return MongoClients.create(MongoClientSettings.builder()\n",
      "                                                      .applyConnectionString(new ConnectionString(connectionString))\n",
      "                                                      .codecRegistry(codecRegistry)\n",
      "                                                      .build());\n",
      "    }\n",
      "\n",
      "}\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Let me search for more specific backup and restore documentation.\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_014uCE8QRUjAUUnB24qApvfF)\n",
      " Call ID: toolu_bdrk_014uCE8QRUjAUUnB24qApvfF\n",
      "  Args:\n",
      "    user_query: backup methods overview filesystem snapshot cloud manager ops manager\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "# Administration\n",
      "\n",
      "The administration documentation addresses the ongoing operation and maintenance of MongoDB instances and deployments. This documentation includes both high level overviews of these concerns as well as tutorials that cover specific procedures and processes for operating MongoDB.\n",
      "\n",
      "### Enter the new name for the organization.\n",
      "\n",
      "### Click Save.\n",
      "\n",
      "## Delete an Organization\n",
      "\n",
      "To delete an organization, you must have `Organization Owner` role for the organization.\n",
      "\n",
      "You can't delete an organization that has active projects. You must delete the organization's projects before you can delete the organization.\n",
      "\n",
      "You can't delete an organization with outstanding payments. To learn more, see Troubleshoot Invoices and Payments.\n",
      "\n",
      "If you have a Backup Compliance Policy enabled, you can't delete a project if any snapshots exists. If you can't remove all projects, you can't delete the organization.\n",
      "\n",
      "<Tabs>\n",
      "\n",
      "<Tab name=\"Atlas CLI\">\n",
      "\n",
      "To delete an organization using the Atlas CLI, run the following command:\n",
      "\n",
      "```sh\n",
      "\n",
      "atlas organizations delete <ID> [options]\n",
      "\n",
      "```\n",
      "\n",
      "To learn more about the command syntax and parameters, see the Atlas CLI documentation for atlas organizations delete.\n",
      "\n",
      "- Install the Atlas CLI\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_page_content_for_summarization (toolu_bdrk_01WRdVUR5cKDPu4R9JRwxW7C)\n",
      " Call ID: toolu_bdrk_01WRdVUR5cKDPu4R9JRwxW7C\n",
      "  Args:\n",
      "    user_query: backup and restore\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Document not found\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01GMmxNP2C4TCrkdCXif6jH5)\n",
      " Call ID: toolu_bdrk_01GMmxNP2C4TCrkdCXif6jH5\n",
      "  Args:\n",
      "    user_query: backup restore tutorial procedures best practices\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "# Administration\n",
      "\n",
      "The administration documentation addresses the ongoing operation and maintenance of MongoDB instances and deployments. This documentation includes both high level overviews of these concerns as well as tutorials that cover specific procedures and processes for operating MongoDB.\n",
      "\n",
      "Just for the sake of it, I also used multi-document ACID transactions in a few methods where it could potentially make sense to use ACID transactions. You can check all the code in the `MongoDBPersonRepository` class.\n",
      "\n",
      "Here is an example:\n",
      "\n",
      "```java\n",
      "private static final TransactionOptions txnOptions = TransactionOptions.builder()\n",
      "    .readPreference(ReadPreference.primary())\n",
      "    .readConcern(ReadConcern.MAJORITY)\n",
      "    .writeConcern(WriteConcern.MAJORITY)\n",
      "    .build();\n",
      "\n",
      "@Override\n",
      "public List saveAll(List personEntities) {\n",
      "    try (ClientSession clientSession = client.startSession()) {\n",
      "        return clientSession.withTransaction(() -> {\n",
      "            personEntities.forEach(p -> p.setId(new ObjectId()));\n",
      "            personCollection.insertMany(clientSession, personEntities);\n",
      "            return personEntities;\n",
      "        }, txnOptions);\n",
      "    }\n",
      "}\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_015VWPzJvsRQuDmzE2cnHMFy)\n",
      " Call ID: toolu_bdrk_015VWPzJvsRQuDmzE2cnHMFy\n",
      "  Args:\n",
      "    user_query: mongodump mongorestore backup options parameters usage\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "FTDC data contains certain host machine information such as hostnames, operating system information, and the options or settings used to start the `mongod` or `mongos`. This information may be considered protected or confidential by some organizations or regulatory bodies, but is not typically considered to be Personally Identifiable Information (PII). For clusters where these fields are configured with protected, confidential, or PII data, please notify MongoDB engineers before sending FTDC data to coordinate appropriate security measures.\n",
      "\n",
      "On Windows, to collect system data such as disk, cpu, and memory, FTDC requires Microsoft access permissions from the following groups:\n",
      "\n",
      "- Performance Monitor Users\n",
      "\n",
      "- Performance Log Users\n",
      "\n",
      "If the user running `mongod` and `mongos` is not an administrator, add them to these groups to log FTDC data. For more information, see the Microsoft documentation here.\n",
      "\n",
      "FTDC periodically collects statistics produced by the following commands:\n",
      "\n",
      "- `serverStatus`\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01YJYzizqvfc1ff7SD6rD638)\n",
      " Call ID: toolu_bdrk_01YJYzizqvfc1ff7SD6rD638\n",
      "  Args:\n",
      "    user_query: oplog replica set backup continuous backup incremental\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "\n",
      "Just for the sake of it, I also used multi-document ACID transactions in a few methods where it could potentially make sense to use ACID transactions. You can check all the code in the `MongoDBPersonRepository` class.\n",
      "\n",
      "Here is an example:\n",
      "\n",
      "```java\n",
      "private static final TransactionOptions txnOptions = TransactionOptions.builder()\n",
      "    .readPreference(ReadPreference.primary())\n",
      "    .readConcern(ReadConcern.MAJORITY)\n",
      "    .writeConcern(WriteConcern.MAJORITY)\n",
      "    .build();\n",
      "\n",
      "@Override\n",
      "public List saveAll(List personEntities) {\n",
      "    try (ClientSession clientSession = client.startSession()) {\n",
      "        return clientSession.withTransaction(() -> {\n",
      "            personEntities.forEach(p -> p.setId(new ObjectId()));\n",
      "            personCollection.insertMany(clientSession, personEntities);\n",
      "            return personEntities;\n",
      "        }, txnOptions);\n",
      "    }\n",
      "}\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the information I've retrieved from the MongoDB documentation, here's a comprehensive overview of **backup and restore strategies** for MongoDB:\n",
      "\n",
      "## **MongoDB Backup and Restore Overview**\n",
      "\n",
      "As a senior DBA focusing on disaster recovery, you have several backup strategies available in MongoDB:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Primary Backup Methods**\n",
      "\n",
      "#### **A. Managed Backup Solutions (Recommended for Production)**\n",
      "- **MongoDB Atlas** - Fully managed cloud backup\n",
      "- **MongoDB Cloud Manager** - Hosted backup management\n",
      "- **MongoDB Ops Manager** - On-premise backup management\n",
      "\n",
      "These solutions provide:\n",
      "- **Coordinated backups** that maintain atomicity guarantees of transactions across shards\n",
      "- Automated scheduling and management\n",
      "- Point-in-time recovery capabilities\n",
      "- Best option for production environments with complex topologies\n",
      "\n",
      "#### **B. mongodump and mongorestore**\n",
      "- Logical backup tool that creates BSON dumps of your data\n",
      "- Works at the database/collection level\n",
      "- **For Sharded Clusters**: Requires special considerations:\n",
      "  - Must **stop the cluster balancer**\n",
      "  - Use `fsync` command or `db.fsyncLock()` method on `mongos` to block writes during backup\n",
      "  - Back up each component individually\n",
      "\n",
      "#### **C. Filesystem Snapshots**\n",
      "- Creates point-in-time snapshots at the storage level\n",
      "- **More efficient** than MongoDB tools if your system supports it\n",
      "- **For Sharded Clusters**: \n",
      "  - Must stop the cluster balancer\n",
      "  - Back up each component individually\n",
      "  - Requires coordination across all cluster components\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Deployment-Specific Considerations**\n",
      "\n",
      "#### **Sharded Clusters**\n",
      "- Require stopping the balancer during backups\n",
      "- Need coordinated backup across all shards to maintain consistency\n",
      "- Can limit balancer operations to create backup windows\n",
      "- Restoration requires careful coordination to restore the entire cluster\n",
      "\n",
      "#### **Replica Sets**\n",
      "- Can perform backups from secondary members to minimize impact on primary\n",
      "- Leverage oplog for point-in-time recovery capabilities\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Best Practices for Disaster Recovery**\n",
      "\n",
      "1. **Minimize Production Impact**: Use secondary members or dedicated backup infrastructure\n",
      "2. **Ensure Consistency**: For sharded clusters, coordinate backups across all components\n",
      "3. **Plan Backup Windows**: Schedule balancer downtime for regular backup operations\n",
      "4. **Test Restores**: Regularly validate your backup and restore procedures\n",
      "5. **Consider Efficiency**: Filesystem snapshots may be more efficient than logical backups for large datasets\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Takeaways for Your DR Strategy**\n",
      "\n",
      "- **Production environments**: Use MongoDB Atlas, Cloud Manager, or Ops Manager for automated, coordinated backups\n",
      "- **Sharded clusters**: Always stop the balancer and coordinate backups across all components\n",
      "- **Performance**: Filesystem snapshots are typically faster than mongodump for large datasets\n",
      "- **Flexibility**: mongodump/mongorestore offers granular control at database/collection level\n",
      "\n",
      "Would you like more specific information about any particular backup method or deployment topology?\n"
     ]
    }
   ],
   "source": [
    "execute_graph_with_memory(\n",
    "    2,\n",
    "    \"Hi! I'm a senior DBA focusing on disaster recovery and backup strategies. Can you tell me about backup and restore?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Will this tailor the response for the role?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you tell me about MongoDB operations?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Let me retrieve information about MongoDB operations for you.\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_014uKwNq11yHx9oYNnrcAhxU)\n",
      " Call ID: toolu_bdrk_014uKwNq11yHx9oYNnrcAhxU\n",
      "  Args:\n",
      "    user_query: MongoDB operations administration maintenance management\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "# Administration\n",
      "\n",
      "The administration documentation addresses the ongoing operation and maintenance of MongoDB instances and deployments. This documentation includes both high level overviews of these concerns as well as tutorials that cover specific procedures and processes for operating MongoDB.\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "MongoDB uses a locking system to ensure data set consistency. If certain operations are long-running or a queue forms, performance will degrade as requests and operations wait for the lock.\n",
      "\n",
      "Lock-related slowdowns can be intermittent. To see if the lock has been affecting your performance, refer to the locks section and the globalLock section of the `serverStatus` output.\n",
      "\n",
      "Dividing `locks.<type>.timeAcquiringMicros` by `locks.<type>.acquireWaitCount` can give an approximate average wait time for a particular lock mode.\n",
      "\n",
      "`locks.<type>.deadlockCount` provide the number of times the lock acquisitions encountered deadlocks.\n",
      "\n",
      "If `globalLock.currentQueue.total` is consistently high, then there is a chance that a large number of requests are waiting for a lock. This indicates a possible concurrency issue that may be affecting performance.\n",
      "\n",
      "You can view the FTDC source code on the MongoDB Github Repository. The `ftdc_system_stats_*.ccp` files specifically define any system-specific diagnostic data captured.\n",
      "\n",
      "FTDC runs with the following defaults:\n",
      "\n",
      "- Data capture every 1 second\n",
      "\n",
      "- 200MB maximum `diagnostic.data` folder size.\n",
      "\n",
      "These defaults are designed to provide useful data to MongoDB engineers with minimal impact on performance or storage size. These values only require modifications if requested by MongoDB engineers for specific diagnostic purposes.\n",
      "\n",
      "To disable FTDC, start up the `mongod` or `mongos` with the `diagnosticDataCollectionEnabled: false` option in the `setParameter` settings of your configuration file:\n",
      "\n",
      "```yaml\n",
      "setParameter:\n",
      "  diagnosticDataCollectionEnabled: false\n",
      "```\n",
      "\n",
      "Disabling FTDC may increase the time or resources required when analyzing or debugging issues with support from MongoDB engineers. For information on MongoDB Support, visit Get Started With MongoDB Support.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01B8P7SZpzsTFEbgjHGnamsU)\n",
      " Call ID: toolu_bdrk_01B8P7SZpzsTFEbgjHGnamsU\n",
      "  Args:\n",
      "    user_query: mongod process management monitoring performance tuning deployment\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "If `globalLock.totalTime` is high relative to `uptime`, the database has existed in a lock state for a significant amount of time.\n",
      "\n",
      "Long queries can result from ineffective use of indexes; non-optimal schema design; poor query structure; system architecture issues; or insufficient RAM resulting in disk reads.\n",
      "\n",
      "## Number of Connections\n",
      "\n",
      "In some cases, the number of connections between the applications and the database can overwhelm the ability of the server to handle requests. The following fields in the `serverStatus` document can provide insight:\n",
      "\n",
      "- `connections` is a container for the following two fields:\n",
      "\n",
      "  - `connections.current` the total number of current clients connected to the database instance.\n",
      "\n",
      "  - `connections.available` the total number of unused connections available for new clients.\n",
      "\n",
      "If there are numerous concurrent application requests, the database may have trouble keeping up with demand. If this is the case, increase the capacity of your deployment.\n",
      "\n",
      "MongoDB uses a locking system to ensure data set consistency. If certain operations are long-running or a queue forms, performance will degrade as requests and operations wait for the lock.\n",
      "\n",
      "Lock-related slowdowns can be intermittent. To see if the lock has been affecting your performance, refer to the locks section and the globalLock section of the `serverStatus` output.\n",
      "\n",
      "Dividing `locks.<type>.timeAcquiringMicros` by `locks.<type>.acquireWaitCount` can give an approximate average wait time for a particular lock mode.\n",
      "\n",
      "`locks.<type>.deadlockCount` provide the number of times the lock acquisitions encountered deadlocks.\n",
      "\n",
      "If `globalLock.currentQueue.total` is consistently high, then there is a chance that a large number of requests are waiting for a lock. This indicates a possible concurrency issue that may be affecting performance.\n",
      "\n",
      "# MongoDB Performance\n",
      "\n",
      "As you develop and operate applications with MongoDB, you may need to analyze the performance of the application and its database. When you encounter degraded performance, it is often a function of database access strategies, hardware availability, and the number of open database connections.\n",
      "\n",
      "Some users may experience performance limitations as a result of inadequate or inappropriate indexing strategies, or as a consequence of poor schema design patterns. Locking Performance discusses how these can impact MongoDB's internal locking.\n",
      "\n",
      "Performance issues may indicate that the database is operating at capacity and that it is time to add additional capacity to the database. In particular, the application's working set should fit in the available physical memory.\n",
      "\n",
      "In some cases performance issues may be temporary and related to abnormal traffic load. As discussed in Number of Connections, scaling can help relax excessive traffic.\n",
      "\n",
      "Database profiling can help you to understand what operations are causing degradation.\n",
      "\n",
      "## Locking Performance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01J3Hb4YZGQLrvK7NFtFNCzG)\n",
      " Call ID: toolu_bdrk_01J3Hb4YZGQLrvK7NFtFNCzG\n",
      "  Args:\n",
      "    user_query: replica sets sharding cluster management replication configuration\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "The configuration can be found in the MongoDBConfiguration.java class.\n",
      "\n",
      "```java\n",
      "package com.mongodb.starter;\n",
      "\n",
      "import ...]\n",
      "\n",
      "import static org.bson.codecs.configuration.CodecRegistries.fromProviders;\n",
      "import static org.bson.codecs.configuration.CodecRegistries.fromRegistries;\n",
      "\n",
      "@Configuration\n",
      "public class MongoDBConfiguration {\n",
      "\n",
      "    @Value(\"${spring.data.mongodb.uri}\")\n",
      "    private String connectionString;\n",
      "\n",
      "    @Bean\n",
      "    public MongoClient mongoClient() {\n",
      "        CodecRegistry pojoCodecRegistry = fromProviders(PojoCodecProvider.builder().automatic(true).build());\n",
      "        CodecRegistry codecRegistry = fromRegistries(MongoClientSettings.getDefaultCodecRegistry(), pojoCodecRegistry);\n",
      "        return MongoClients.create(MongoClientSettings.builder()\n",
      "                                                      .applyConnectionString(new ConnectionString(connectionString))\n",
      "                                                      .codecRegistry(codecRegistry)\n",
      "                                                      .build());\n",
      "    }\n",
      "\n",
      "}\n",
      "```\n",
      "\n",
      "The important section here is the MongoDB configuration, of course. Firstly, you will notice the connection string is automatically retrieved from the `application.properties` file, and secondly, you will notice the configuration of the `MongoClient` bean.\n",
      "\n",
      "A `Codec` is the interface that abstracts the processes of decoding a BSON value into a Java object and encoding a Java object into a BSON value.\n",
      "\n",
      "A `CodecRegistry` contains a set of `Codec` instances that are accessed according to the Java classes that they encode from and decode to.\n",
      "\n",
      "The MongoDB driver is capable of encoding and decoding BSON for us, so we do not have to take care of this anymore. All the configuration we need for this project to run is here and nowhere else.\n",
      "\n",
      "You can read [the driver documentation if you want to know more about this topic.\n",
      "\n",
      "## Multi-document ACID transactions\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_011N3oGuad31fPwhDcfuaxJq)\n",
      " Call ID: toolu_bdrk_011N3oGuad31fPwhDcfuaxJq\n",
      "  Args:\n",
      "    user_query: database profiling monitoring serverStatus metrics diagnostics\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "MongoDB uses a locking system to ensure data set consistency. If certain operations are long-running or a queue forms, performance will degrade as requests and operations wait for the lock.\n",
      "\n",
      "Lock-related slowdowns can be intermittent. To see if the lock has been affecting your performance, refer to the locks section and the globalLock section of the `serverStatus` output.\n",
      "\n",
      "Dividing `locks.<type>.timeAcquiringMicros` by `locks.<type>.acquireWaitCount` can give an approximate average wait time for a particular lock mode.\n",
      "\n",
      "`locks.<type>.deadlockCount` provide the number of times the lock acquisitions encountered deadlocks.\n",
      "\n",
      "If `globalLock.currentQueue.total` is consistently high, then there is a chance that a large number of requests are waiting for a lock. This indicates a possible concurrency issue that may be affecting performance.\n",
      "\n",
      "If `globalLock.totalTime` is high relative to `uptime`, the database has existed in a lock state for a significant amount of time.\n",
      "\n",
      "Long queries can result from ineffective use of indexes; non-optimal schema design; poor query structure; system architecture issues; or insufficient RAM resulting in disk reads.\n",
      "\n",
      "## Number of Connections\n",
      "\n",
      "In some cases, the number of connections between the applications and the database can overwhelm the ability of the server to handle requests. The following fields in the `serverStatus` document can provide insight:\n",
      "\n",
      "- `connections` is a container for the following two fields:\n",
      "\n",
      "  - `connections.current` the total number of current clients connected to the database instance.\n",
      "\n",
      "  - `connections.available` the total number of unused connections available for new clients.\n",
      "\n",
      "If there are numerous concurrent application requests, the database may have trouble keeping up with demand. If this is the case, increase the capacity of your deployment.\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "\n",
      "You can view the FTDC source code on the MongoDB Github Repository. The `ftdc_system_stats_*.ccp` files specifically define any system-specific diagnostic data captured.\n",
      "\n",
      "FTDC runs with the following defaults:\n",
      "\n",
      "- Data capture every 1 second\n",
      "\n",
      "- 200MB maximum `diagnostic.data` folder size.\n",
      "\n",
      "These defaults are designed to provide useful data to MongoDB engineers with minimal impact on performance or storage size. These values only require modifications if requested by MongoDB engineers for specific diagnostic purposes.\n",
      "\n",
      "To disable FTDC, start up the `mongod` or `mongos` with the `diagnosticDataCollectionEnabled: false` option in the `setParameter` settings of your configuration file:\n",
      "\n",
      "```yaml\n",
      "setParameter:\n",
      "  diagnosticDataCollectionEnabled: false\n",
      "```\n",
      "\n",
      "Disabling FTDC may increase the time or resources required when analyzing or debugging issues with support from MongoDB engineers. For information on MongoDB Support, visit Get Started With MongoDB Support.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_014vD1JyMLF1zNC84D42wfB7)\n",
      " Call ID: toolu_bdrk_014vD1JyMLF1zNC84D42wfB7\n",
      "  Args:\n",
      "    user_query: security authentication authorization access control users roles\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "If authentication requests occur during a period when logs are not collected, they will not appear in the database access history.\n",
      "\n",
      "## Required Access\n",
      "\n",
      "To view database access history, you must have `Project Owner` or `Organization Owner` access to Atlas.\n",
      "\n",
      "## Procedure\n",
      "\n",
      "<Tabs>\n",
      "\n",
      "<Tab name=\"Atlas CLI\">\n",
      "\n",
      "To return the access logs for a cluster using the Atlas CLI, run the following command:\n",
      "\n",
      "```sh\n",
      "\n",
      "atlas accessLogs list [options]\n",
      "\n",
      "```\n",
      "\n",
      "To learn more about the command syntax and parameters, see the Atlas CLI documentation for atlas accessLogs list.\n",
      "\n",
      "- Install the Atlas CLI\n",
      "\n",
      "- Connect to the Atlas CLI\n",
      "\n",
      "</Tab>\n",
      "\n",
      "<Tab name=\"Atlas Administration API\">\n",
      "\n",
      "To view the database access history using the API, see Access Tracking.\n",
      "\n",
      "</Tab>\n",
      "\n",
      "<Tab name=\"Atlas UI\">\n",
      "\n",
      "Use the following procedure to view your database access history using the Atlas UI:\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "The date and time of the authentication request.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Field\">\n",
      "Username\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "The username associated with the database user who made the authentication request.\n",
      "\n",
      "For LDAP usernames, the UI displays the resolved LDAP name. Hover over the name to see the full LDAP username.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Field\">\n",
      "IP Address\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "The IP address of the machine that sent the authentication request.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Field\">\n",
      "Host\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "The target server that processed the authentication request.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Field\">\n",
      "Authentication Source\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "The database that the authentication request was made against. `admin` is the authentication source for SCRAM-SHA users and `$external` for LDAP users.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Field\">\n",
      "Authentication Result\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "The success or failure of the authentication request. A reason code is displayed for the failed authentication requests.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "</table>Authentication requests are pre-sorted by descending timestamp with 25 entries per page.\n",
      "\n",
      "### Logging Limitations\n",
      "\n",
      "If a cluster experiences an activity spike and generates an extremely large quantity of log messages, Atlas may stop collecting and storing new logs for a period of time.\n",
      "\n",
      "Log analysis rate limits apply only to the Performance Advisor UI, the Query Insights UI, the Access Tracking UI, and the Atlas Search Query Analytics UI. Downloadable log files are always complete.\n",
      "\n",
      "### Navigate to the Clusters page for your project.\n",
      "\n",
      "- If it is not already displayed, select the organization that contains your desired project from the  Organizations menu in the navigation bar.\n",
      "\n",
      "- If it is not already displayed, select your desired project from the Projects menu in the navigation bar.\n",
      "\n",
      "- If the Clusters page is not already displayed, click Database in the sidebar.\n",
      "\n",
      "### View the cluster's database access history.\n",
      "\n",
      "- On the cluster card, click .\n",
      "\n",
      "- Select View Database Access History.\n",
      "\n",
      "or\n",
      "\n",
      "- Click the cluster name.\n",
      "\n",
      "- Click .\n",
      "\n",
      "- Select View Database Access History.\n",
      "\n",
      "</Tab>\n",
      "\n",
      "</Tabs>\n",
      "\n",
      "# Manage Organization Teams\n",
      "\n",
      "You can create teams at the organization level and add teams to projects to grant project access roles to multiple users. Add any number of organization users to a team.\n",
      "\n",
      "Grant a team roles for specific projects. All members of a team share the same project access. Organization users can belong to multiple teams. To add teams to a project or edit team roles, see Manage Access to a Project.\n",
      "\n",
      "## Required Access\n",
      "\n",
      "To perform any of the following actions, you must have `Organization Owner` access to Atlas.\n",
      "\n",
      "## Create a Team\n",
      "\n",
      "Atlas limits the number of users to a maximum of 100 teams per project and a maximum of 250 teams per organization.\n",
      "\n",
      "<Tabs>\n",
      "\n",
      "<Tab name=\"Atlas CLI\">\n",
      "\n",
      "To create one team in your organization using the Atlas CLI, run the following command:\n",
      "\n",
      "```sh\n",
      "\n",
      "atlas teams create <name> [options]\n",
      "\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01THKkXyYaPXHUWY7NMybLk1)\n",
      " Call ID: toolu_bdrk_01THKkXyYaPXHUWY7NMybLk1\n",
      "  Args:\n",
      "    user_query: indexing query optimization explain plan performance\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Compound Indexes\n",
      "\n",
      "## Overview\n",
      "\n",
      "Compound indexes hold references to multiple fields within a collection's documents, improving query and sort performance.\n",
      "\n",
      "### Sample Data\n",
      "\n",
      "The examples in this guide use the `sample_mflix.movies` collection from the Atlas sample datasets. To learn how to create a free MongoDB Atlas cluster and load the sample datasets, see the Get Started with PyMongo.\n",
      "\n",
      "## Create a Compound Index\n",
      "\n",
      "The following example creates a compound index on the `type` and `genre` fields:\n",
      "\n",
      "```python\n",
      "movies.create_index([(\"type\", pymongo.ASCENDING), (\"genre\", pymongo.ASCENDING)])\n",
      "```\n",
      "\n",
      "The following is an example of a query that uses the index created in the preceding code example:\n",
      "\n",
      "```python\n",
      "query = { \"type\": \"movie\", \"genre\": \"Drama\" }\n",
      "sort = [(\"type\", pymongo.ASCENDING), (\"genre\", pymongo.ASCENDING)]\n",
      "\n",
      "cursor = movies.find(query).sort(sort)\n",
      "```\n",
      "\n",
      "For more information, see Compound Indexes in the MongoDB Server manual.\n",
      "\n",
      "### **[Episode 7:  Query Analytics][8]**\n",
      "\n",
      "Are your users finding what they are looking for? Are your top queries returning the best results? This episode covers the important topic of query analytics. If you're using search, you need this!\n",
      "\n",
      "### **[Episode 8:  Tips & Tricks][9]**\n",
      "\n",
      "In this final episode of The Atlas Search 'cene Season 1, useful techniques to introspect query details and see the relevancy scoring computation details. Also shown is how to get facets and search results back in one API call.\n",
      "\n",
      "### **[Episode 3: Indexing][4]**\n",
      "\n",
      "While Atlas Search automatically indexes your collections content, it does demand attention to the indexing configuration details in order to match users queries appropriately. This episode covers how Atlas Search builds an inverted index, and the options one must consider.\n",
      "\n",
      "### **[Episode 4: Searching][5]**\n",
      "\n",
      "Atlas Search provides a rich set of query operators and relevancy controls. This episode covers the common query operators, their relevancy controls, and ends with coverage of the must-have Query Analytics feature.\n",
      "\n",
      "### **[Episode 5:  Faceting][6]**\n",
      "\n",
      "Facets produce additional context for search results, providing a list of subsets and counts within. This episode details the faceting options available in Atlas Search.\n",
      "\n",
      "### **[Episode 6: Advanced Search Topics][7]**\n",
      "\n",
      "In this episode, we go through some more advanced search topics including embedded documents, fuzzy search, autocomplete, highlighting, and geospatial.\n",
      "\n",
      "# MongoDB Performance\n",
      "\n",
      "As you develop and operate applications with MongoDB, you may need to analyze the performance of the application and its database. When you encounter degraded performance, it is often a function of database access strategies, hardware availability, and the number of open database connections.\n",
      "\n",
      "Some users may experience performance limitations as a result of inadequate or inappropriate indexing strategies, or as a consequence of poor schema design patterns. Locking Performance discusses how these can impact MongoDB's internal locking.\n",
      "\n",
      "Performance issues may indicate that the database is operating at capacity and that it is time to add additional capacity to the database. In particular, the application's working set should fit in the available physical memory.\n",
      "\n",
      "In some cases performance issues may be temporary and related to abnormal traffic load. As discussed in Number of Connections, scaling can help relax excessive traffic.\n",
      "\n",
      "Database profiling can help you to understand what operations are causing degradation.\n",
      "\n",
      "## Locking Performance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01T8UZys3tihEbMQwz4KbhmH)\n",
      " Call ID: toolu_bdrk_01T8UZys3tihEbMQwz4KbhmH\n",
      "  Args:\n",
      "    user_query: log rotation upgrades patches maintenance windows operational tasks\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "# Administration\n",
      "\n",
      "The administration documentation addresses the ongoing operation and maintenance of MongoDB instances and deployments. This documentation includes both high level overviews of these concerns as well as tutorials that cover specific procedures and processes for operating MongoDB.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "System CPU Usage Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "CPU usage of the MongoDB process reaches a specified threshold.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "</table>\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Percentage of used disk space on a partition reaches a specified threshold.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Query Targeting Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Indicates inefficient queries.\n",
      "\n",
      "The change streams cursors that the Atlas Search process (`mongot`) uses to keep Atlas Search indexes updated can contribute to the query targeting ratio and trigger query targeting alerts if the ratio is high.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Replica Set Has No Primary\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "No primary is detected in replica set.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Replication Oplog Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Amount of oplog data generated on a primary cluster member is larger than the cluster's configured oplog size.\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the information retrieved, here's a comprehensive overview of **MongoDB Operations**:\n",
      "\n",
      "## **MongoDB Operations Overview**\n",
      "\n",
      "MongoDB operations encompass a wide range of administration, maintenance, and monitoring activities. Here's what you need to know:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Configuration and Maintenance**\n",
      "\n",
      "#### **Routine Management Operations:**\n",
      "- **Configuration Management**: Update and manage MongoDB deployment configurations\n",
      "- **Upgrades**: Upgrade deployments to different patch releases within the same major release series\n",
      "- **Process Management**: Start, configure, and manage running `mongod` processes\n",
      "- **Operation Control**: Stop in-progress client operations using `db.killOp()` and `maxTimeMS()`\n",
      "- **Log Management**: Archive current log files and start new ones\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Performance Monitoring & Diagnostics**\n",
      "\n",
      "#### **Full Time Diagnostic Data Capture (FTDC)**\n",
      "- **Enabled by default** for both `mongod` and `mongos` processes\n",
      "- **Captures every 1 second** with 200MB maximum folder size\n",
      "- **Storage locations**:\n",
      "  - `mongod`: `<dbPath>/diagnostic.data` (e.g., `/data/db/diagnostic.data`)\n",
      "  - `mongos`: `<logPath>.diagnostic.data` (e.g., `/var/log/mongodb/mongos.diagnostic.data`)\n",
      "\n",
      "**FTDC Collects:**\n",
      "- CPU, memory, disk, and network utilization statistics\n",
      "- `serverStatus`, `replSetGetStatus`, `collStats`, `connPoolStats`\n",
      "- `getCmdLineOpts`, `buildInfo`, `hostInfo`\n",
      "\n",
      "**FTDC Does NOT Collect:**\n",
      "- Query samples or results\n",
      "- User data from collections/indexes\n",
      "- Credentials or security certificates\n",
      "\n",
      "#### **Performance Metrics via serverStatus**\n",
      "\n",
      "**Key Areas to Monitor:**\n",
      "\n",
      "1. **Locking Performance**\n",
      "   - Check `locks` and `globalLock` sections\n",
      "   - Calculate average wait time: `locks.<type>.timeAcquiringMicros / locks.<type>.acquireWaitCount`\n",
      "   - Monitor `locks.<type>.deadlockCount` for deadlocks\n",
      "   - High `globalLock.currentQueue.total` indicates concurrency issues\n",
      "   - High `globalLock.totalTime` relative to `uptime` shows excessive locking\n",
      "\n",
      "2. **Connection Management**\n",
      "   - `connections.current`: Total current client connections\n",
      "   - `connections.available`: Unused connections available\n",
      "   - High concurrent requests may require capacity increases\n",
      "\n",
      "3. **Query Performance**\n",
      "   - Long queries often result from:\n",
      "     - Ineffective indexing\n",
      "     - Non-optimal schema design\n",
      "     - Poor query structure\n",
      "     - Insufficient RAM (causing disk reads)\n",
      "   - Use **database profiling** to identify degraded operations\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Capacity Planning & Scaling**\n",
      "\n",
      "**Performance Issues May Indicate:**\n",
      "- Database operating at capacity\n",
      "- Working set doesn't fit in available physical memory\n",
      "- Need for additional capacity\n",
      "- Temporary abnormal traffic load\n",
      "\n",
      "**Solutions:**\n",
      "- Scale deployment to handle increased load\n",
      "- Optimize indexing strategies\n",
      "- Review schema design patterns\n",
      "- Increase available connections\n",
      "\n",
      "---\n",
      "\n",
      "### **4. Indexing & Query Optimization**\n",
      "\n",
      "**Best Practices:**\n",
      "- Create **compound indexes** for multi-field queries\n",
      "- Use appropriate indexing strategies to avoid performance limitations\n",
      "- Leverage **Query Analytics** to understand query patterns\n",
      "- Monitor query targeting ratios for inefficient queries\n",
      "- Use `explain()` plans to analyze query execution\n",
      "\n",
      "---\n",
      "\n",
      "### **5. Operational Alerts**\n",
      "\n",
      "**Common Alert Types:**\n",
      "- **System CPU Usage**: CPU threshold monitoring\n",
      "- **Disk Space**: Partition usage thresholds\n",
      "- **Query Targeting**: Inefficient query indicators\n",
      "- **Replica Set Health**: No primary detected\n",
      "- **Replication Oplog**: Oplog size management\n",
      "\n",
      "---\n",
      "\n",
      "### **6. Security Operations**\n",
      "\n",
      "**Access Control:**\n",
      "- Authentication and authorization management\n",
      "- User and role management\n",
      "- Database access history tracking\n",
      "- Authentication sources: `admin` (SCRAM-SHA), `$external` (LDAP)\n",
      "- Monitor failed authentication attempts\n",
      "\n",
      "---\n",
      "\n",
      "### **7. Sharded Cluster Operations**\n",
      "\n",
      "**Special Considerations:**\n",
      "- **Balancer management**: Limit operations for backup windows\n",
      "- Coordinated operations across shards\n",
      "- Transaction atomicity across shards\n",
      "- Use `fsync` or `db.fsyncLock()` for write blocking during maintenance\n",
      "\n",
      "---\n",
      "\n",
      "### **8. Best Practices for Operations**\n",
      "\n",
      "1. **Enable\n"
     ]
    }
   ],
   "source": [
    "execute_graph_with_memory(\n",
    "    2,\n",
    "    \"Can you tell me about MongoDB operations?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long-Term Memory Implementation: Hot Path (Memory Tools)\n",
    "\n",
    "This implementation uses **Memory Tools** (`create_manage_memory_tool` and `create_search_memory_tool`) \n",
    "which allow the agent to **consciously** manage its own long-term memory.\n",
    "\n",
    "## How it works:\n",
    "1. The agent has access to `manage_memory` tool to save important user information\n",
    "2. The agent has access to `search_memory` tool to retrieve relevant memories\n",
    "3. Memories persist in MongoDB and survive across conversation threads\n",
    "\n",
    "## References:\n",
    "- [LangMem Hot Path Quickstart](https://langchain-ai.github.io/langmem/hot_path_quickstart/)\n",
    "- [LangMem Memory Tools Reference](https://langchain-ai.github.io/langmem/reference/tools/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: langmem inports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS FOR LONG-TERM MEMORY (HOT PATH)\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "from langmem import create_search_memory_tool\n",
    "from langgraph.store.mongodb import MongoDBStore, create_vector_index_config\n",
    "from langchain_voyageai import VoyageAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop the memories collection\n",
    "mongodb_client[\"mongodb_genai_devday_agents\"][\"memories\"].drop()\n",
    "print(\"Collection dropped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monkey Patch for [Issue 138](https://github.com/langchain-ai/langmem/issues/138) in langmem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hot path patched to include 'kind' field\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MONKEY-PATCH: HOT PATH TO INCLUDE \"kind\" FIELD\n",
    "# Add this AFTER imports, BEFORE creating memory tools\n",
    "# =============================================================================\n",
    "\n",
    "from langmem.knowledge.tools import _get_store, _ensure_json_serializable\n",
    "from langmem import utils\n",
    "from langchain_core.tools import StructuredTool\n",
    "import typing\n",
    "import uuid\n",
    "\n",
    "def create_manage_memory_tool(\n",
    "    namespace: tuple[str, ...] | str,\n",
    "    *,\n",
    "    instructions: str = \"Proactively call this tool when you:\\n\\n\"\n",
    "    \"1. Identify a new USER preference.\\n\"\n",
    "    \"2. Receive an explicit USER request to remember something or otherwise alter your behavior.\\n\"\n",
    "    \"3. Are working and want to record important context.\\n\"\n",
    "    \"4. Identify that an existing MEMORY is incorrect or outdated.\\n\",\n",
    "    schema: typing.Type = str,\n",
    "    actions_permitted: tuple = (\"create\", \"update\", \"delete\"),\n",
    "    store = None,\n",
    "    name: str = \"manage_memory\",\n",
    "):\n",
    "    \"\"\"Drop-in replacement for langmem.create_manage_memory_tool with cold path compatibility.\"\"\"\n",
    "    \n",
    "    namespacer = utils.NamespaceTemplate(namespace)\n",
    "    action_type = typing.Literal[actions_permitted]\n",
    "    default_action = \"create\" if \"create\" in actions_permitted else actions_permitted[0]\n",
    "    initial_store = store\n",
    "    \n",
    "    # Get schema name for \"kind\" field\n",
    "    schema_name = schema.__name__ if hasattr(schema, \"__name__\") else \"Memory\"\n",
    "\n",
    "    async def amanage_memory(\n",
    "        content: typing.Optional[schema] = None,\n",
    "        action: action_type = default_action,\n",
    "        *,\n",
    "        id: typing.Optional[uuid.UUID] = None,\n",
    "    ):\n",
    "        store = _get_store(initial_store)\n",
    "        if action not in actions_permitted:\n",
    "            raise ValueError(f\"Invalid action {action}. Must be one of {actions_permitted}.\")\n",
    "        if action == \"create\" and id is not None:\n",
    "            raise ValueError(\"Cannot provide ID when creating a memory.\")\n",
    "        if action in (\"delete\", \"update\") and not id:\n",
    "            raise ValueError(\"Must provide ID when deleting or updating.\")\n",
    "        \n",
    "        ns = namespacer()\n",
    "        if action == \"delete\":\n",
    "            await store.adelete(ns, key=str(id))\n",
    "            return f\"Deleted memory {id}\"\n",
    "\n",
    "        id = id or uuid.uuid4()\n",
    "        # PATCHED: Include \"kind\" for cold path compatibility\n",
    "        await store.aput(\n",
    "            ns,\n",
    "            key=str(id),\n",
    "            value={\n",
    "                \"kind\": schema_name,\n",
    "                \"content\": _ensure_json_serializable(content)\n",
    "            },\n",
    "        )\n",
    "        return f\"{action}d memory {id}\"\n",
    "\n",
    "    def manage_memory(\n",
    "        content: typing.Optional[schema] = None,\n",
    "        action: action_type = default_action,\n",
    "        *,\n",
    "        id: typing.Optional[uuid.UUID] = None,\n",
    "    ):\n",
    "        store = _get_store(initial_store)\n",
    "        if action not in actions_permitted:\n",
    "            raise ValueError(f\"Invalid action {action}. Must be one of {actions_permitted}.\")\n",
    "        if action == \"create\" and id is not None:\n",
    "            raise ValueError(\"Cannot provide ID when creating a memory.\")\n",
    "        if action in (\"delete\", \"update\") and not id:\n",
    "            raise ValueError(\"Must provide ID when deleting or updating.\")\n",
    "        \n",
    "        ns = namespacer()\n",
    "        if action == \"delete\":\n",
    "            store.delete(ns, key=str(id))\n",
    "            return f\"Deleted memory {id}\"\n",
    "\n",
    "        id = id or uuid.uuid4()\n",
    "        # PATCHED: Include \"kind\" for cold path compatibility\n",
    "        store.put(\n",
    "            ns,\n",
    "            key=str(id),\n",
    "            value={\n",
    "                \"kind\": schema_name,\n",
    "                \"content\": _ensure_json_serializable(content)\n",
    "            },\n",
    "        )\n",
    "        return f\"{action}d memory {id}\"\n",
    "\n",
    "    description = f\"\"\"Create, update, or delete a memory.\n",
    "Include the MEMORY ID when updating or deleting. Omit when creating.\n",
    "{instructions}\"\"\"\n",
    "\n",
    "    return StructuredTool.from_function(\n",
    "        manage_memory, amanage_memory, name=name, description=description\n",
    "    )\n",
    "\n",
    "print(\"Hot path patched to include 'kind' field\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Setup MongoDB Store for long term memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MongoDBStore initialized for mongodb_genai_devday_agents.memories\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SETUP MONGODB STORE FOR LONG-TERM MEMORY\n",
    "# =============================================================================\n",
    "\n",
    "MEMORY_DB_NAME = \"mongodb_genai_devday_agents\"\n",
    "MEMORY_COLLECTION_NAME = \"memories\"\n",
    "\n",
    "# Get collection reference for direct queries\n",
    "memory_collection = mongodb_client[MEMORY_DB_NAME][MEMORY_COLLECTION_NAME]\n",
    "\n",
    "# Create vector index configuration for semantic search\n",
    "memory_index_config = create_vector_index_config(\n",
    "    dims=1024,\n",
    "    embed=VoyageAIEmbeddings(model=\"voyage-3\"),\n",
    "    fields=[\"content\"],\n",
    "    name=\"memory_vector_index\"\n",
    ")\n",
    "\n",
    "# Initialize MongoDBStore with collection object (NOT from_conn_string)\n",
    "# IMPORTANT: from_conn_string() returns a context manager, not a store object\n",
    "memory_store = MongoDBStore(\n",
    "    collection=memory_collection,\n",
    "    index_config=memory_index_config\n",
    ")\n",
    "\n",
    "print(f\"MongoDBStore initialized for {MEMORY_DB_NAME}.{MEMORY_COLLECTION_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Create hot path tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Memory tools created:\n",
      "   - manage_memory: Save/update/delete memories\n",
      "   - search_memory: Search existing memories\n"
     ]
    }
   ],
   "source": [
    "# Tool for saving/updating/deleting memories\n",
    "\n",
    "manage_memory_tool = create_manage_memory_tool(\n",
    "    namespace=(\"memories\", \"{langgraph_user_id}\"), \n",
    "     store=memory_store, # User-scoped memories\n",
    "     actions_permitted=(\"create\",), \n",
    "   \n",
    ")\n",
    "\n",
    "# Tool for searching memories\n",
    "search_memory_tool = create_search_memory_tool(\n",
    "   namespace=(\"memories\", \"{langgraph_user_id}\"),\n",
    "   store= memory_store\n",
    ")\n",
    "\n",
    "print(\" Memory tools created:\")\n",
    "print(f\"   - {manage_memory_tool.name}: Save/update/delete memories\")\n",
    "print(f\"   - {search_memory_tool.name}: Search existing memories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total tools available: 4\n",
      "   - get_information_for_question_answering\n",
      "   - get_page_content_for_summarization\n",
      "   - manage_memory\n",
      "   - search_memory\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# COMBINE ORIGINAL TOOLS WITH MEMORY TOOLS\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "#To avoid adding duplicates when re-executing the cell\n",
    "tools = tools + [t for t in [manage_memory_tool, search_memory_tool] if t.name not in [x.name for x in tools]]\n",
    "\n",
    "\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "print(f\"✅ Total tools available: {len(tools)}\")\n",
    "for tool in tools:\n",
    "    print(f\"   - {tool.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Create LLM prompt with memory tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Memory-aware prompt created\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CREATE MEMORY-AWARE PROMPT\n",
    "# This prompt instructs the agent to use memory tools\n",
    "# =============================================================================\n",
    "\n",
    "memory_aware_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "       (\n",
    "    \"system\",\n",
    "    \"\"\"You are a helpful AI assistant with persistent memory capabilities.\n",
    "You can answer questions about MongoDB documentation using your tools.\n",
    "\n",
    "## MANDATORY FIRST ACTION:\n",
    "Before responding to ANY user message, you MUST call search_memory first.\n",
    "Do not skip this step. Do not assume you know the user.\n",
    "\n",
    "## CRITICAL RULES:\n",
    "- You have ZERO memory of users unless search_memory returns it\n",
    "- NEVER say \"I remember\" or \"You told me\" without calling search_memory first\n",
    "- If search_memory returns empty, respond with \"I don't have any information about you yet\"\n",
    "\n",
    "## MEMORY INSTRUCTIONS:\n",
    "1. FIRST: Always call search_memory with a relevant query\n",
    "2. THEN: If user shares personal info, use manage_memory to save it\n",
    "3. Acknowledge when you save something to memory\n",
    "\n",
    "## PERSONALIZATION:\n",
    "Based on search_memory results:\n",
    "- Match technical depth to user's expertise level\n",
    "- Focus on topics relevant to their role\n",
    "- Reference their interests naturally\n",
    "\n",
    "## TOOL USAGE:\n",
    "- Do NOT call the same tool more than 2 times\n",
    "- Use documentation tools for technical questions\n",
    "\n",
    "Available tools: {tool_names}\n",
    "\n",
    "REMEMBER: Your FIRST tool call must ALWAYS be search_memory.\"\"\"\n",
    "),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fill in tool names\n",
    "memory_aware_prompt = memory_aware_prompt.partial(\n",
    "    #tool_names=\", \".join([tool.name for tool in tools_with_memory])\n",
    "    tool_names=\", \".join([tool.name for tool in tools])\n",
    ")\n",
    "\n",
    "print(\" Memory-aware prompt created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM chain with memory tools created\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CREATE MEMORY-AWARE LLM CHAIN\n",
    "# =============================================================================\n",
    "\n",
    "llm_with_tools = memory_aware_prompt | llm.bind_tools(tools)\n",
    "\n",
    "print(\"✅ LLM chain with memory tools created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory-aware graph compiled with:\n",
      "   - Checkpointer: Short-term memory (conversation threads)\n",
      "   - Store: Long-term memory (persistent user memories)\n"
     ]
    }
   ],
   "source": [
    "##Recompile the graph with memory_store\n",
    "app_with_memory = graph.compile(\n",
    "    checkpointer=checkpointer,  # Short-term memory (conversation history)\n",
    "    store=memory_store          # Long-term memory (persistent memories)\n",
    ")\n",
    "\n",
    "print(\"Memory-aware graph compiled with:\")\n",
    "print(\"   - Checkpointer: Short-term memory (conversation threads)\")\n",
    "print(\"   - Store: Long-term memory (persistent user memories)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7834643d2550>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE THE MEMORY-AWARE GRAPH\n",
    "# =============================================================================\n",
    "\n",
    "app_with_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXECUTION FUNCTION WITH MEMORY\n",
    "# =============================================================================\n",
    "\n",
    "def run_agent_with_memory(thread_id: str, user_id: str, user_input: str):\n",
    "    \"\"\"\n",
    "    Execute the memory-aware agent.\n",
    "    \n",
    "    Args:\n",
    "        thread_id: Unique conversation thread ID (short-term memory)\n",
    "        user_id: User identifier for memory scoping (long-term memory)\n",
    "        user_input: User's message\n",
    "    \"\"\"\n",
    "    # Config with both thread_id and langgraph_user_id\n",
    "    # IMPORTANT: langgraph_user_id must match the namespace pattern {langgraph_user_id}\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id,\n",
    "            \"langgraph_user_id\": user_id,  # Required for memory namespace\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Thread: {thread_id} | User: {user_id}\")\n",
    "    print(f\"Input: {user_input}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Stream the response\n",
    "    for step in app_with_memory.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        msg = step[\"messages\"][-1]\n",
    "        if hasattr(msg, 'pretty_print'):\n",
    "            msg.pretty_print()\n",
    "        else:\n",
    "            print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoints cleared\n"
     ]
    }
   ],
   "source": [
    "# Drop the checkpointing collection to start fresh\n",
    "#mongodb_client[\"checkpointing_db\"][\"checkpoints\"].drop()\n",
    "#print(\"Checkpoints cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Save User Information to Memory\n",
    "\n",
    "In this test, the user introduces themselves. The agent should:\n",
    "1. Recognize this is personal information\n",
    "2. Use `manage_memory` tool to save it\n",
    "3. Acknowledge that it saved the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Thread: session-0001 | User: user-00001\n",
      "Input: Hi! I'm a senior DBA focusing on disaster recovery and backup strategies.\n",
      "============================================================\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi! I'm a senior DBA focusing on disaster recovery and backup strategies.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_memory (toolu_bdrk_01QECRdHwDmxG3g6CrDP6ggA)\n",
      " Call ID: toolu_bdrk_01QECRdHwDmxG3g6CrDP6ggA\n",
      "  Args:\n",
      "    query: user profile role expertise DBA disaster recovery backup\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "[]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  manage_memory (toolu_bdrk_01XPBbQjBWDZFrXD4H4pD1rK)\n",
      " Call ID: toolu_bdrk_01XPBbQjBWDZFrXD4H4pD1rK\n",
      "  Args:\n",
      "    action: create\n",
      "    content: User is a senior DBA (Database Administrator) with a focus on disaster recovery and backup strategies. This indicates advanced technical expertise and interest in high availability, data protection, backup/restore procedures, and business continuity planning.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "created memory d0a39b2a-6e8d-45b8-a5eb-c5c22562a331\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! Great to meet you! I've saved your profile - as a senior DBA specializing in disaster recovery and backup strategies, you're working on some of the most critical aspects of database management.\n",
      "\n",
      "I can help you with MongoDB documentation related to:\n",
      "- **Backup and restore procedures** (mongodump, mongorestore, filesystem snapshots)\n",
      "- **Point-in-time recovery** strategies\n",
      "- **Replica set configuration** for high availability\n",
      "- **Disaster recovery planning** and failover procedures\n",
      "- **Backup strategies** for sharded clusters\n",
      "- **Cloud backup solutions** (Atlas backups, Ops Manager)\n",
      "- **Recovery time objectives (RTO)** and recovery point objectives (RPO)\n",
      "\n",
      "What specific aspect of MongoDB disaster recovery or backup would you like to explore today?\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST 1: User introduces themselves - Agent should save to memory\n",
    "# =============================================================================\n",
    "\n",
    "run_agent_with_memory(\n",
    "    \"session-0001\",\n",
    "    \"user-00001\",\n",
    "    \"Hi! I'm a senior DBA focusing on disaster recovery and backup strategies.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checking MongoDB for saved memories ===\n",
      "\n",
      "Collection: mongodb_genai_devday_agents.memories\n",
      "\n",
      "Total documents in collection: 1\n",
      "\n",
      "--- Memory Document ---\n",
      "Namespace: ['memories', 'user-00001']\n",
      "Key: d0a39b2a-6e8d-45b8-a5eb-c5c22562a331\n",
      "Value: {'kind': 'str', 'content': 'User is a senior DBA (Database Administrator) with a focus on disaster recovery and backup strategies. This indicates advanced technical expertise and interest in high availability, data protection, backup/restore procedures, and business continuity planning.'}\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VERIFY: Check if memory was saved to MongoDB\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "print(\"=== Checking MongoDB for saved memories ===\")\n",
    "print(f\"\\nCollection: {MEMORY_DB_NAME}.{MEMORY_COLLECTION_NAME}\")\n",
    "\n",
    "# Query memories for user-123\n",
    "user_memories = list(memory_collection.find({}))\n",
    "print(f\"\\nTotal documents in collection: {len(user_memories)}\")\n",
    "\n",
    "for doc in user_memories:\n",
    "    print(f\"\\n--- Memory Document ---\")\n",
    "    print(f\"Namespace: {doc.get('namespace', 'N/A')}\")\n",
    "    print(f\"Key: {doc.get('key', 'N/A')}\")\n",
    "    print(f\"Value: {doc.get('value', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: New Conversation Thread Recalls Memory\n",
    "\n",
    "In this test, we start a NEW conversation thread but with the SAME user.\n",
    "The agent should:\n",
    "1. Search for existing memories about this user\n",
    "2. Find the previously saved information\n",
    "3. Use that context to personalize the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Thread: session-00002 | User: user-00001\n",
      "Input: What do you know about me?\n",
      "============================================================\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What do you know about me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_memory (toolu_bdrk_01G6BoMkpbF6HBhJpgSwCWCt)\n",
      " Call ID: toolu_bdrk_01G6BoMkpbF6HBhJpgSwCWCt\n",
      "  Args:\n",
      "    query: user information preferences background\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "[{\"namespace\":[\"memories\",\"user-00001\"],\"key\":\"d0a39b2a-6e8d-45b8-a5eb-c5c22562a331\",\"value\":{\"kind\":\"str\",\"content\":\"User is a senior DBA (Database Administrator) with a focus on disaster recovery and backup strategies. This indicates advanced technical expertise and interest in high availability, data protection, backup/restore procedures, and business continuity planning.\"},\"created_at\":\"2026-01-06T00:05:01.108000\",\"updated_at\":\"2026-01-06T00:05:01.108000\",\"score\":0.6390223503112793}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on my memory, I know that you are a **senior DBA (Database Administrator)** with a focus on **disaster recovery and backup strategies**. This tells me you have advanced technical expertise and are particularly interested in:\n",
      "\n",
      "- High availability\n",
      "- Data protection\n",
      "- Backup and restore procedures\n",
      "- Business continuity planning\n",
      "\n",
      "Is there anything else you'd like me to know about you, or would you like help with any MongoDB-related topics in these areas?\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST 2: New thread, same user - Agent should recall memory\n",
    "# =============================================================================\n",
    "\n",
    "run_agent_with_memory(\n",
    "    \"session-00002\",  # NEW thread\n",
    "    \"user-00001\",        # SAME user\n",
    "    \"What do you know about me?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Technical Question with User Context\n",
    "\n",
    "Ask a technical question. The agent should:\n",
    "1. Recall that the user is a DBA focused on disaster recovery\n",
    "2. Tailor the response to their expertise level\n",
    "3. Focus on backup/recovery aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Thread: session-0023 | User: user-0123\n",
      "Input: I am a Data Engineer interested in Scaling systems. Looking for the best practices for MongoDB Operations\n",
      "============================================================\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I am a Data Engineer interested in Scaling systems. Looking for the best practices for MongoDB Operations\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_memory (toolu_bdrk_01DrKvcR8ee25WFNJKtDvnUU)\n",
      " Call ID: toolu_bdrk_01DrKvcR8ee25WFNJKtDvnUU\n",
      "  Args:\n",
      "    query: Data Engineer scaling systems MongoDB\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "[]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  manage_memory (toolu_bdrk_01VdjtzdFDQKCNf4oEmPEkMb)\n",
      " Call ID: toolu_bdrk_01VdjtzdFDQKCNf4oEmPEkMb\n",
      "  Args:\n",
      "    action: create\n",
      "    content: User is a Data Engineer with interest in scaling systems and MongoDB operations best practices\n",
      "  get_information_for_question_answering (toolu_bdrk_017iCef4zw48hCKYMhBapUYY)\n",
      " Call ID: toolu_bdrk_017iCef4zw48hCKYMhBapUYY\n",
      "  Args:\n",
      "    user_query: MongoDB operations best practices scaling systems\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# MongoDB Performance\n",
      "\n",
      "As you develop and operate applications with MongoDB, you may need to analyze the performance of the application and its database. When you encounter degraded performance, it is often a function of database access strategies, hardware availability, and the number of open database connections.\n",
      "\n",
      "Some users may experience performance limitations as a result of inadequate or inappropriate indexing strategies, or as a consequence of poor schema design patterns. Locking Performance discusses how these can impact MongoDB's internal locking.\n",
      "\n",
      "Performance issues may indicate that the database is operating at capacity and that it is time to add additional capacity to the database. In particular, the application's working set should fit in the available physical memory.\n",
      "\n",
      "In some cases performance issues may be temporary and related to abnormal traffic load. As discussed in Number of Connections, scaling can help relax excessive traffic.\n",
      "\n",
      "Database profiling can help you to understand what operations are causing degradation.\n",
      "\n",
      "## Locking Performance\n",
      "\n",
      "For write-heavy applications, deploy sharding and add one or more shards to a sharded cluster to distribute load among `mongod` instances.\n",
      "\n",
      "Spikes in the number of connections can also be the result of application or driver errors. All of the officially supported MongoDB drivers implement connection pooling, which allows clients to use and reuse connections more efficiently. An extremely high number of connections, particularly without corresponding workload, is often indicative of a driver or other configuration error.\n",
      "\n",
      "Unless constrained by system-wide limits, the maximum number of incoming connections supported by MongoDB is configured with the `maxIncomingConnections` setting. On Unix-based systems, system-wide limits can be modified using the `ulimit` command, or by editing your system's `/etc/sysctl` file. See UNIX `ulimit` Settings for more information.\n",
      "\n",
      "## Full Time Diagnostic Data Capture\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "If `globalLock.totalTime` is high relative to `uptime`, the database has existed in a lock state for a significant amount of time.\n",
      "\n",
      "Long queries can result from ineffective use of indexes; non-optimal schema design; poor query structure; system architecture issues; or insufficient RAM resulting in disk reads.\n",
      "\n",
      "## Number of Connections\n",
      "\n",
      "In some cases, the number of connections between the applications and the database can overwhelm the ability of the server to handle requests. The following fields in the `serverStatus` document can provide insight:\n",
      "\n",
      "- `connections` is a container for the following two fields:\n",
      "\n",
      "  - `connections.current` the total number of current clients connected to the database instance.\n",
      "\n",
      "  - `connections.available` the total number of unused connections available for new clients.\n",
      "\n",
      "If there are numerous concurrent application requests, the database may have trouble keeping up with demand. If this is the case, increase the capacity of your deployment.\n",
      "\n",
      "MongoDB uses a locking system to ensure data set consistency. If certain operations are long-running or a queue forms, performance will degrade as requests and operations wait for the lock.\n",
      "\n",
      "Lock-related slowdowns can be intermittent. To see if the lock has been affecting your performance, refer to the locks section and the globalLock section of the `serverStatus` output.\n",
      "\n",
      "Dividing `locks.<type>.timeAcquiringMicros` by `locks.<type>.acquireWaitCount` can give an approximate average wait time for a particular lock mode.\n",
      "\n",
      "`locks.<type>.deadlockCount` provide the number of times the lock acquisitions encountered deadlocks.\n",
      "\n",
      "If `globalLock.currentQueue.total` is consistently high, then there is a chance that a large number of requests are waiting for a lock. This indicates a possible concurrency issue that may be affecting performance.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great! I've saved your profile and found some excellent information on MongoDB operations best practices for scaling. Let me get you more comprehensive details on this topic.\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_016t27ve53RiLD3bv3Fz8Mmi)\n",
      " Call ID: toolu_bdrk_016t27ve53RiLD3bv3Fz8Mmi\n",
      "  Args:\n",
      "    user_query: MongoDB sharding replication scaling deployment best practices capacity planning\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "For write-heavy applications, deploy sharding and add one or more shards to a sharded cluster to distribute load among `mongod` instances.\n",
      "\n",
      "Spikes in the number of connections can also be the result of application or driver errors. All of the officially supported MongoDB drivers implement connection pooling, which allows clients to use and reuse connections more efficiently. An extremely high number of connections, particularly without corresponding workload, is often indicative of a driver or other configuration error.\n",
      "\n",
      "Unless constrained by system-wide limits, the maximum number of incoming connections supported by MongoDB is configured with the `maxIncomingConnections` setting. On Unix-based systems, system-wide limits can be modified using the `ulimit` command, or by editing your system's `/etc/sysctl` file. See UNIX `ulimit` Settings for more information.\n",
      "\n",
      "## Full Time Diagnostic Data Capture\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "# MongoDB Performance\n",
      "\n",
      "As you develop and operate applications with MongoDB, you may need to analyze the performance of the application and its database. When you encounter degraded performance, it is often a function of database access strategies, hardware availability, and the number of open database connections.\n",
      "\n",
      "Some users may experience performance limitations as a result of inadequate or inappropriate indexing strategies, or as a consequence of poor schema design patterns. Locking Performance discusses how these can impact MongoDB's internal locking.\n",
      "\n",
      "Performance issues may indicate that the database is operating at capacity and that it is time to add additional capacity to the database. In particular, the application's working set should fit in the available physical memory.\n",
      "\n",
      "In some cases performance issues may be temporary and related to abnormal traffic load. As discussed in Number of Connections, scaling can help relax excessive traffic.\n",
      "\n",
      "Database profiling can help you to understand what operations are causing degradation.\n",
      "\n",
      "## Locking Performance\n",
      "\n",
      "If `globalLock.totalTime` is high relative to `uptime`, the database has existed in a lock state for a significant amount of time.\n",
      "\n",
      "Long queries can result from ineffective use of indexes; non-optimal schema design; poor query structure; system architecture issues; or insufficient RAM resulting in disk reads.\n",
      "\n",
      "## Number of Connections\n",
      "\n",
      "In some cases, the number of connections between the applications and the database can overwhelm the ability of the server to handle requests. The following fields in the `serverStatus` document can provide insight:\n",
      "\n",
      "- `connections` is a container for the following two fields:\n",
      "\n",
      "  - `connections.current` the total number of current clients connected to the database instance.\n",
      "\n",
      "  - `connections.available` the total number of unused connections available for new clients.\n",
      "\n",
      "If there are numerous concurrent application requests, the database may have trouble keeping up with demand. If this is the case, increase the capacity of your deployment.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Perfect! Based on your interest in scaling systems, here are the **key MongoDB operations best practices** for scaling:\n",
      "\n",
      "## 🎯 **Core Scaling Strategies**\n",
      "\n",
      "### **1. Sharding for Horizontal Scaling**\n",
      "- **For write-heavy applications**: Deploy sharding and add shards to distribute load among `mongod` instances\n",
      "- Sharding allows you to scale beyond single-server limitations\n",
      "- Manage the cluster balancer carefully - schedule it during maintenance windows for backup operations\n",
      "\n",
      "### **2. Performance Monitoring & Diagnostics**\n",
      "\n",
      "**Key Metrics to Watch:**\n",
      "- **Working Set**: Ensure your application's working set fits in available physical memory\n",
      "- **Connection Management**:\n",
      "  - Monitor `connections.current` and `connections.available` via `serverStatus`\n",
      "  - Use connection pooling (built into all official MongoDB drivers)\n",
      "  - High connections without corresponding workload often indicates driver/configuration errors\n",
      "  - Configure `maxIncomingConnections` appropriately\n",
      "\n",
      "- **Lock Performance**:\n",
      "  - Monitor `globalLock.totalTime` relative to `uptime`\n",
      "  - Check `globalLock.currentQueue.total` - consistently high values indicate concurrency issues\n",
      "  - Calculate average wait time: `locks.<type>.timeAcquiringMicros / locks.<type>.acquireWaitCount`\n",
      "\n",
      "### **3. Capacity Planning Indicators**\n",
      "\n",
      "**When to Scale:**\n",
      "- Database operating at capacity\n",
      "- Working set exceeds physical memory (causing disk reads)\n",
      "- High connection counts overwhelming server capacity\n",
      "- Consistent lock queues affecting performance\n",
      "- Abnormal traffic spikes\n",
      "\n",
      "### **4. Query & Schema Optimization**\n",
      "- Implement proper **indexing strategies** (inadequate indexes are a common bottleneck)\n",
      "- Optimize **schema design patterns**\n",
      "- Use **database profiling** to identify degraded operations\n",
      "- Address long-running queries that may result from ineffective indexes or poor query structure\n",
      "\n",
      "### **5. System Configuration**\n",
      "- Adjust `ulimit` settings on Unix-based systems\n",
      "- Configure `/etc/sysctl` for system-wide limits\n",
      "- Use `maxTimeMS()` and `db.killOp()` to manage long-running operations\n",
      "\n",
      "### **6. Backup Strategy for Scaled Deployments**\n",
      "- Use coordinated backup processes (Atlas, Cloud Manager, Ops Manager) for sharded clusters\n",
      "- Stop balancer during backups\n",
      "- Consider file system snapshots for efficiency\n",
      "\n",
      "## 💡 **Quick Win for Data Engineers**\n",
      "Enable **Full Time Diagnostic Data Capture** to continuously monitor performance and identify bottlenecks before they become critical issues.\n",
      "\n",
      "Would you like me to dive deeper into any specific area, such as sharding configuration, monitoring setup, or index optimization strategies?\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST 3: Technical question - Agent should use memory context\n",
    "# =============================================================================\n",
    "\n",
    "run_agent_with_memory(\n",
    "    \"session-0023\",\n",
    "    \"user-0123\",\n",
    "    \"I am a Data Engineer interested in Scaling systems. Looking for the best practices for MongoDB Operations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: Different User (Memory Isolation)\n",
    "\n",
    "Test with a different user to verify memory isolation.\n",
    "This user should NOT see user-123's memories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Thread: session-00044 | User: user-456\n",
      "Input:  I'm a Data Engineer. Tell me about  MongoDB Atlas scaling.\n",
      "============================================================\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      " I'm a Data Engineer. Tell me about  MongoDB Atlas scaling.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_memory (toolu_bdrk_01WteDkPSKdj6j1yh7348YfH)\n",
      " Call ID: toolu_bdrk_01WteDkPSKdj6j1yh7348YfH\n",
      "  Args:\n",
      "    query: Data Engineer user information preferences\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "[]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  manage_memory (toolu_bdrk_012TgD46uSvUCC1WknewDEHc)\n",
      " Call ID: toolu_bdrk_012TgD46uSvUCC1WknewDEHc\n",
      "  Args:\n",
      "    action: create\n",
      "    content: User is a Data Engineer interested in MongoDB Atlas scaling\n",
      "  get_information_for_question_answering (toolu_bdrk_01MGbJ9qbyvb5GQYojc6yx8V)\n",
      " Call ID: toolu_bdrk_01MGbJ9qbyvb5GQYojc6yx8V\n",
      "  Args:\n",
      "    user_query: MongoDB Atlas scaling options vertical horizontal auto-scaling\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Percentage of used disk space on a partition reaches a specified threshold.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Query Targeting Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Indicates inefficient queries.\n",
      "\n",
      "The change streams cursors that the Atlas Search process (`mongot`) uses to keep Atlas Search indexes updated can contribute to the query targeting ratio and trigger query targeting alerts if the ratio is high.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Replica Set Has No Primary\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "No primary is detected in replica set.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Replication Oplog Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Amount of oplog data generated on a primary cluster member is larger than the cluster's configured oplog size.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "System CPU Usage Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "CPU usage of the MongoDB process reaches a specified threshold.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "</table>\n",
      "\n",
      "<Tab name=\"Project Alerts\">\n",
      "\n",
      "You can retrieve events for a project using the get all API (Application Programming Interface) resource.\n",
      "\n",
      "</Tab>\n",
      "\n",
      "</Tabs>\n",
      "\n",
      "## Resolutions for Specific Alerts\n",
      "\n",
      "The following sections describe Atlas\n",
      "alert conditions and suggest steps for resolving them.\n",
      "\n",
      "<table>\n",
      "<tr>\n",
      "<th id=\"Alert%20Type\">\n",
      "Alert Type\n",
      "\n",
      "</th>\n",
      "<th id=\"Description\">\n",
      "Description\n",
      "\n",
      "</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Atlas Search Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Amount of CPU and memory used by Atlas Search processes reach a specified threshold.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Connection Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Number of connections to a MongoDB process exceeds the allowable maximum.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Disk Space % Used Alerts\n",
      "\n",
      "For write-heavy applications, deploy sharding and add one or more shards to a sharded cluster to distribute load among `mongod` instances.\n",
      "\n",
      "Spikes in the number of connections can also be the result of application or driver errors. All of the officially supported MongoDB drivers implement connection pooling, which allows clients to use and reuse connections more efficiently. An extremely high number of connections, particularly without corresponding workload, is often indicative of a driver or other configuration error.\n",
      "\n",
      "Unless constrained by system-wide limits, the maximum number of incoming connections supported by MongoDB is configured with the `maxIncomingConnections` setting. On Unix-based systems, system-wide limits can be modified using the `ulimit` command, or by editing your system's `/etc/sysctl` file. See UNIX `ulimit` Settings for more information.\n",
      "\n",
      "## Full Time Diagnostic Data Capture\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_018jbcpXGxjVfxKxbhEetQTd)\n",
      " Call ID: toolu_bdrk_018jbcpXGxjVfxKxbhEetQTd\n",
      "  Args:\n",
      "    user_query: MongoDB Atlas cluster tier scaling auto-scaling storage compute\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "To learn more, see the Queues alert conditions.\n",
      "\n",
      "### CPU Steal\n",
      "\n",
      "AWS EC2 clusters that support Burstable Performance might experience CPU steal when using shared CPU cores. This alert condition measures the percentage by which the CPU usage exceeds the guaranteed baseline CPU credit accumulation rate.\n",
      "\n",
      "CPU credits are units of CPU utilization that you accumulate. The credits accumulate at a constant rate to provide a guaranteed level of performance. These credits can be used for additional CPU performance. When the credit balance is exhausted, only the guaranteed baseline of CPU performance is provided, and the amount of excess is shown as steal percent.\n",
      "\n",
      "You can view CPU usage on the Normalized System CPU chart, accessed through cluster monitoring.\n",
      "\n",
      "To learn more, see the `System: CPU (Steal) % is` alert condition.\n",
      "\n",
      "### Query Targeting\n",
      "\n",
      "Properly configured indexes can significantly improve query performance. These alert conditions help identify inefficient queries. Too many indexes can impact write performance.\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Percentage of used disk space on a partition reaches a specified threshold.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Query Targeting Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Indicates inefficient queries.\n",
      "\n",
      "The change streams cursors that the Atlas Search process (`mongot`) uses to keep Atlas Search indexes updated can contribute to the query targeting ratio and trigger query targeting alerts if the ratio is high.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Replica Set Has No Primary\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "No primary is detected in replica set.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "Replication Oplog Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "Amount of oplog data generated on a primary cluster member is larger than the cluster's configured oplog size.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td headers=\"Alert%20Type\">\n",
      "System CPU Usage Alerts\n",
      "\n",
      "</td>\n",
      "<td headers=\"Description\">\n",
      "CPU usage of the MongoDB process reaches a specified threshold.\n",
      "\n",
      "</td>\n",
      "</tr>\n",
      "</table>\n",
      "\n",
      "You can view these metrics on the Query Targeting chart, accessed through cluster monitoring.\n",
      "\n",
      "To learn more, see the Query Targeting alert conditions.\n",
      "\n",
      "### Connection Limits\n",
      "\n",
      "Each Atlas instance has a connection limit. These alert conditions help you proactively address scaling needs or potential issues related to connection availability.\n",
      "\n",
      "You can view these metrics on the Connections chart, accessed through cluster monitoring.\n",
      "\n",
      "To learn more, see the Connection alert conditions.\n",
      "\n",
      "## Configure Alerts\n",
      "\n",
      "To set which conditions trigger alerts and how users are notified, Configure Alert Settings. You can configure alerts at the organization or project level. Atlas provides default alerts at the project level. You can clone existing alerts and configure maintenance window alerts.\n",
      "\n",
      "Experiment with alert condition values based on your specific requirements. Periodically reassess these values for optimal performance.\n",
      "\n",
      "### Tickets Available\n",
      "\n",
      "Configure the alert settings to send an alert if these metrics drop below 30 for at least a few minutes. You want to avoid false positives triggered by relatively harmless short-term drops, but catch issues when these metrics stay low for a while.\n",
      "\n",
      "To configure these alert conditions, see Configure Alert Settings.\n",
      "\n",
      "### Queues\n",
      "\n",
      "Configure the alert settings to send an alert if these metrics rise above 100 for a minute. You want to avoid false positives triggered by relatively harmless short-term spikes, but catch issues when these metrics stay elevated for a while.\n",
      "\n",
      "To configure these alert conditions, see Configure Alert Settings.\n",
      "\n",
      "### CPU Steal\n",
      "\n",
      "Configure the alert settings to send an alert if this metric rises above 10%.\n",
      "\n",
      "To configure this alert condition, see Configure Alert Settings.\n",
      "\n",
      "### Query Targeting\n",
      "\n",
      "Configure the alert settings to send an alert if this metric rises above 50 or 100.\n",
      "\n",
      "To configure these alert conditions, see Configure Alert Settings.\n",
      "\n",
      "### Connection Limits\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great! As a Data Engineer, you'll want to understand MongoDB Atlas's comprehensive scaling capabilities. Let me break down the key scaling options:\n",
      "\n",
      "## **MongoDB Atlas Scaling Options**\n",
      "\n",
      "### **1. Vertical Scaling (Cluster Tier)**\n",
      "You can scale your cluster up or down by changing the cluster tier, which adjusts:\n",
      "- **Compute resources** (CPU and RAM)\n",
      "- **Storage capacity**\n",
      "- **IOPS performance**\n",
      "\n",
      "Atlas offers various cluster tiers from shared clusters (M0, M2, M5) to dedicated clusters (M10 through M700+) for production workloads.\n",
      "\n",
      "### **2. Horizontal Scaling (Sharding)**\n",
      "For write-heavy applications and large datasets:\n",
      "- **Deploy sharding** to distribute data across multiple shards\n",
      "- **Add shards** to distribute load among `mongod` instances\n",
      "- Each shard is a replica set, providing both scalability and high availability\n",
      "\n",
      "### **3. Auto-Scaling**\n",
      "Atlas provides automated scaling capabilities:\n",
      "- **Storage auto-scaling**: Automatically increases storage capacity when thresholds are met\n",
      "- **Compute auto-scaling**: Can automatically adjust cluster tier based on workload demands\n",
      "\n",
      "### **4. Connection Management**\n",
      "- MongoDB uses **connection pooling** through official drivers for efficient connection reuse\n",
      "- Maximum connections configured via `maxIncomingConnections` setting\n",
      "- Monitor connection metrics to identify when scaling is needed\n",
      "\n",
      "### **Key Monitoring Metrics for Scaling Decisions**\n",
      "Atlas provides alerts for:\n",
      "- **CPU usage** thresholds\n",
      "- **Disk space utilization**\n",
      "- **Connection limits**\n",
      "- **Query targeting** (inefficient queries)\n",
      "- **Queue depths** (tickets available)\n",
      "\n",
      "**Pro tip**: Configure alerts to proactively identify when you need to scale. For example, set alerts when disk usage reaches certain thresholds or when connection counts approach limits.\n",
      "\n",
      "Would you like more details on any specific scaling aspect, such as auto-scaling configuration or sharding strategies?\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST 4: Different user - Should NOT have user-123's memories\n",
    "# =============================================================================\n",
    "\n",
    "run_agent_with_memory(\n",
    "    thread_id=\"session-00044\",\n",
    "    user_id=\"user-456\",  # DIFFERENT user\n",
    "    user_input=\" I'm a Data Engineer. Tell me about  MongoDB Atlas scaling.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Thread: session-00045 | User: user-456\n",
      "Input:  I'm a DBA   interested in MongoDB Atlas functions.\n",
      "============================================================\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      " I'm a DBA   interested in MongoDB Atlas functions.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_memory (toolu_bdrk_01B4m4RCiRT7PTPz9deCJS5E)\n",
      " Call ID: toolu_bdrk_01B4m4RCiRT7PTPz9deCJS5E\n",
      "  Args:\n",
      "    query: DBA MongoDB Atlas functions\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "[{\"namespace\":[\"memories\",\"user-456\"],\"key\":\"ed74b3b3-aab6-4b76-93f7-f282a262f087\",\"value\":{\"kind\":\"str\",\"content\":\"User is a Data Engineer interested in MongoDB Atlas scaling\"},\"created_at\":\"2026-01-06T00:07:40.929000\",\"updated_at\":\"2026-01-06T00:07:40.929000\",\"score\":0.767501711845398}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  manage_memory (toolu_bdrk_01Eja9D6G2gYpoeP4RSFeRkn)\n",
      " Call ID: toolu_bdrk_01Eja9D6G2gYpoeP4RSFeRkn\n",
      "  Args:\n",
      "    action: create\n",
      "    content: User is a DBA interested in MongoDB Atlas functions\n",
      "  get_information_for_question_answering (toolu_bdrk_01Rqt1kMQhfgEkFzALFs7mdc)\n",
      " Call ID: toolu_bdrk_01Rqt1kMQhfgEkFzALFs7mdc\n",
      "  Args:\n",
      "    user_query: MongoDB Atlas functions overview features capabilities\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "### **[Episode 3: Indexing][4]**\n",
      "\n",
      "While Atlas Search automatically indexes your collections content, it does demand attention to the indexing configuration details in order to match users queries appropriately. This episode covers how Atlas Search builds an inverted index, and the options one must consider.\n",
      "\n",
      "### **[Episode 4: Searching][5]**\n",
      "\n",
      "Atlas Search provides a rich set of query operators and relevancy controls. This episode covers the common query operators, their relevancy controls, and ends with coverage of the must-have Query Analytics feature.\n",
      "\n",
      "### **[Episode 5:  Faceting][6]**\n",
      "\n",
      "Facets produce additional context for search results, providing a list of subsets and counts within. This episode details the faceting options available in Atlas Search.\n",
      "\n",
      "### **[Episode 6: Advanced Search Topics][7]**\n",
      "\n",
      "In this episode, we go through some more advanced search topics including embedded documents, fuzzy search, autocomplete, highlighting, and geospatial.\n",
      "\n",
      "[1]: https://www.mongodb.com/atlas/search\n",
      "  [2]: https://www.mongodb.com/developer/videos/what-is-atlas-search-quick-start/\n",
      "  [3]: https://www.mongodb.com/developer/videos/atlas-search-configuration-development-environment/\n",
      "  [4]: https://www.mongodb.com/developer/videos/mastering-indexing-for-perfect-query-matches/\n",
      "  [5]: https://www.mongodb.com/developer/videos/query-operators-relevancy-controls-for-precision-searches/\n",
      "  [6]: https://www.mongodb.com/developer/videos/faceting-mastery-unlock-the-full-potential-of-atlas-search-s-contextual-insights/\n",
      "  [7]: https://www.mongodb.com/developer/videos/atlas-search-mastery-elevate-your-search-with-fuzzy-geospatial-highlighting-hacks/\n",
      "  [8]: https://www.mongodb.com/developer/videos/atlas-search-query-analytics/\n",
      "\n",
      "### **[Episode 7:  Query Analytics][8]**\n",
      "\n",
      "Are your users finding what they are looking for? Are your top queries returning the best results? This episode covers the important topic of query analytics. If you're using search, you need this!\n",
      "\n",
      "### **[Episode 8:  Tips & Tricks][9]**\n",
      "\n",
      "In this final episode of The Atlas Search 'cene Season 1, useful techniques to introspect query details and see the relevancy scoring computation details. Also shown is how to get facets and search results back in one API call.\n",
      "\n",
      "# The Atlas Search 'cene: Season 1\n",
      "\n",
      "# The Atlas Search 'cene: Season 1\n",
      "\n",
      "Welcome to the first season of a video series dedicated to Atlas Search!  This series of videos is designed to guide you through the journey from getting started and understanding the concepts, to advanced techniques.\n",
      "\n",
      "## What is Atlas Search?\n",
      "\n",
      "[Atlas Search][1] is an embedded full-text search in MongoDB Atlas that gives you a seamless, scalable experience for building relevance-based app features. Built on Apache Lucene, Atlas Search eliminates the need to run a separate search system alongside your database.\n",
      "\n",
      "By integrating the database, search engine, and sync mechanism into a single, unified, and fully managed platform, Atlas Search is the fastest and easiest way to build relevance-based search capabilities directly into applications.\n",
      "\n",
      "> Hip to the *'cene*\n",
      "> \n",
      "> The name of this video series comes from a contraction of \"Lucene\",\n",
      "> the search engine library leveraged by Atlas. Or it's a short form of \"scene\". \n",
      "\n",
      "## Episode Guide\n",
      "\n",
      "### **[Episode 1: What is Atlas Search & Quick Start][2]**\n",
      "\n",
      "In this first episode of the Atlas Search 'cene, learn what Atlas Search is, and get a quick start introduction to setting up Atlas Search on your data.  Within a few clicks, you can set up a powerful, full-text search index on your Atlas collection data, and leverage the fast, relevant results to your users queries.\n",
      "\n",
      "### **[Episode 2: Configuration / Development Environment][3]**\n",
      "\n",
      "In order to best leverage Atlas Search, configuring it for your querying needs leads to success. In this episode, learn how Atlas Search maps your documents to its index, and discover the configuration control you have.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great! I've saved that you're a DBA interested in MongoDB Atlas functions. Let me get you the right information about Atlas Functions.\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01VT7uPBzt7E8y8795yhhLGj)\n",
      " Call ID: toolu_bdrk_01VT7uPBzt7E8y8795yhhLGj\n",
      "  Args:\n",
      "    user_query: Atlas Functions serverless functions triggers database operations\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "### Main trigger logic\n",
      "\n",
      "The main trigger logic is invoked when an update change event is detected with a `\"process\" : false` field.\n",
      "```javascript\n",
      "exports = async function(changeEvent) {\n",
      "  // A Database Trigger will always call a function with a changeEvent.\n",
      "  // Documentation on ChangeEvents: https://www.mongodb.com/docs/manual/reference/change-events\n",
      "\n",
      "  // This sample function will listen for events and replicate them to a collection in a different Database\n",
      "function sampleReviews(reviews) {\n",
      "// Logic above...\n",
      "   if (reviews.length <= 50) {\n",
      "        return reviews;\n",
      "    }\n",
      "    const sampledReviews = [];\n",
      "    const seenIndices = new Set();\n",
      "\n",
      "    while (sampledReviews.length < 50) {\n",
      "        const randomIndex = Math.floor(Math.random() * reviews.length);\n",
      "        if (!seenIndices.has(randomIndex)) {\n",
      "            seenIndices.add(randomIndex);\n",
      "            sampledReviews.push(reviews[randomIndex]);\n",
      "        }\n",
      "    }\n",
      "\n",
      "    return sampledReviews;\n",
      "}\n",
      "\n",
      "// Access the _id of the changed document:\n",
      "  const docId = changeEvent.documentKey._id;\n",
      "  const doc= changeEvent.fullDocument;\n",
      "  \n",
      "\n",
      "  // Get the MongoDB service you want to use (see \"Linked Data Sources\" tab)\n",
      "  const serviceName = \"mongodb-atlas\";\n",
      "  const databaseName = \"sample_airbnb\";\n",
      "  const collection = context.services.get(serviceName).db(databaseName).collection(changeEvent.ns.coll);\n",
      "\n",
      " // This function is the endpoint's request handler. \n",
      "    // URL to make the request to the OpenAI API.\n",
      "    const url = 'https://api.openai.com/v1/chat/completions';\n",
      "\n",
      "    // Fetch the OpenAI key stored in the context values.\n",
      "    const openai_key = context.values.get(\"openAIKey\");\n",
      "\n",
      "    const reviews = doc.reviews.map((review) => {return {\"comments\" : review.comments}});\n",
      "    \n",
      "    const sampledReviews= sampleReviews(reviews);\n",
      "\n",
      "- API request preparation: Reviews from the changed document are sampled and prepared into a request string for the OpenAI API. The format and instructions are tailored to ensure the API returns a valid JSON with summarized content and tags.\n",
      "- API interaction: Using the context.http.post method, the trigger sends the prepared data to the OpenAI API.\n",
      "- Updating the original document: Upon a successful response from the API, the trigger updates the original document with the summarized content, negative tags (neg_tags), positive tags (pos_tags), and a process flag set to true.\n",
      "\n",
      "const code = responseData.choices[0].message.content;\n",
      "        // Get the required data to be added into the document\n",
      "        const updateDoc = JSON.parse(code)\n",
      "        // Set a flag that this document does not need further re-processing \n",
      "        updateDoc.process = true\n",
      "        await collection.updateOne({_id : docId}, {$set : updateDoc});\n",
      "      \n",
      "\n",
      "    } else {\n",
      "        console.error(\"Failed to generate filter JSON.\");\n",
      "        console.log(JSON.stringify(responseData));\n",
      "        return {};\n",
      "    }\n",
      "};\n",
      "```\n",
      "\n",
      "Key steps include:\n",
      "\n",
      "Example of a review update operation that will fire this trigger:\n",
      "```javascript\n",
      "listingsAndReviews.updateOne({\"_id\" : \"1129303\"}, { $push : { \"reviews\" : new_review } , $set : { \"process\" : false\" }});\n",
      "```\n",
      "\n",
      "### Sample reviews function\n",
      "To prevent overloading the API with a large number of reviews, a function sampleReviews is defined to randomly sample up to 50 reviews:\n",
      "\n",
      "```javscript\n",
      "function sampleReviews(reviews) {\n",
      "    if (reviews.length <= 50) {\n",
      "        return reviews;\n",
      "    }\n",
      "\n",
      "    const sampledReviews = ];\n",
      "    const seenIndices = new Set();\n",
      "\n",
      "    while (sampledReviews.length < 50) {\n",
      "        const randomIndex = Math.floor(Math.random() * reviews.length);\n",
      "        if (!seenIndices.has(randomIndex)) {\n",
      "            seenIndices.add(randomIndex);\n",
      "            sampledReviews.push(reviews[randomIndex]);\n",
      "        }\n",
      "    }\n",
      "\n",
      "    return sampledReviews;\n",
      "}\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Perfect! **MongoDB Atlas Functions** are serverless functions that let you execute application logic directly in Atlas. As a DBA, you'll find them particularly useful for automating database operations and responding to data changes. Here's what you should know:\n",
      "\n",
      "## Key Capabilities:\n",
      "\n",
      "**1. Database Triggers**\n",
      "- Automatically execute functions in response to database changes (inserts, updates, deletes)\n",
      "- React to change events in real-time\n",
      "- Access full document data through `changeEvent.fullDocument`\n",
      "\n",
      "**2. Serverless Execution**\n",
      "- Write JavaScript functions that run on Atlas infrastructure\n",
      "- No server management required\n",
      "- Integrated with MongoDB services via `context.services.get()`\n",
      "\n",
      "**3. Common DBA Use Cases:**\n",
      "- **Data validation and enrichment** - Automatically process new documents\n",
      "- **Audit logging** - Track changes across collections\n",
      "- **Data replication** - Sync data between databases or collections\n",
      "- **Automated maintenance** - Schedule cleanup tasks\n",
      "- **Integration with external APIs** - Call third-party services when data changes\n",
      "\n",
      "**4. Access Patterns:**\n",
      "```javascript\n",
      "// Access MongoDB from within a function\n",
      "const serviceName = \"mongodb-atlas\";\n",
      "const db = context.services.get(serviceName).db(\"myDatabase\");\n",
      "const collection = db.collection(\"myCollection\");\n",
      "\n",
      "// Perform operations\n",
      "await collection.updateOne({_id: docId}, {$set: updateDoc});\n",
      "```\n",
      "\n",
      "**5. Security & Context:**\n",
      "- Store sensitive data (API keys, credentials) in **Context Values**\n",
      "- Access via `context.values.get(\"keyName\")`\n",
      "- Functions run with defined execution roles and permissions\n",
      "\n",
      "Would you like to dive deeper into setting up triggers, scheduling functions, or any specific automation scenario you have in mind?\n"
     ]
    }
   ],
   "source": [
    "run_agent_with_memory(\n",
    "     thread_id=\"session-00045\",\n",
    "    user_id=\"user-456\",  # DIFFERENT user\n",
    "    user_input=\" I'm a DBA   interested in MongoDB Atlas functions.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Adding Cold path for summarization at the end of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmem import create_memory_store_manager\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLD_PATH_INSTRUCTIONS = \"\"\"You are a memory consolidation system. Your job is to MERGE and CLEAN UP memories.\n",
    "\n",
    "STRICT RULES:\n",
    "1. MAXIMUM 1 memory per user - never more\n",
    "2. You MUST DELETE all old memories after merging them\n",
    "3. Create ONE new consolidated memory with ALL information\n",
    "\n",
    "REQUIRED ACTIONS:\n",
    "1. READ all existing memories\n",
    "2. MERGE all information into ONE comprehensive memory  \n",
    "3. DELETE every old memory (use the delete/remove function)\n",
    "4. SAVE the single merged memory\n",
    "\n",
    "FORMAT for the single memory:\n",
    "\"User Profile: [role] at [company]. Works with [technologies]. Preferences: [preferences]. Interests: [interests].\"\n",
    "\n",
    "CRITICAL: If you see 3 existing memories, your output should be:\n",
    "- DELETE mem-001\n",
    "- DELETE mem-002  \n",
    "- DELETE mem-003\n",
    "- CREATE one consolidated memory\n",
    "\n",
    "DO NOT just add a new memory. You MUST delete the old ones.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_store_manager = create_memory_store_manager(\n",
    "    llm,\n",
    "    namespace=(\"memories\", \"{langgraph_user_id}\"),  \n",
    "    store=memory_store,                             \n",
    "    instructions=COLD_PATH_INSTRUCTIONS,\n",
    "    enable_inserts=True,\n",
    "    enable_deletes=True,\n",
    "    query_model=llm,\n",
    "    query_limit=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def queue_memory_consolidation(reason: str = \"conversation_ended\") -> str:\n",
    "    \"\"\"\n",
    "    Consolidate memories for the current user.\n",
    "    Call this tool when the user says goodbye.\n",
    "    \"\"\"\n",
    "    config = {\"configurable\": {\"langgraph_user_id\": _current_user_id}}\n",
    "    \n",
    "    try:\n",
    "        # Synchronous call - no executor needed\n",
    "        result = memory_store_manager.invoke(\n",
    "            {\n",
    "                \"messages\": _current_conversation_messages,\n",
    "                \"max_steps\": 3\n",
    "            },\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        print(f\"📝 Consolidation complete for user: {_current_user_id}\")\n",
    "        print(f\"   Memories created/updated: {len(result)}\")\n",
    "        for r in result:\n",
    "            print(f\"   - {r['value']}\")\n",
    "        \n",
    "        return f\"Memory consolidation complete. Updated {len(result)} memories.\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Consolidation failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return f\"Failed: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tools updated. Total: 5\n",
      "   - get_information_for_question_answering\n",
      "   - get_page_content_for_summarization\n",
      "   - manage_memory\n",
      "   - search_memory\n",
      "   - queue_memory_consolidation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tools = tools + [t for t in [queue_memory_consolidation] if t.name not in [x.name for x in tools]]\n",
    "#tools = tools + [queue_memory_consolidation]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "print(f\" Tools updated. Total: {len(tools)}\")\n",
    "for t in tools:\n",
    "    print(f\"   - {t.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "memory_aware_prompt_with_goodbye = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "    \"system\",\n",
    "    \"\"\"You are a helpful AI assistant with persistent memory capabilities.\n",
    "You can answer questions about MongoDB documentation using your tools.\n",
    "\n",
    "## CRITICAL MEMORY RULES:\n",
    "- You have NO built-in memory of users\n",
    "- You ONLY know what search_memory returns\n",
    "- NEVER claim to remember something without calling search_memory first\n",
    "- If search_memory returns empty, say \"I don't have any information about you yet\"\n",
    "\n",
    "## MEMORY INSTRUCTIONS:\n",
    "1. When a user shares personal information (role, expertise, preferences, interests),\n",
    "   ALWAYS use manage_memory to save it immediately\n",
    "2. Acknowledge when you save something to memory\n",
    "3. Tailor your responses based on what search_memory returns:\n",
    "   - Match technical depth to user's expertise level\n",
    "   - Focus on topics relevant to their role\n",
    "   - Use their preferred communication style\n",
    "## GOODBYE INSTRUCTION:\n",
    "When the user says goodbye, ends the conversation, or uses phrases like:\n",
    "- \"bye\", \"goodbye\", \"see you\", \"thanks bye\", \"that's all\", \"gotta go\", \"talk later\"\n",
    "Call the queue_memory_consolidation tool to consolidate their memories, then say a friendly goodbye.\n",
    "\n",
    "## TOOL USAGE:\n",
    "- Do NOT call the same tool more than 2 times per question\n",
    "- Use documentation tools for technical questions\n",
    "\n",
    "Available tools: {tool_names}\"\"\"\n",
    "),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_aware_prompt_with_goodbye = memory_aware_prompt_with_goodbye.partial(\n",
    "    tool_names=\", \".join([tool.name for tool in tools])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph recompiled with LangMem cold path support\n"
     ]
    }
   ],
   "source": [
    "llm_with_tools = memory_aware_prompt_with_goodbye | llm.bind_tools(tools)\n",
    "\n",
    "# Recompile the graph\n",
    "app_with_memory = graph.compile(\n",
    "    checkpointer=checkpointer,\n",
    "    store=memory_store\n",
    ")\n",
    "\n",
    "print(\"Graph recompiled with LangMem cold path support\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent wrapper updated with cold path tracking\n"
     ]
    }
   ],
   "source": [
    "def run_agent_with_memory_and_coldpath(\n",
    "    thread_id: str,\n",
    "    user_id: str,\n",
    "    user_input: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Run the agent with memory support and cold path tracking.\n",
    "    \n",
    "    This wrapper:\n",
    "    1. Tracks conversation messages for cold path consolidation\n",
    "    2. Passes user_id for proper namespace scoping\n",
    "    3. Streams and displays the response\n",
    "    \"\"\"\n",
    "    global _current_conversation_messages, _current_user_id\n",
    "    \n",
    "    # Set current user for consolidation tool\n",
    "    _current_user_id = user_id\n",
    "    \n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id,\n",
    "            \"langgraph_user_id\": user_id\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    input_message = HumanMessage(content=user_input)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\" Thread: {thread_id}\")\n",
    "    print(f\" User: {user_id}\")\n",
    "    print(f\" Input: {user_input}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Stream the response\n",
    "    final_response = None\n",
    "    for chunk in app_with_memory.stream(\n",
    "        {\"messages\": [input_message]},\n",
    "        config=config,\n",
    "        stream_mode=\"values\"\n",
    "    ):\n",
    "        if \"messages\" in chunk:\n",
    "            final_response = chunk[\"messages\"][-1]\n",
    "            # Track messages for cold path\n",
    "            _current_conversation_messages = chunk[\"messages\"]\n",
    "    \n",
    "    if final_response:\n",
    "        print(f\"\\n Assistant: {final_response.content}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\\n\")\n",
    "\n",
    "\n",
    "print(\"Agent wrapper updated with cold path tracking\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Creating some memories...\n",
      "\n",
      "============================================================\n",
      " Thread: session-coldpath-test_1\n",
      " User: user-coldpath-dem\n",
      " Input: Hi! I'm a senior data engineer at a fintech startup. I work mostly with MongoDB and Kafka.\n",
      "============================================================\n",
      "\n",
      "\n",
      " Assistant: Hello! Great to meet you! As a senior data engineer working with MongoDB and Kafka at a fintech startup, you're dealing with some powerful technologies for handling data pipelines and real-time data processing.\n",
      "\n",
      "I'm here to help you with any MongoDB-related questions you might have - whether it's about:\n",
      "- Performance optimization and indexing strategies\n",
      "- Data modeling for financial data\n",
      "- Aggregation pipelines\n",
      "- Replication and sharding\n",
      "- Integration patterns with Kafka\n",
      "- Or anything else MongoDB-related!\n",
      "\n",
      "What can I help you with today?\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: TEST - Create some memories first\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 1: Creating some memories...\")\n",
    "\n",
    "run_agent_with_memory_and_coldpath(\n",
    "    \"session-coldpath-test_1\",\n",
    "    \"user-coldpath-dem\",\n",
    "    \"Hi! I'm a senior data engineer at a fintech startup. I work mostly with MongoDB and Kafka.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Adding more context...\n",
      "\n",
      "============================================================\n",
      " Thread: session-coldpath-test_1\n",
      " User: user-coldpath-dem\n",
      " Input: I'm a DBA particularly interested in performance optimization and I prefer detailed technical explanations with code examples.\n",
      "============================================================\n",
      "\n",
      "\n",
      " Assistant: Excellent! I've noted that you're a DBA focused on performance optimization with a preference for detailed technical explanations and code examples. That's perfect for diving deep into MongoDB optimization strategies, which is crucial in fintech environments where performance, reliability, and data integrity are paramount.\n",
      "\n",
      "As a DBA, I can provide you with in-depth technical guidance on:\n",
      "\n",
      "- **Index optimization strategies** - compound indexes, covered queries, index intersection, ESR (Equality-Sort-Range) rule, index selectivity analysis\n",
      "- **Query performance analysis** - explain() output interpretation, execution stats, query profiling, slow query analysis\n",
      "- **Aggregation pipeline optimization** - stage ordering, $match/$project early placement, memory limits, allowDiskUse considerations\n",
      "- **Schema design patterns** - embedding vs referencing, bucketing patterns, computed patterns for performance\n",
      "- **Connection pooling and driver configuration** - maxPoolSize, minPoolSize, connection lifecycle management\n",
      "- **Write concern and read preference tuning** - balancing durability, consistency, and throughput\n",
      "- **Database profiling and monitoring** - profiler levels, currentOp, serverStatus metrics\n",
      "- **Storage engine tuning** - WiredTiger cache configuration, compression settings\n",
      "\n",
      "What specific performance optimization area would you like to explore with detailed examples? Or do you have a particular performance challenge you're working on?\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: TEST - Add more context\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 2: Adding more context...\")\n",
    "\n",
    "run_agent_with_memory_and_coldpath(\n",
    "    \"session-coldpath-test_1\",\n",
    "    \"user-coldpath-dem\",\n",
    "    \"I'm a DBA particularly interested in performance optimization and I prefer detailed technical explanations with code examples.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " User memories before consolidation:\n",
      "==================================================\n",
      "\n",
      "--- Memory 1 ---\n",
      "Key: 3fed47b8-378b-43d4-ae2d-7cf27ee7a04a\n",
      "Value: {'kind': 'Memory', 'content': {'content': 'User Profile: Senior data engineer and DBA at a fintech startup. Works with MongoDB and Kafka. Preferences: Detailed technical explanations with code examples. Interests: MongoDB performance optimization.'}}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: VERIFY - Check memories before consolidation\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "time.sleep(5)  # Give executor time to process\n",
    "\n",
    "# Check what's in the memory store for this user\n",
    "print(\"\\n User memories before consolidation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "namespace = (\"memories\", \"user-coldpath-dem\")\n",
    "\n",
    "# Search for all memories\n",
    "try:\n",
    "    results = list(memory_store.search(namespace, query=\"user profile expertise\", limit=10))\n",
    "    \n",
    "    if results:\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"\\n--- Memory {i} ---\")\n",
    "            print(f\"Key: {result.key}\")\n",
    "            print(f\"Value: {result.value}\")\n",
    "            \n",
    "    else:\n",
    "        print(\"No memories found via search. Checking raw collection...\")\n",
    "        \n",
    "        # Fallback: check MongoDB directly\n",
    "        raw_memories = list(memory_collection.find({\"namespace\": list(namespace)}))\n",
    "        print(f\"Found {len(raw_memories)} memories in MongoDB:\")\n",
    "        for mem in raw_memories[:5]:\n",
    "            print(f\"  - {mem.get('key')}: {str(mem.get('value', {}))[:100]}...\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error searching memories: {e}\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Triggering cold path consolidation...\n",
      "\n",
      "============================================================\n",
      " Thread: session-coldpath-test_1\n",
      " User: user-coldpath-dem\n",
      " Input: Thanks for your help! Goodbye!\n",
      "============================================================\n",
      "\n",
      "📝 Consolidation complete for user: user-coldpath-dem\n",
      "   Memories created/updated: 1\n",
      "   - {'kind': 'Memory', 'content': {'content': 'User Profile: Senior data engineer and DBA at a fintech startup. Works with MongoDB and Kafka. Preferences: Detailed technical explanations with code examples. Interests: MongoDB performance optimization.'}}\n",
      "\n",
      " Assistant: You're welcome! It was great chatting with you. Feel free to come back anytime you need help with MongoDB performance optimization or any other DBA-related questions. Good luck with your work at the fintech startup! Goodbye! 👋\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 10: TEST - Say goodbye to trigger consolidation\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 3: Triggering cold path consolidation...\")\n",
    "\n",
    "run_agent_with_memory_and_coldpath(\n",
    "    thread_id=\"session-coldpath-test_1\",\n",
    "    user_id=\"user-coldpath-dem\",\n",
    "    user_input=\"Thanks for your help! Goodbye!\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for background consolidation to complete...\n",
      "\n",
      "📋 User memories after consolidation:\n",
      "==================================================\n",
      "\n",
      "--- Memory 1 ---\n",
      "Key: 3fed47b8-378b-43d4-ae2d-7cf27ee7a04a\n",
      "Value: {'kind': 'Memory', 'content': {'content': 'User Profile: Senior data engineer and DBA at a fintech startup. Works with MongoDB and Kafka. Preferences: Detailed technical explanations with code examples. Interests: MongoDB performance optimization.'}}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: VERIFY - Check memories after consolidation\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "print(\"Waiting for background consolidation to complete...\")\n",
    "time.sleep(5)  # Give executor time to process\n",
    "\n",
    "# Check what's in the memory store for this user\n",
    "print(\"\\n📋 User memories after consolidation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "namespace = (\"memories\", \"user-coldpath-dem\")\n",
    "\n",
    "# Search for all memories\n",
    "try:\n",
    "    results = list(memory_store.search(namespace, query=\"user profile expertise\", limit=10))\n",
    "    \n",
    "    if results:\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"\\n--- Memory {i} ---\")\n",
    "            print(f\"Key: {result.key}\")\n",
    "            print(f\"Value: {result.value}\")\n",
    "         \n",
    "    else:\n",
    "        print(\"No memories found via search. Checking raw collection...\")\n",
    "        \n",
    "        # Fallback: check MongoDB directly\n",
    "        raw_memories = list(memory_collection.find({\"namespace\": list(namespace)}))\n",
    "        print(f\"Found {len(raw_memories)} memories in MongoDB:\")\n",
    "        for mem in raw_memories[:5]:\n",
    "            print(f\"  - {mem.get('key')}: {str(mem.get('value', {}))[:100]}...\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error searching memories: {e}\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {}
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
