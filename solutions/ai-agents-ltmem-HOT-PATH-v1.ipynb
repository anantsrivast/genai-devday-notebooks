{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Lab Documentation and Solutions](https://img.shields.io/badge/Lab%20Documentation%20and%20Solutions-purple)](https://mongodb-developer.github.io/ai-agents-lab/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RM8rg08YhqZe"
   },
   "source": [
    "# Step 1: Setup prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Add parent directory to path to import from utils\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd())))\n",
    "from utils import track_progress, set_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1766372994, 2),\n",
       "  'signature': {'hash': b'\\xde\\xd5\\xe1\\xcd\\xeat\\xdb+Y4\\xfb\\xca m\\xecL\\xa7\\xd1\\xdf\\x89',\n",
       "   'keyId': 7583894535055343622}},\n",
       " 'operationTime': Timestamp(1766372994, 2)}"
      ]
     },
     "execution_count": 1205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you are using your own MongoDB Atlas cluster, use the connection string for your cluster here\n",
    "MONGODB_URI = os.environ.get(\"MONGODB_URI\")\n",
    "# Initialize a MongoDB Python client\n",
    "mongodb_client = MongoClient(MONGODB_URI)\n",
    "# Check the connection to the server\n",
    "mongodb_client.admin.command(\"ping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking progress for task cluster_creation\n"
     ]
    }
   ],
   "source": [
    "# Track progress of key steps-- DO NOT CHANGE\n",
    "track_progress(\"cluster_creation\", \"ai_agents_mem_lab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the LLM provider and passkey provided by your workshop instructor\n",
    "# NOTE: LLM_PROVIDER can be set to one of \"aws\"/ \"microsoft\" / \"google\"\n",
    "LLM_PROVIDER = \"aws\"\n",
    "PASSKEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully set AWS_ACCESS_KEY_ID environment variable.\n",
      "Successfully set AWS_SECRET_ACCESS_KEY environment variable.\n",
      "Successfully set VOYAGE_API_KEY environment variable.\n"
     ]
    }
   ],
   "source": [
    "# Obtain API keys from our AI model proxy and set them as environment variables-- DO NOT CHANGE\n",
    "set_env([LLM_PROVIDER,\"voyageai\"], PASSKEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUf3jtFzO4-V"
   },
   "source": [
    "# Step 2: Import data into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Do not change the values assigned to the variables below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Database name\n",
    "DB_NAME = \"mongodb_genai_devday_agents\"\n",
    "# Name of the collection with full documents- used for summarization\n",
    "FULL_COLLECTION_NAME = \"mongodb_docs\"\n",
    "# Name of the collection for vector search- used for Q&A\n",
    "VS_COLLECTION_NAME = \"mongodb_docs_embeddings\"\n",
    "# Name of the vector search index\n",
    "VS_INDEX_NAME = \"vector_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the `VS_COLLECTION_NAME` collection.\n",
    "vs_collection = mongodb_client[DB_NAME][VS_COLLECTION_NAME]\n",
    "# Connect to the `FULL_COLLECTION_NAME` collection.\n",
    "full_collection = mongodb_client[DB_NAME][FULL_COLLECTION_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting existing documents from the mongodb_docs_embeddings collection.\n",
      "101 documents ingested into the mongodb_docs_embeddings collection.\n"
     ]
    }
   ],
   "source": [
    "# Insert a dataset of MongoDB docs with embeddings into the `VS_COLLECTION_NAME` collection\n",
    "with open(f\"../data/{VS_COLLECTION_NAME}.json\", \"r\") as data_file:\n",
    "    json_data = data_file.read()\n",
    "\n",
    "data = json.loads(json_data)\n",
    "\n",
    "print(f\"Deleting existing documents from the {VS_COLLECTION_NAME} collection.\")\n",
    "vs_collection.delete_many({})\n",
    "vs_collection.insert_many(data)\n",
    "print(\n",
    "    f\"{vs_collection.count_documents({})} documents ingested into the {VS_COLLECTION_NAME} collection.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting existing documents from the mongodb_docs collection.\n",
      "20 documents ingested into the mongodb_docs collection.\n"
     ]
    }
   ],
   "source": [
    "# Insert a dataset of MongoDB documentation pages into the `FULL_COLLECTION_NAME` collection\n",
    "with open(f\"../data/{FULL_COLLECTION_NAME}.json\", \"r\") as data_file:\n",
    "    json_data = data_file.read()\n",
    "\n",
    "data = json.loads(json_data)\n",
    "\n",
    "print(f\"Deleting existing documents from the {FULL_COLLECTION_NAME} collection.\")\n",
    "full_collection.delete_many({})\n",
    "full_collection.insert_many(data)\n",
    "print(\n",
    "    f\"{full_collection.count_documents({})} documents ingested into the {FULL_COLLECTION_NAME} collection.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Create a vector search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_index, check_index_ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector index definition specifying:\n",
    "# path: Path to the embeddings field\n",
    "# numDimensions: Number of embedding dimensions- depends on the embedding model used\n",
    "# similarity: Similarity metric. One of cosine, euclidean, dotProduct.\n",
    "model = {\n",
    "    \"name\": VS_INDEX_NAME,\n",
    "    \"type\": \"vectorSearch\",\n",
    "    \"definition\": {\n",
    "        \"fields\": [\n",
    "            {\n",
    "                \"type\": \"vector\",\n",
    "                \"path\": \"embedding\",\n",
    "                \"numDimensions\": 1024,\n",
    "                \"similarity\": \"cosine\",\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the vector_index index\n"
     ]
    }
   ],
   "source": [
    "# Use the `create_index` function from the `utils` module to create a vector search index with the above definition for the `vs_collection` collection\n",
    "create_index(vs_collection, VS_INDEX_NAME, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_index index status: READY\n",
      "vector_index index definition: {'fields': [{'type': 'vector', 'path': 'embedding', 'numDimensions': 1024, 'similarity': 'cosine'}]}\n"
     ]
    }
   ],
   "source": [
    "# Use the `check_index_ready` function from the `utils` module to verify that the index was created and is in READY status before proceeding\n",
    "check_index_ready(vs_collection, VS_INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking progress for task vs_index_creation\n"
     ]
    }
   ],
   "source": [
    "# Track progress of key steps-- DO NOT CHANGE\n",
    "track_progress(\"vs_index_creation\", \"ai_agents_lab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZfheX5FiIhU"
   },
   "source": [
    "# Step 4: Create agent tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "import voyageai\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Voyage AI client\n",
    "vo = voyageai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://docs.voyageai.com/docs/contextualized-chunk-embeddings#approach-2-contextualized-chunk-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(query: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Get embeddings for an input query.\n",
    "\n",
    "    Args:\n",
    "        query (str): Query string\n",
    "\n",
    "    Returns:\n",
    "        List[float]: Embedding of the query string\n",
    "    \"\"\"\n",
    "    # Use the `contextualized_embed` method of the Voyage AI API to embed the user query with the following arguments:\n",
    "    # inputs: `query` wrapped in a list of lists\n",
    "    # model: `voyage-context-3`\n",
    "    # input_type: \"query\"\n",
    "    embds_obj = vo.contextualized_embed(inputs=[[query]], model=\"voyage-context-3\", input_type=\"query\")\n",
    "    # Extract embeddings from the embeddings object\n",
    "    embeddings = embds_obj.results[0].embeddings[0]\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#ann-examples (Refer to the \"Basic Example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tool to retrieve relevant documents for a user query using vector search\n",
    "@tool\n",
    "def get_information_for_question_answering(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve information using vector search to answer a user query.\n",
    "\n",
    "    Args:\n",
    "    user_query (str): The user's query string.\n",
    "\n",
    "    Returns:\n",
    "    str: The retrieved information formatted as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate embeddings for the `user_query` using the `get_embeddings` function defined above\n",
    "    query_embedding = get_embeddings(user_query)\n",
    "\n",
    "    # Define an aggregation pipeline consisting of a $vectorSearch stage, followed by a $project stage\n",
    "    # Set the number of candidates to 150 and only return the top 5 documents from the vector search\n",
    "    # In the $project stage, exclude the `_id` field and include only the `body` field and `vectorSearchScore`\n",
    "    # NOTE: Use variables defined previously for the `index`, `queryVector` and `path` fields in the $vectorSearch stage\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$vectorSearch\": {\n",
    "                \"index\": VS_INDEX_NAME,\n",
    "                \"path\": \"embedding\",\n",
    "                \"queryVector\": query_embedding,\n",
    "                \"numCandidates\": 150,\n",
    "                \"limit\": 5,\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"_id\": 0,\n",
    "                \"body\": 1,\n",
    "                \"score\": {\"$meta\": \"vectorSearchScore\"},\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Execute the aggregation `pipeline` against the `vs_collection` collection and store the results in `results`\n",
    "    results = vs_collection.aggregate(pipeline)\n",
    "    # Concatenate the results into a string\n",
    "    context = \"\\n\\n\".join([doc.get(\"body\") for doc in results])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get page content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://www.mongodb.com/docs/manual/reference/method/db.collection.findOne/#return-all-but-the-excluded-fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tool to retrieve the content of a documentation page for summarization\n",
    "@tool\n",
    "def get_page_content_for_summarization(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve page content based on provided title.\n",
    "\n",
    "    Args:\n",
    "    user_query (str): The user's query string i.e. title of the documentation page.\n",
    "\n",
    "    Returns:\n",
    "    str: The content of the page.\n",
    "    \"\"\"\n",
    "    # Query the documents where the `title` field is equal to the `user_query`\n",
    "    query = {\"title\": user_query}\n",
    "    # Only return the `body` field from the retrieved documents.\n",
    "    # NOTE: Set fields to include to 1, those to exclude to 0. `_id` is included by default, so exclude that.\n",
    "    projection = {\"_id\": 0, \"body\": 1}\n",
    "    # Use the `query` and `projection` with the `find_one` method\n",
    "    # to get the `body` of the document with `title` equal to the `user_query` from the `full_collection` collection\n",
    "    document = full_collection.find_one(query, projection)\n",
    "    if document:\n",
    "        return document[\"body\"]\n",
    "    else:\n",
    "        return \"Document not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of tools\n",
    "tools = [\n",
    "    get_information_for_question_answering,\n",
    "    get_page_content_for_summarization,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out the tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Backup and Restore Sharded Clusters\\n\\nThe following tutorials describe backup and restoration for sharded clusters:\\n\\nTo use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\\n\\nSharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\\n\\n- MongoDB Atlas\\n\\n- MongoDB Cloud Manager\\n\\n- MongoDB Ops Manager\\n\\nUse file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\\n\\nCreate backups using `mongodump` to back up each component in the cluster individually.\\n\\nLimit the operation of the cluster balancer to provide a window for regular backup operations.\\n\\nAn outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\\n\\nTo help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\\n\\nFTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\\n\\nMongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\\n\\nFTDC data **never** contains any of the following information:\\n\\n- Samples of queries, query predicates, or query results\\n\\n- Data sampled from any end-user collection or index\\n\\n- System or MongoDB user credentials or security certificates\\n\\n# Configuration and Maintenance\\n\\nThis section describes routine management operations, including updating your MongoDB deployment's configuration.\\n\\nOutlines common MongoDB configurations and examples of best-practice configurations for common use cases.\\n\\nUpgrade a MongoDB deployment to a different patch release within the same major release series.\\n\\nStart, configure, and manage running `mongod` process.\\n\\nStop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\\n\\nArchive the current log files and start new ones.\\n\\nFTDC data contains certain host machine information such as hostnames, operating system information, and the options or settings used to start the `mongod` or `mongos`. This information may be considered protected or confidential by some organizations or regulatory bodies, but is not typically considered to be Personally Identifiable Information (PII). For clusters where these fields are configured with protected, confidential, or PII data, please notify MongoDB engineers before sending FTDC data to coordinate appropriate security measures.\\n\\nOn Windows, to collect system data such as disk, cpu, and memory, FTDC requires Microsoft access permissions from the following groups:\\n\\n- Performance Monitor Users\\n\\n- Performance Log Users\\n\\nIf the user running `mongod` and `mongos` is not an administrator, add them to these groups to log FTDC data. For more information, see the Microsoft documentation here.\\n\\nFTDC periodically collects statistics produced by the following commands:\\n\\n- `serverStatus`\""
      ]
     },
     "execution_count": 1225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test out the `get_information_for_question_answering` tool with the query \"What are some best practices for data backups in MongoDB?\"\n",
    "# You should see a non-empty response\n",
    "get_information_for_question_answering.invoke(\n",
    "    \"What are some best practices for data backups in MongoDB?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Create a MongoDB Deployment\\n\\nYou can create a free tier MongoDB deployment on MongoDB Atlas to store and manage your data. MongoDB Atlas hosts and manages your MongoDB database in the cloud.\\n\\n## Create a Free MongoDB deployment on Atlas\\n\\nComplete the Get Started with Atlas guide to set up a new Atlas account and load sample data into a new free tier MongoDB deployment.\\n\\n## Save your Credentials\\n\\nAfter you create your database user, save that user's username and password to a safe location for use in an upcoming step.\\n\\nAfter you complete these steps, you have a new free tier MongoDB deployment on Atlas, database user credentials, and sample data loaded in your database.\\n\\nIf you run into issues on this step, ask for help in the MongoDB Community Forums or submit feedback by using the Rate this page tab on the right or bottom right side of this page.\\n\\n\""
      ]
     },
     "execution_count": 1226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test out the `get_page_content_for_summarization` tool with page title \"Create a MongoDB Deployment\"\n",
    "# You should see a non-empty response\n",
    "get_page_content_for_summarization.invoke(\"Create a MongoDB Deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Define graph state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the graph state\n",
    "# We are only tracking chat messages but you can track other attributes as well\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Instantiate the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.load import load\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from utils import get_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the Langchain LLM object using the `get_llm` function from the `utils`` module.\n",
    "llm = get_llm(LLM_PROVIDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Chain-of-Thought (CoT) prompt template for the agent.\n",
    "# This includes a system prompt with a placeholder for tool names, and a placeholder for messages i.e. user queries and assistant responses\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"You are a helpful AI assistant.\"\n",
    "            \" You are provided with tools to answer questions and summarize technical documentation related to MongoDB.\"\n",
    "            \" Think step-by-step and use these tools to get the information required to answer the user query.\"\n",
    "            \" Do not re-run tools unless absolutely necessary.\"\n",
    "            \" If you are not able to get enough information using the tools, reply with I DON'T KNOW.\"\n",
    "            \" You have access to the following tools: {tool_names}.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the prompt template with the tool names\n",
    "prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://python.langchain.com/v0.1/docs/modules/model_io/chat/function_calling/#binding-tool-schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind the `tools` to the `llm` instantiated above\n",
    "bind_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://python.langchain.com/v0.1/docs/expression_language/primitives/sequence/#the-pipe-operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain the `prompt` with the tool-augmented llm using the `|` operator\n",
    "llm_with_tools = prompt | bind_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_page_content_for_summarization',\n",
       "  'args': {'user_query': 'Create a MongoDB Deployment'},\n",
       "  'id': 'toolu_bdrk_019WKm54nEmMrQSPTKXGJJo6',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 1235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that the LLM is making the right tool calls\n",
    "llm_with_tools.invoke(\n",
    "    [\"Give me a summary of the page titled Create a MongoDB Deployment.\"]\n",
    ").tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_information_for_question_answering',\n",
       "  'args': {'user_query': 'best practices for data backups in MongoDB'},\n",
       "  'id': 'toolu_bdrk_01GEKPgPmPTVSmevQwbMPtLS',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 1236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that the LLM is making the right tool calls\n",
    "llm_with_tools.invoke(\n",
    "    [\"What are some best practices for data backups in MongoDB?\"]\n",
    ").tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Define graph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from typing import Dict\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the agent node\n",
    "def agent(state: GraphState) -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Agent node\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Graph state\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List]: Updates to messages\n",
    "    \"\"\"\n",
    "    # Get the messages from the graph `state`\n",
    "    messages = state[\"messages\"]\n",
    "    # Invoke `llm_with_tools` with `messages` using the `invoke` method\n",
    "    # HINT: See Step 6 for how to invoke `llm_with_tools`\n",
    "    result = llm_with_tools.invoke(messages)\n",
    "    # Write `result` to the `messages` attribute of the graph state\n",
    "    return {\"messages\": [result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'get_information_for_question_answering': StructuredTool(name='get_information_for_question_answering', description=\"Retrieve information using vector search to answer a user query.\\n\\nArgs:\\nuser_query (str): The user's query string.\\n\\nReturns:\\nstr: The retrieved information formatted as a string.\", args_schema=<class 'langchain_core.utils.pydantic.get_information_for_question_answering'>, func=<function get_information_for_question_answering at 0x768a3d0e8cc0>),\n",
      " 'get_page_content_for_summarization': StructuredTool(name='get_page_content_for_summarization', description=\"Retrieve page content based on provided title.\\n\\nArgs:\\nuser_query (str): The user's query string i.e. title of the documentation page.\\n\\nReturns:\\nstr: The content of the page.\", args_schema=<class 'langchain_core.utils.pydantic.get_page_content_for_summarization'>, func=<function get_page_content_for_summarization at 0x768a3c983920>)}\n"
     ]
    }
   ],
   "source": [
    "# Create a map of tool name to tool call\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "pprint(tools_by_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tool node\n",
    "def tool_node(state: GraphState) -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Tool node\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Graph state\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List]: Updates to messages\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    # Get the list of tool calls from messages\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    # A tool_call looks as follows:\n",
    "    # {\n",
    "    #     \"name\": \"get_information_for_question_answering\",\n",
    "    #     \"args\": {\"user_query\": \"What are Atlas Triggers\"},\n",
    "    #     \"id\": \"call_H5TttXb423JfoulF1qVfPN3m\",\n",
    "    #     \"type\": \"tool_call\",\n",
    "    # }\n",
    "    # Iterate through `tool_calls`\n",
    "    for tool_call in tool_calls:\n",
    "        # Get the tool from `tools_by_name` using the `name` attribute of the `tool_call`\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        # Invoke the `tool` using the `args` attribute of the `tool_call`\n",
    "        # HINT: See previous line to see how to extract attributes from `tool_call`\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        # Append the result of executing the tool to the `result` list as a ToolMessage\n",
    "        # The `content` of the message is `observation` i.e. result of the tool call\n",
    "        # The `tool_call_id` can be obtained from the `tool_call`\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    # Write `result` to the `messages` attribute of the graph state\n",
    "    return {\"messages\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Define conditional edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conditional routing function\n",
    "def route_tools(state: GraphState):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the tool node if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    # Get messages from graph state\n",
    "    messages = state.get(\"messages\", [])\n",
    "    if len(messages) > 0:\n",
    "        # Get the last AI message from messages\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    # Check if the last message has tool calls\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        # If yes, return \"tools\"\n",
    "        return \"tools\"\n",
    "    # If no, return END\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the graph\n",
    "graph = StateGraph(GraphState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://blog.langchain.dev/langgraph/#nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x768a3ac8fad0>"
      ]
     },
     "execution_count": 1245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add nodes to the `graph` using the `add_node` function\n",
    "# Add a `agent` node. The `agent` node should run the `agent` function\n",
    "graph.add_node(\"agent\", agent)\n",
    "# Add a `tools` node. The `tools` node should run the `tool_node` function\n",
    "graph.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://langchain-ai.github.io/langgraph/concepts/low_level/#normal-edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x768a3ac8fad0>"
      ]
     },
     "execution_count": 1246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add fixed edges to the `graph` using the `add_edge` method\n",
    "# Add an edge from the START node to the `agent` node\n",
    "graph.add_edge(START, \"agent\")\n",
    "# Add an edge from the `tools` node to the `agent` node\n",
    "graph.add_edge(\"tools\", \"agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://langchain-ai.github.io/langgraph/concepts/low_level/#conditional-edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x768a3ac8fad0>"
      ]
     },
     "execution_count": 1247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the `add_conditional_edges` method to add a conditional edge from the `agent` node to the `tools` node\n",
    "# based on the output of the `route_tools` function\n",
    "graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    route_tools,\n",
    "    {\"tools\": \"tools\", END: END},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the `graph`\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x768a3990ec90>"
      ]
     },
     "execution_count": 1249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the graph\n",
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Execute the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_graph(user_input: str) -> None:\n",
    "    \"\"\"\n",
    "    Stream outputs from the graph\n",
    "\n",
    "    Args:\n",
    "        user_input (str): User query string\n",
    "    \"\"\"\n",
    "    # Stream outputs from each step in the graph\n",
    "    for step in app.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        # Stream full value of the state after each step\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        # Print the latest message from the step\n",
    "        step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are some best practices for data backups in MongoDB?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'll help you find information about best practices for data backups in MongoDB.\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_019bGLozYGFN7KtG6pdA4xYK)\n",
      " Call ID: toolu_bdrk_019bGLozYGFN7KtG6pdA4xYK\n",
      "  Args:\n",
      "    user_query: best practices for data backups in MongoDB\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "FTDC data contains certain host machine information such as hostnames, operating system information, and the options or settings used to start the `mongod` or `mongos`. This information may be considered protected or confidential by some organizations or regulatory bodies, but is not typically considered to be Personally Identifiable Information (PII). For clusters where these fields are configured with protected, confidential, or PII data, please notify MongoDB engineers before sending FTDC data to coordinate appropriate security measures.\n",
      "\n",
      "On Windows, to collect system data such as disk, cpu, and memory, FTDC requires Microsoft access permissions from the following groups:\n",
      "\n",
      "- Performance Monitor Users\n",
      "\n",
      "- Performance Log Users\n",
      "\n",
      "If the user running `mongod` and `mongos` is not an administrator, add them to these groups to log FTDC data. For more information, see the Microsoft documentation here.\n",
      "\n",
      "FTDC periodically collects statistics produced by the following commands:\n",
      "\n",
      "- `serverStatus`\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01AeKCjRwDUarCGq4zkeHh6J)\n",
      " Call ID: toolu_bdrk_01AeKCjRwDUarCGq4zkeHh6J\n",
      "  Args:\n",
      "    user_query: MongoDB backup strategies recommendations mongodump file system snapshots\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01XmhWPrybbhjmq7yeBNNRLT)\n",
      " Call ID: toolu_bdrk_01XmhWPrybbhjmq7yeBNNRLT\n",
      "  Args:\n",
      "    user_query: MongoDB backup methods replica sets point in time recovery backup frequency\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "Just for the sake of it, I also used multi-document ACID transactions in a few methods where it could potentially make sense to use ACID transactions. You can check all the code in the `MongoDBPersonRepository` class.\n",
      "\n",
      "Here is an example:\n",
      "\n",
      "```java\n",
      "private static final TransactionOptions txnOptions = TransactionOptions.builder()\n",
      "    .readPreference(ReadPreference.primary())\n",
      "    .readConcern(ReadConcern.MAJORITY)\n",
      "    .writeConcern(WriteConcern.MAJORITY)\n",
      "    .build();\n",
      "\n",
      "@Override\n",
      "public List saveAll(List personEntities) {\n",
      "    try (ClientSession clientSession = client.startSession()) {\n",
      "        return clientSession.withTransaction(() -> {\n",
      "            personEntities.forEach(p -> p.setId(new ObjectId()));\n",
      "            personCollection.insertMany(clientSession, personEntities);\n",
      "            return personEntities;\n",
      "        }, txnOptions);\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "As you can see, Iâ€™m using an auto-closeable try-with-resources which will automatically close the client session at the end. This helps me to keep the code clean and simple.\n",
      "\n",
      "Some of you may argue that it is actually too simple because transactions (and write operations, in general) can throw exceptions, and Iâ€™m not handling any of them hereâ€¦ You are absolutely right and this is an excellent transition to the next part of this article.\n",
      "\n",
      "## Exception management\n",
      "\n",
      "Transactions in MongoDB can raise exceptions for various reasons, and I donâ€™t want to go into the details too much here, but since MongoDB 3.6, any write operation that fails can be automatically retried once. And the transactions are no different. See the documentation for retryWrites.\n",
      "\n",
      "If retryable writes are disabled or if a write operation fails twice, then MongoDB will send a MongoException (extends RuntimeException) which should be handled properly.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_018aq4kYjPTXJ5FEymv1MMG9)\n",
      " Call ID: toolu_bdrk_018aq4kYjPTXJ5FEymv1MMG9\n",
      "  Args:\n",
      "    user_query: backup best practices testing backups offsite storage encryption\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "\n",
      "FTDC data contains certain host machine information such as hostnames, operating system information, and the options or settings used to start the `mongod` or `mongos`. This information may be considered protected or confidential by some organizations or regulatory bodies, but is not typically considered to be Personally Identifiable Information (PII). For clusters where these fields are configured with protected, confidential, or PII data, please notify MongoDB engineers before sending FTDC data to coordinate appropriate security measures.\n",
      "\n",
      "On Windows, to collect system data such as disk, cpu, and memory, FTDC requires Microsoft access permissions from the following groups:\n",
      "\n",
      "- Performance Monitor Users\n",
      "\n",
      "- Performance Log Users\n",
      "\n",
      "If the user running `mongod` and `mongos` is not an administrator, add them to these groups to log FTDC data. For more information, see the Microsoft documentation here.\n",
      "\n",
      "FTDC periodically collects statistics produced by the following commands:\n",
      "\n",
      "- `serverStatus`\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_017U9jSjAt95tk6ft1qzAxZM)\n",
      " Call ID: toolu_bdrk_017U9jSjAt95tk6ft1qzAxZM\n",
      "  Args:\n",
      "    user_query: MongoDB backup considerations replica set secondary node snapshot\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "FTDC data contains certain host machine information such as hostnames, operating system information, and the options or settings used to start the `mongod` or `mongos`. This information may be considered protected or confidential by some organizations or regulatory bodies, but is not typically considered to be Personally Identifiable Information (PII). For clusters where these fields are configured with protected, confidential, or PII data, please notify MongoDB engineers before sending FTDC data to coordinate appropriate security measures.\n",
      "\n",
      "On Windows, to collect system data such as disk, cpu, and memory, FTDC requires Microsoft access permissions from the following groups:\n",
      "\n",
      "- Performance Monitor Users\n",
      "\n",
      "- Performance Log Users\n",
      "\n",
      "If the user running `mongod` and `mongos` is not an administrator, add them to these groups to log FTDC data. For more information, see the Microsoft documentation here.\n",
      "\n",
      "FTDC periodically collects statistics produced by the following commands:\n",
      "\n",
      "- `serverStatus`\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_page_content_for_summarization (toolu_bdrk_01NCUcbYBDiG52QXYSucvurY)\n",
      " Call ID: toolu_bdrk_01NCUcbYBDiG52QXYSucvurY\n",
      "  Args:\n",
      "    user_query: MongoDB backup methods\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Document not found\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_page_content_for_summarization (toolu_bdrk_01NvbB3wYRuTNSF7C29KYvYe)\n",
      " Call ID: toolu_bdrk_01NvbB3wYRuTNSF7C29KYvYe\n",
      "  Args:\n",
      "    user_query: backup and restore\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Document not found\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_011FNs3YjMpx5Hd4kNLwuXqu)\n",
      " Call ID: toolu_bdrk_011FNs3YjMpx5Hd4kNLwuXqu\n",
      "  Args:\n",
      "    user_query: mongodump mongorestore backup procedure standalone replica set\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "\n",
      "# Administration\n",
      "\n",
      "The administration documentation addresses the ongoing operation and maintenance of MongoDB instances and deployments. This documentation includes both high level overviews of these concerns as well as tutorials that cover specific procedures and processes for operating MongoDB.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01YHNjqvmB3Z83kZQAmR2F18)\n",
      " Call ID: toolu_bdrk_01YHNjqvmB3Z83kZQAmR2F18\n",
      "  Args:\n",
      "    user_query: backup strategies file system snapshot LVM EBS consistent backup\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the information I've gathered from the MongoDB documentation, here are some **best practices for data backups in MongoDB**:\n",
      "\n",
      "## Backup Methods\n",
      "\n",
      "1. **Use Managed Backup Solutions (Recommended)**\n",
      "   - **MongoDB Atlas, Cloud Manager, or Ops Manager** - These provide coordinated backup and restore processes that maintain atomicity guarantees of transactions across shards\n",
      "   - These are particularly recommended for sharded clusters\n",
      "\n",
      "2. **File System Snapshots**\n",
      "   - Can be more efficient than MongoDB tools if your system configuration supports them\n",
      "   - Suitable for backing up each component in a cluster individually\n",
      "   - Requires stopping the cluster balancer during backup operations\n",
      "\n",
      "3. **mongodump and mongorestore**\n",
      "   - Can be used as a backup strategy for various deployment types\n",
      "   - For sharded clusters, requires additional precautions:\n",
      "     - Stop the sharded cluster balancer\n",
      "     - Use the `fsync` command or `db.fsyncLock()` method on `mongos` to block writes during backups\n",
      "   - Back up each component in the cluster individually\n",
      "\n",
      "## Key Best Practices\n",
      "\n",
      "1. **Minimize Impact on Production**\n",
      "   - For sharded clusters, stop or limit the cluster balancer operation to provide a window for regular backup operations\n",
      "   - Use `fsync` or `db.fsyncLock()` to ensure data consistency during backups\n",
      "\n",
      "2. **Maintain Consistency**\n",
      "   - Ensure backups are consistent, especially in sharded environments\n",
      "   - Use coordinated backup processes that maintain atomicity guarantees across shards\n",
      "\n",
      "3. **Plan for Different Deployment Types**\n",
      "   - Backup strategies differ between standalone instances, replica sets, and sharded clusters\n",
      "   - Sharded clusters require more coordination and planning\n",
      "\n",
      "4. **Regular Backup Schedule**\n",
      "   - Establish regular backup windows, especially when using the balancer limitation approach\n",
      "\n",
      "These practices help ensure your MongoDB data is properly protected and can be restored when needed.\n"
     ]
    }
   ],
   "source": [
    "# Test the graph execution to view end-to-end flow\n",
    "execute_graph(\"What are some best practices for data backups in MongoDB?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Give me a summary of the page titled Create a MongoDB Deployment\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'll retrieve the content of the page titled \"Create a MongoDB Deployment\" and provide you with a summary.\n",
      "Tool Calls:\n",
      "  get_page_content_for_summarization (toolu_bdrk_014Pmemi5rnM2TE8JuzCXJrX)\n",
      " Call ID: toolu_bdrk_014Pmemi5rnM2TE8JuzCXJrX\n",
      "  Args:\n",
      "    user_query: Create a MongoDB Deployment\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Create a MongoDB Deployment\n",
      "\n",
      "You can create a free tier MongoDB deployment on MongoDB Atlas to store and manage your data. MongoDB Atlas hosts and manages your MongoDB database in the cloud.\n",
      "\n",
      "## Create a Free MongoDB deployment on Atlas\n",
      "\n",
      "Complete the Get Started with Atlas guide to set up a new Atlas account and load sample data into a new free tier MongoDB deployment.\n",
      "\n",
      "## Save your Credentials\n",
      "\n",
      "After you create your database user, save that user's username and password to a safe location for use in an upcoming step.\n",
      "\n",
      "After you complete these steps, you have a new free tier MongoDB deployment on Atlas, database user credentials, and sample data loaded in your database.\n",
      "\n",
      "If you run into issues on this step, ask for help in the MongoDB Community Forums or submit feedback by using the Rate this page tab on the right or bottom right side of this page.\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "## Summary of \"Create a MongoDB Deployment\"\n",
      "\n",
      "This page provides guidance on creating a free MongoDB deployment using MongoDB Atlas, which is MongoDB's cloud-based database hosting and management service.\n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "1. **Free Tier Deployment**: You can create a free tier MongoDB deployment on MongoDB Atlas to store and manage your data in the cloud.\n",
      "\n",
      "2. **Getting Started**: The page directs users to follow the \"Get Started with Atlas\" guide, which walks through:\n",
      "   - Setting up a new Atlas account\n",
      "   - Creating a new free tier MongoDB deployment\n",
      "   - Loading sample data into the deployment\n",
      "\n",
      "3. **Important Security Step**: After creating a database user, you must save the username and password credentials in a safe location for future use.\n",
      "\n",
      "4. **Expected Outcome**: Upon completion, you will have:\n",
      "   - A new free tier MongoDB deployment on Atlas\n",
      "   - Database user credentials\n",
      "   - Sample data loaded in your database\n",
      "\n",
      "5. **Support Resources**: If you encounter issues, you can seek help through the MongoDB Community Forums or submit feedback using the page rating feature.\n",
      "\n",
      "This is an introductory page designed to help new users quickly set up their first MongoDB database in the cloud using Atlas's free tier offering.\n"
     ]
    }
   ],
   "source": [
    "# Test the graph execution to view end-to-end flow\n",
    "execute_graph(\"Give me a summary of the page titled Create a MongoDB Deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11: Add memory to the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.mongodb import MongoDBSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a MongoDB checkpointer\n",
    "checkpointer = MongoDBSaver(mongodb_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the graph with the checkpointer\n",
    "app = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://langchain-ai.github.io/langgraph/concepts/persistence/#threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_graph_with_memory(thread_id: str, user_input: str) -> None:\n",
    "    \"\"\"\n",
    "    Stream outputs from the graph\n",
    "\n",
    "    Args:\n",
    "        thread_id (str): Thread ID for the checkpointer\n",
    "        user_input (str): User query string\n",
    "    \"\"\"\n",
    "    # Create a runtime config for the thread ID `thread_id`\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    # Stream outputs from each step in the graph\n",
    "    for step in app.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        # Pass the config as an additional parameter\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        # Print the latest message from the step\n",
    "        step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are some best practices for data backups in MongoDB?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'll help you find information about best practices for data backups in MongoDB.\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01LkqfAxww5ux1XpfHYty88P)\n",
      " Call ID: toolu_bdrk_01LkqfAxww5ux1XpfHYty88P\n",
      "  Args:\n",
      "    user_query: best practices for data backups in MongoDB\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "FTDC data contains certain host machine information such as hostnames, operating system information, and the options or settings used to start the `mongod` or `mongos`. This information may be considered protected or confidential by some organizations or regulatory bodies, but is not typically considered to be Personally Identifiable Information (PII). For clusters where these fields are configured with protected, confidential, or PII data, please notify MongoDB engineers before sending FTDC data to coordinate appropriate security measures.\n",
      "\n",
      "On Windows, to collect system data such as disk, cpu, and memory, FTDC requires Microsoft access permissions from the following groups:\n",
      "\n",
      "- Performance Monitor Users\n",
      "\n",
      "- Performance Log Users\n",
      "\n",
      "If the user running `mongod` and `mongos` is not an administrator, add them to these groups to log FTDC data. For more information, see the Microsoft documentation here.\n",
      "\n",
      "FTDC periodically collects statistics produced by the following commands:\n",
      "\n",
      "- `serverStatus`\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01DSZDiTMfYwCtXY6S2t2fLj)\n",
      " Call ID: toolu_bdrk_01DSZDiTMfYwCtXY6S2t2fLj\n",
      "  Args:\n",
      "    user_query: MongoDB backup strategies recommendations mongodump file system snapshots\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01Qp6ebTUBk3udHbeain1YQc)\n",
      " Call ID: toolu_bdrk_01Qp6ebTUBk3udHbeain1YQc\n",
      "  Args:\n",
      "    user_query: MongoDB backup methods replica sets point in time recovery backup frequency\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "Just for the sake of it, I also used multi-document ACID transactions in a few methods where it could potentially make sense to use ACID transactions. You can check all the code in the `MongoDBPersonRepository` class.\n",
      "\n",
      "Here is an example:\n",
      "\n",
      "```java\n",
      "private static final TransactionOptions txnOptions = TransactionOptions.builder()\n",
      "    .readPreference(ReadPreference.primary())\n",
      "    .readConcern(ReadConcern.MAJORITY)\n",
      "    .writeConcern(WriteConcern.MAJORITY)\n",
      "    .build();\n",
      "\n",
      "@Override\n",
      "public List saveAll(List personEntities) {\n",
      "    try (ClientSession clientSession = client.startSession()) {\n",
      "        return clientSession.withTransaction(() -> {\n",
      "            personEntities.forEach(p -> p.setId(new ObjectId()));\n",
      "            personCollection.insertMany(clientSession, personEntities);\n",
      "            return personEntities;\n",
      "        }, txnOptions);\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "As you can see, Iâ€™m using an auto-closeable try-with-resources which will automatically close the client session at the end. This helps me to keep the code clean and simple.\n",
      "\n",
      "Some of you may argue that it is actually too simple because transactions (and write operations, in general) can throw exceptions, and Iâ€™m not handling any of them hereâ€¦ You are absolutely right and this is an excellent transition to the next part of this article.\n",
      "\n",
      "## Exception management\n",
      "\n",
      "Transactions in MongoDB can raise exceptions for various reasons, and I donâ€™t want to go into the details too much here, but since MongoDB 3.6, any write operation that fails can be automatically retried once. And the transactions are no different. See the documentation for retryWrites.\n",
      "\n",
      "If retryable writes are disabled or if a write operation fails twice, then MongoDB will send a MongoException (extends RuntimeException) which should be handled properly.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01Uqm1sCrRfBpJzqPYwQhk1r)\n",
      " Call ID: toolu_bdrk_01Uqm1sCrRfBpJzqPYwQhk1r\n",
      "  Args:\n",
      "    user_query: backup best practices testing backups offsite storage encryption\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "\n",
      "FTDC data contains certain host machine information such as hostnames, operating system information, and the options or settings used to start the `mongod` or `mongos`. This information may be considered protected or confidential by some organizations or regulatory bodies, but is not typically considered to be Personally Identifiable Information (PII). For clusters where these fields are configured with protected, confidential, or PII data, please notify MongoDB engineers before sending FTDC data to coordinate appropriate security measures.\n",
      "\n",
      "On Windows, to collect system data such as disk, cpu, and memory, FTDC requires Microsoft access permissions from the following groups:\n",
      "\n",
      "- Performance Monitor Users\n",
      "\n",
      "- Performance Log Users\n",
      "\n",
      "If the user running `mongod` and `mongos` is not an administrator, add them to these groups to log FTDC data. For more information, see the Microsoft documentation here.\n",
      "\n",
      "FTDC periodically collects statistics produced by the following commands:\n",
      "\n",
      "- `serverStatus`\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_014tUDg6GAc4V6FFLjfTqiMR)\n",
      " Call ID: toolu_bdrk_014tUDg6GAc4V6FFLjfTqiMR\n",
      "  Args:\n",
      "    user_query: MongoDB backup considerations replica set secondary node snapshot\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "FTDC data contains certain host machine information such as hostnames, operating system information, and the options or settings used to start the `mongod` or `mongos`. This information may be considered protected or confidential by some organizations or regulatory bodies, but is not typically considered to be Personally Identifiable Information (PII). For clusters where these fields are configured with protected, confidential, or PII data, please notify MongoDB engineers before sending FTDC data to coordinate appropriate security measures.\n",
      "\n",
      "On Windows, to collect system data such as disk, cpu, and memory, FTDC requires Microsoft access permissions from the following groups:\n",
      "\n",
      "- Performance Monitor Users\n",
      "\n",
      "- Performance Log Users\n",
      "\n",
      "If the user running `mongod` and `mongos` is not an administrator, add them to these groups to log FTDC data. For more information, see the Microsoft documentation here.\n",
      "\n",
      "FTDC periodically collects statistics produced by the following commands:\n",
      "\n",
      "- `serverStatus`\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_page_content_for_summarization (toolu_bdrk_01SxdHgSojUvatDe4abP4sDH)\n",
      " Call ID: toolu_bdrk_01SxdHgSojUvatDe4abP4sDH\n",
      "  Args:\n",
      "    user_query: MongoDB backup methods\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Document not found\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_page_content_for_summarization (toolu_bdrk_014ZMkeWbRvZ2xC3hJwPteYW)\n",
      " Call ID: toolu_bdrk_014ZMkeWbRvZ2xC3hJwPteYW\n",
      "  Args:\n",
      "    user_query: backup and restore\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Document not found\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01Y8FMP9cTryTv6No3wLCMPj)\n",
      " Call ID: toolu_bdrk_01Y8FMP9cTryTv6No3wLCMPj\n",
      "  Args:\n",
      "    user_query: mongodump mongorestore backup procedure standalone replica set\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "\n",
      "# Administration\n",
      "\n",
      "The administration documentation addresses the ongoing operation and maintenance of MongoDB instances and deployments. This documentation includes both high level overviews of these concerns as well as tutorials that cover specific procedures and processes for operating MongoDB.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01YX15dzZadnatP5DBicytN6)\n",
      " Call ID: toolu_bdrk_01YX15dzZadnatP5DBicytN6\n",
      "  Args:\n",
      "    user_query: backup strategies file system snapshot LVM EBS consistent backup\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the information I've gathered from the MongoDB documentation, here are some **best practices for data backups in MongoDB**:\n",
      "\n",
      "## Backup Methods\n",
      "\n",
      "1. **Use Managed Backup Solutions (Recommended)**\n",
      "   - **MongoDB Atlas, Cloud Manager, or Ops Manager** - These provide coordinated backup and restore processes that maintain atomicity guarantees of transactions across shards\n",
      "   - These are particularly recommended for sharded clusters\n",
      "\n",
      "2. **File System Snapshots**\n",
      "   - Can be more efficient than MongoDB tools if your system configuration supports them\n",
      "   - Suitable for backing up each component in a cluster individually\n",
      "   - Requires stopping the cluster balancer during backup operations\n",
      "\n",
      "3. **mongodump and mongorestore**\n",
      "   - Can be used as a backup strategy for various deployment types\n",
      "   - For sharded clusters, requires additional precautions:\n",
      "     - Stop the sharded cluster balancer\n",
      "     - Use the `fsync` command or `db.fsyncLock()` method on `mongos` to block writes during backups\n",
      "   - Back up each component in the cluster individually\n",
      "\n",
      "## Key Best Practices\n",
      "\n",
      "1. **Minimize Impact on Production**\n",
      "   - For sharded clusters, stop or limit the cluster balancer operation to provide a window for regular backup operations\n",
      "   - Use `fsync` or `db.fsyncLock()` to ensure data consistency during backups\n",
      "\n",
      "2. **Maintain Consistency**\n",
      "   - Ensure backups are consistent, especially in sharded environments\n",
      "   - Use coordinated backup processes that maintain atomicity guarantees across shards\n",
      "\n",
      "3. **Plan for Different Deployment Types**\n",
      "   - Backup strategies differ between standalone instances, replica sets, and sharded clusters\n",
      "   - Sharded clusters require more coordination and planning\n",
      "\n",
      "4. **Regular Backup Schedule**\n",
      "   - Establish regular backup windows, especially when using the balancer limitation approach\n",
      "\n",
      "These practices help ensure your MongoDB data is properly protected and can be restored when needed.\n"
     ]
    }
   ],
   "source": [
    "# Test graph execution with thread ID\n",
    "execute_graph_with_memory(\n",
    "    \"1\",\n",
    "    \"What are some best practices for data backups in MongoDB?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What did I just ask you?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You just asked me: \"What are some best practices for data backups in MongoDB?\"\n"
     ]
    }
   ],
   "source": [
    "# Follow-up question to ensure message history works\n",
    "execute_graph_with_memory(\n",
    "    \"1\",\n",
    "    \"What did I just ask you?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1259,
   "metadata": {},
   "outputs": [],
   "source": [
    "####THIS IS THE LONG TERM MEMORY SECTION#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long-Term Memory Implementation: Hot Path (Memory Tools)\n",
    "\n",
    "This implementation uses **Memory Tools** (`create_manage_memory_tool` and `create_search_memory_tool`) \n",
    "which allow the agent to **consciously** manage its own long-term memory.\n",
    "\n",
    "## How it works:\n",
    "1. The agent has access to `manage_memory` tool to save important user information\n",
    "2. The agent has access to `search_memory` tool to retrieve relevant memories\n",
    "3. Memories persist in MongoDB and survive across conversation threads\n",
    "\n",
    "## References:\n",
    "- [LangMem Hot Path Quickstart](https://langchain-ai.github.io/langmem/hot_path_quickstart/)\n",
    "- [LangMem Memory Tools Reference](https://langchain-ai.github.io/langmem/reference/tools/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS FOR LONG-TERM MEMORY (HOT PATH)\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
    "from langgraph.store.mongodb import MongoDBStore, create_vector_index_config\n",
    "from langchain_voyageai import VoyageAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MongoDBStore initialized for mongodb_genai_devday_agents.memories\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SETUP MONGODB STORE FOR LONG-TERM MEMORY\n",
    "# =============================================================================\n",
    "\n",
    "MEMORY_DB_NAME = \"mongodb_genai_devday_agents\"\n",
    "MEMORY_COLLECTION_NAME = \"memories\"\n",
    "\n",
    "# Get collection reference for direct queries\n",
    "memory_collection = mongodb_client[MEMORY_DB_NAME][MEMORY_COLLECTION_NAME]\n",
    "\n",
    "# Create vector index configuration for semantic search\n",
    "memory_index_config = create_vector_index_config(\n",
    "    dims=1024,\n",
    "    embed=VoyageAIEmbeddings(model=\"voyage-3\"),\n",
    "    fields=[\"content\"],\n",
    "    name=\"memory_vector_index\"\n",
    ")\n",
    "\n",
    "# Initialize MongoDBStore with collection object (NOT from_conn_string)\n",
    "# IMPORTANT: from_conn_string() returns a context manager, not a store object\n",
    "memory_store = MongoDBStore(\n",
    "    collection=memory_collection,\n",
    "    index_config=memory_index_config\n",
    ")\n",
    "\n",
    "print(f\"âœ… MongoDBStore initialized for {MEMORY_DB_NAME}.{MEMORY_COLLECTION_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Memory tools created:\n",
      "   - manage_memory: Save/update/delete memories\n",
      "   - search_memory: Search existing memories\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CREATE MEMORY TOOLS (HOT PATH)\n",
    "# These tools allow the agent to consciously manage its memory\n",
    "# =============================================================================\n",
    "\n",
    "# Tool for saving/updating/deleting memories\n",
    "# Note: namespace uses {langgraph_user_id} which must match the config key\n",
    "'''manage_memory_tool = create_manage_memory_tool(\n",
    "    namespace=(\"memories\", \"{langgraph_user_id}\"),  # User-scoped memories\n",
    "    instructions=\"\"\"Save important user information to memory, including:\n",
    "    - User's role or job title (e.g., DBA, developer, architect)\n",
    "    - User's expertise level and areas of focus\n",
    "    - User's preferences for how information should be presented\n",
    "    - Topics the user is interested in\n",
    "    Always save relevant user context when they share it.\"\"\"\n",
    ")'''\n",
    "manage_memory_tool = create_manage_memory_tool(\n",
    "    namespace=(\"memories\", \"{langgraph_user_id}\"),  # User-scoped memories\n",
    "   \n",
    ")\n",
    "\n",
    "# Tool for searching memories\n",
    "search_memory_tool = create_search_memory_tool(\n",
    "    namespace=(\"memories\", \"{langgraph_user_id}\")\n",
    ")\n",
    "\n",
    "print(\"âœ… Memory tools created:\")\n",
    "print(f\"   - {manage_memory_tool.name}: Save/update/delete memories\")\n",
    "print(f\"   - {search_memory_tool.name}: Search existing memories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Total tools available: 4\n",
      "   - get_information_for_question_answering\n",
      "   - get_page_content_for_summarization\n",
      "   - manage_memory\n",
      "   - search_memory\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# COMBINE ORIGINAL TOOLS WITH MEMORY TOOLS\n",
    "# =============================================================================\n",
    "\n",
    "# Add memory tools to the existing tools list\n",
    "'''tools_with_memory = tools + [manage_memory_tool, search_memory_tool]\n",
    "\n",
    "# Update tools_by_name dictionary\n",
    "tools_by_name_with_memory = {tool.name: tool for tool in tools_with_memory}'''\n",
    "\n",
    "tools = tools + [manage_memory_tool, search_memory_tool]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "print(f\"âœ… Total tools available: {len(tools)}\")\n",
    "for tool in tools:\n",
    "    print(f\"   - {tool.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Memory-aware prompt created\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CREATE MEMORY-AWARE PROMPT\n",
    "# This prompt instructs the agent to use memory tools\n",
    "# =============================================================================\n",
    "\n",
    "memory_aware_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a helpful AI assistant with persistent memory capabilities.\n",
    "You can answer questions about MongoDB documentation using your tools.\n",
    "\n",
    "IMPORTANT MEMORY INSTRUCTIONS:\n",
    "1. When a user shares personal information (their role, expertise, preferences, interests),\n",
    "   ALWAYS use the manage_memory tool to save it immediately.\n",
    "2. At the start of conversations, use search_memory to check for relevant user context.\n",
    "3. Tailor your responses based on what you remember about the user.\n",
    "4. Acknowledge when you save something to memory.\n",
    "5. CRITICAL: Use only the information provided by tools to respond to user questions. Say you Do not know if you the tools do not provide relevant info\n",
    "## Tool Usage Guidelines\n",
    "- Do NOT call the same retrieval tool more than 2 times for a single user question\n",
    "- If consecutive searches return similar content, stop searching and synthesize what you have\n",
    "- Only search for terms present in or directly implied by the user's question\n",
    "- Do not invent increasingly specific queries hoping for different results\n",
    "\n",
    "Available tools: {tool_names}\n",
    "\n",
    "Think step-by-step:\n",
    "1. First, search memory for relevant user context\n",
    "2. If user shares new info about themselves, save it to memory\n",
    "3. Use documentation tools to answer technical questions\n",
    "4. Provide personalized responses based on user context\"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fill in tool names\n",
    "memory_aware_prompt = memory_aware_prompt.partial(\n",
    "    #tool_names=\", \".join([tool.name for tool in tools_with_memory])\n",
    "    tool_names=\", \".join([tool.name for tool in tools])\n",
    ")\n",
    "\n",
    "print(\"âœ… Memory-aware prompt created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLM chain with memory tools created\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CREATE MEMORY-AWARE LLM CHAIN\n",
    "# =============================================================================\n",
    "\n",
    "# Bind all tools (including memory tools) to the LLM\n",
    "#llm_with_memory_tools = llm.bind_tools(tools_with_memory)\n",
    "llm_with_tools = memory_aware_prompt | llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "# Chain prompt with LLM\n",
    "#llm_chain_with_memory = memory_aware_prompt | llm_with_memory_tools\n",
    "\n",
    "print(\"âœ… LLM chain with memory tools created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def agent_with_memory(state: GraphState) -> Dict[str, List]:\\n    \"\"\"\\n    Agent node with memory capabilities.\\n    Uses the memory-aware prompt and tools.\\n    \"\"\"\\n    messages = state[\"messages\"]\\n    result = llm_chain_with_memory.invoke(messages)\\n    return {\"messages\": [result]}\\n\\n\\ndef tool_node_with_memory(state: GraphState) -> Dict[str, List]:\\n    \"\"\"\\n    Tool node that handles all tools including memory tools.\\n    \"\"\"\\n    result = []\\n    tool_calls = state[\"messages\"][-1].tool_calls\\n    \\n    for tool_call in tool_calls:\\n        tool_name = tool_call[\"name\"]\\n        tool = tools_by_name_with_memory[tool_name]\\n        \\n        try:\\n            observation = tool.invoke(tool_call[\"args\"])\\n            result.append(ToolMessage(\\n                content=str(observation), \\n                tool_call_id=tool_call[\"id\"]\\n            ))\\n        except Exception as e:\\n            result.append(ToolMessage(\\n                content=f\"Error executing {tool_name}: {str(e)}\", \\n                tool_call_id=tool_call[\"id\"]\\n            ))\\n    \\n    return {\"messages\": result}\\n\\nprint(\"âœ… Memory-aware agent and tool nodes defined\")'"
      ]
     },
     "execution_count": 1266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DEFINE MEMORY-AWARE AGENT AND TOOL NODES\n",
    "# =============================================================================\n",
    "\n",
    "'''def agent_with_memory(state: GraphState) -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Agent node with memory capabilities.\n",
    "    Uses the memory-aware prompt and tools.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    result = llm_chain_with_memory.invoke(messages)\n",
    "    return {\"messages\": [result]}\n",
    "\n",
    "\n",
    "def tool_node_with_memory(state: GraphState) -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Tool node that handles all tools including memory tools.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    \n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool = tools_by_name_with_memory[tool_name]\n",
    "        \n",
    "        try:\n",
    "            observation = tool.invoke(tool_call[\"args\"])\n",
    "            result.append(ToolMessage(\n",
    "                content=str(observation), \n",
    "                tool_call_id=tool_call[\"id\"]\n",
    "            ))\n",
    "        except Exception as e:\n",
    "            result.append(ToolMessage(\n",
    "                content=f\"Error executing {tool_name}: {str(e)}\", \n",
    "                tool_call_id=tool_call[\"id\"]\n",
    "            ))\n",
    "    \n",
    "    return {\"messages\": result}\n",
    "\n",
    "print(\"âœ… Memory-aware agent and tool nodes defined\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Memory-aware graph compiled with:\n",
      "   - Checkpointer: Short-term memory (conversation threads)\n",
      "   - Store: Long-term memory (persistent user memories)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BUILD MEMORY-AWARE GRAPH\n",
    "# =============================================================================\n",
    "\n",
    "# Create new graph with memory capabilities\n",
    "'''memory_graph = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes\n",
    "memory_graph.add_node(\"agent\", agent_with_memory)\n",
    "memory_graph.add_node(\"tools\", tool_node_with_memory)\n",
    "\n",
    "# Add edges\n",
    "memory_graph.add_edge(START, \"agent\")\n",
    "memory_graph.add_edge(\"tools\", \"agent\")\n",
    "memory_graph.add_conditional_edges(\n",
    "    \"agent\", \n",
    "    route_tools, \n",
    "    {\"tools\": \"tools\", END: END}\n",
    ")\n",
    "'''\n",
    "# Compile with checkpointer (short-term) AND store (long-term)\n",
    "'''app_with_memory = memory_graph.compile(\n",
    "    checkpointer=checkpointer,  # Short-term memory (conversation history)\n",
    "    store=memory_store          # Long-term memory (persistent memories)\n",
    ")'''\n",
    "app_with_memory = graph.compile(\n",
    "    checkpointer=checkpointer,  # Short-term memory (conversation history)\n",
    "    store=memory_store          # Long-term memory (persistent memories)\n",
    ")\n",
    "\n",
    "print(\"âœ… Memory-aware graph compiled with:\")\n",
    "print(\"   - Checkpointer: Short-term memory (conversation threads)\")\n",
    "print(\"   - Store: Long-term memory (persistent user memories)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x768a39ad6c90>"
      ]
     },
     "execution_count": 1268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE THE MEMORY-AWARE GRAPH\n",
    "# =============================================================================\n",
    "\n",
    "app_with_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXECUTION FUNCTION WITH MEMORY\n",
    "# =============================================================================\n",
    "\n",
    "def run_agent_with_memory(thread_id: str, user_id: str, user_input: str):\n",
    "    \"\"\"\n",
    "    Execute the memory-aware agent.\n",
    "    \n",
    "    Args:\n",
    "        thread_id: Unique conversation thread ID (short-term memory)\n",
    "        user_id: User identifier for memory scoping (long-term memory)\n",
    "        user_input: User's message\n",
    "    \"\"\"\n",
    "    # Config with both thread_id and langgraph_user_id\n",
    "    # IMPORTANT: langgraph_user_id must match the namespace pattern {langgraph_user_id}\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id,\n",
    "            \"langgraph_user_id\": user_id,  # Required for memory namespace\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Thread: {thread_id} | User: {user_id}\")\n",
    "    print(f\"Input: {user_input}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Stream the response\n",
    "    for step in app_with_memory.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        msg = step[\"messages\"][-1]\n",
    "        if hasattr(msg, 'pretty_print'):\n",
    "            msg.pretty_print()\n",
    "        else:\n",
    "            print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Save User Information to Memory\n",
    "\n",
    "In this test, the user introduces themselves. The agent should:\n",
    "1. Recognize this is personal information\n",
    "2. Use `manage_memory` tool to save it\n",
    "3. Acknowledge that it saved the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Thread: session-02 | User: user-104\n",
      "Input: Hi! I'm a senior DBA focusing on disaster recovery and backup strategies. Please remember this about me.\n",
      "============================================================\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi! I'm a senior DBA focusing on disaster recovery and backup strategies. Please remember this about me.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  manage_memory (toolu_bdrk_01VJ5VGRh9Uoc9S8nP58MBKE)\n",
      " Call ID: toolu_bdrk_01VJ5VGRh9Uoc9S8nP58MBKE\n",
      "  Args:\n",
      "    action: create\n",
      "    content: User is a senior DBA (Database Administrator) with a focus on disaster recovery and backup strategies\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "created memory 9d811dbe-e2af-42c9-8732-8ab6ee7ce103\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! I've saved that information to memory. It's great to meet you! As a senior DBA specializing in disaster recovery and backup strategies, you're likely interested in topics like:\n",
      "\n",
      "- MongoDB backup and restore procedures\n",
      "- Point-in-time recovery\n",
      "- Replica set configurations for high availability\n",
      "- Backup strategies (mongodump, filesystem snapshots, Cloud backups)\n",
      "- Disaster recovery planning and testing\n",
      "- Data consistency and durability\n",
      "\n",
      "How can I help you with MongoDB today? Whether you need information about backup methods, recovery procedures, or best practices for disaster recovery planning, I'm here to assist!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST 1: User introduces themselves - Agent should save to memory\n",
    "# =============================================================================\n",
    "\n",
    "run_agent_with_memory(\n",
    "    thread_id=\"session-02\",\n",
    "    user_id=\"user-104\",\n",
    "    user_input=\"Hi! I'm a senior DBA focusing on disaster recovery and backup strategies. Please remember this about me.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checking MongoDB for saved memories ===\n",
      "\n",
      "Collection: mongodb_genai_devday_agents.memories\n",
      "\n",
      "Total documents in collection: 1\n",
      "\n",
      "--- Memory Document ---\n",
      "Namespace: ['memories', 'user-104']\n",
      "Key: 9d811dbe-e2af-42c9-8732-8ab6ee7ce103\n",
      "Value: {'content': 'User is a senior DBA (Database Administrator) with a focus on disaster recovery and backup strategies'}\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VERIFY: Check if memory was saved to MongoDB\n",
    "# =============================================================================\n",
    "\n",
    "time.sleep(2)  # Brief pause for write to complete\n",
    "\n",
    "print(\"=== Checking MongoDB for saved memories ===\")\n",
    "print(f\"\\nCollection: {MEMORY_DB_NAME}.{MEMORY_COLLECTION_NAME}\")\n",
    "\n",
    "# Query memories for user-123\n",
    "user_memories = list(memory_collection.find({}))\n",
    "print(f\"\\nTotal documents in collection: {len(user_memories)}\")\n",
    "\n",
    "for doc in user_memories:\n",
    "    print(f\"\\n--- Memory Document ---\")\n",
    "    print(f\"Namespace: {doc.get('namespace', 'N/A')}\")\n",
    "    print(f\"Key: {doc.get('key', 'N/A')}\")\n",
    "    print(f\"Value: {doc.get('value', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: New Conversation Thread Recalls Memory\n",
    "\n",
    "In this test, we start a NEW conversation thread but with the SAME user.\n",
    "The agent should:\n",
    "1. Search for existing memories about this user\n",
    "2. Find the previously saved information\n",
    "3. Use that context to personalize the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Thread: session-0002 | User: user-104\n",
      "Input: What do you remember about me? And can you give me backup advice based on my role?\n",
      "============================================================\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What do you remember about me? And can you give me backup advice based on my role?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'll search my memory for information about you and then provide tailored backup advice.\n",
      "Tool Calls:\n",
      "  search_memory (toolu_bdrk_01P8hwG9x9UoKmaxpCA2odXz)\n",
      " Call ID: toolu_bdrk_01P8hwG9x9UoKmaxpCA2odXz\n",
      "  Args:\n",
      "    query: user role expertise preferences\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "[{\"namespace\":[\"memories\",\"user-104\"],\"key\":\"9d811dbe-e2af-42c9-8732-8ab6ee7ce103\",\"value\":{\"content\":\"User is a senior DBA (Database Administrator) with a focus on disaster recovery and backup strategies\"},\"created_at\":\"2025-12-22T03:11:24.918000\",\"updated_at\":\"2025-12-22T03:11:24.918000\",\"score\":0.6836355924606323}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great! I remember that **you're a senior DBA with a focus on disaster recovery and backup strategies**.\n",
      "\n",
      "Now let me get you MongoDB backup advice tailored to your expertise level:\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01NfXPHnAhD5QQbrAQayjLdC)\n",
      " Call ID: toolu_bdrk_01NfXPHnAhD5QQbrAQayjLdC\n",
      "  Args:\n",
      "    user_query: MongoDB backup strategies disaster recovery best practices for DBAs\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01BmnxjZPCDU85ge8FwmfR7r)\n",
      " Call ID: toolu_bdrk_01BmnxjZPCDU85ge8FwmfR7r\n",
      "  Args:\n",
      "    user_query: MongoDB backup methods mongodump replica set backup point-in-time recovery\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on what I remember about you and the MongoDB documentation, here's backup advice tailored for a senior DBA focused on disaster recovery:\n",
      "\n",
      "## MongoDB Backup Strategies for Your Role\n",
      "\n",
      "### **Primary Backup Methods:**\n",
      "\n",
      "1. **Coordinated Backup Solutions (Recommended for Production)**\n",
      "   - **MongoDB Atlas, Cloud Manager, or Ops Manager** - These maintain atomicity guarantees of transactions across shards, which is critical for your disaster recovery planning\n",
      "   - Best for enterprise environments where consistency is paramount\n",
      "\n",
      "2. **File System Snapshots**\n",
      "   - More efficient than MongoDB tools if your infrastructure supports it\n",
      "   - Back up each component individually\n",
      "   - **Important**: Requires stopping the cluster balancer during backup operations\n",
      "\n",
      "3. **mongodump/mongorestore**\n",
      "   - Logical backup approach\n",
      "   - For sharded clusters: Must stop the balancer and use `fsync` or `db.fsyncLock()` on `mongos` to block writes during backups\n",
      "   - Back up each component in the cluster individually\n",
      "\n",
      "### **Critical Considerations for Sharded Clusters:**\n",
      "\n",
      "- **Balancer Management**: You'll need to schedule backup windows when the balancer is stopped or limited\n",
      "- **Transaction Atomicity**: For multi-shard transactions, use coordinated backup processes (Atlas/Cloud Manager/Ops Manager) to maintain consistency\n",
      "- **Component-Level Backups**: Each shard, config server, and mongos needs individual attention in your backup strategy\n",
      "\n",
      "### **DR Planning Recommendations:**\n",
      "\n",
      "Given your disaster recovery focus, consider:\n",
      "- Testing restore procedures for entire sharded cluster scenarios\n",
      "- Documenting balancer stop/start procedures as part of your backup runbooks\n",
      "- Evaluating whether file system snapshots align with your RTO/RPO requirements\n",
      "- Implementing one of the managed backup solutions for automated, consistent backups\n",
      "\n",
      "Would you like me to dive deeper into any specific backup method or disaster recovery scenario?\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST 2: New thread, same user - Agent should recall memory\n",
    "# =============================================================================\n",
    "\n",
    "run_agent_with_memory(\n",
    "    thread_id=\"session-0002\",  # NEW thread\n",
    "    user_id=\"user-104\",        # SAME user\n",
    "    user_input=\"What do you remember about me? And can you give me backup advice based on my role?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Technical Question with User Context\n",
    "\n",
    "Ask a technical question. The agent should:\n",
    "1. Recall that the user is a DBA focused on disaster recovery\n",
    "2. Tailor the response to their expertise level\n",
    "3. Focus on backup/recovery aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Thread: session-00003 | User: user-104\n",
      "Input: What are the best practices for MongoDB backups?\n",
      "============================================================\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are the best practices for MongoDB backups?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'll search for information about MongoDB backup best practices for you.\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01CAPDToxNVtvquUrrGPYJuE)\n",
      " Call ID: toolu_bdrk_01CAPDToxNVtvquUrrGPYJuE\n",
      "  Args:\n",
      "    user_query: MongoDB backup best practices\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "# Configuration and Maintenance\n",
      "\n",
      "This section describes routine management operations, including updating your MongoDB deployment's configuration.\n",
      "\n",
      "Outlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n",
      "\n",
      "Upgrade a MongoDB deployment to a different patch release within the same major release series.\n",
      "\n",
      "Start, configure, and manage running `mongod` process.\n",
      "\n",
      "Stop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n",
      "\n",
      "Archive the current log files and start new ones.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_019B9DBez3T9F5fkedHUJ2GY)\n",
      " Call ID: toolu_bdrk_019B9DBez3T9F5fkedHUJ2GY\n",
      "  Args:\n",
      "    user_query: backup strategies recommendations mongodump file system snapshots\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Backup and Restore Sharded Clusters\n",
      "\n",
      "The following tutorials describe backup and restoration for sharded clusters:\n",
      "\n",
      "To use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n",
      "\n",
      "Sharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n",
      "\n",
      "- MongoDB Atlas\n",
      "\n",
      "- MongoDB Cloud Manager\n",
      "\n",
      "- MongoDB Ops Manager\n",
      "\n",
      "Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n",
      "\n",
      "Create backups using `mongodump` to back up each component in the cluster individually.\n",
      "\n",
      "Limit the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "An outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n",
      "\n",
      "- `replSetGetStatus` (`mongod` only)\n",
      "\n",
      "- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n",
      "\n",
      "- `connPoolStats` (`mongos` only)\n",
      "\n",
      "Depending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n",
      "\n",
      "- CPU utilization\n",
      "\n",
      "- Memory utilization\n",
      "\n",
      "- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n",
      "\n",
      "- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n",
      "\n",
      "If the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n",
      "\n",
      "FTDC collects statistics produced by the following commands on file rotation or startup:\n",
      "\n",
      "- `getCmdLineOpts`\n",
      "\n",
      "- `buildInfo`\n",
      "\n",
      "- `hostInfo`\n",
      "\n",
      "`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n",
      "\n",
      "`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n",
      "\n",
      "To help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n",
      "\n",
      "FTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n",
      "\n",
      "MongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n",
      "\n",
      "FTDC data **never** contains any of the following information:\n",
      "\n",
      "- Samples of queries, query predicates, or query results\n",
      "\n",
      "- Data sampled from any end-user collection or index\n",
      "\n",
      "- System or MongoDB user credentials or security certificates\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the MongoDB documentation, here are the **best practices for MongoDB backups**:\n",
      "\n",
      "## Backup Methods\n",
      "\n",
      "1. **Managed Backup Solutions (Recommended for Production)**\n",
      "   - **MongoDB Atlas** - Fully managed cloud solution\n",
      "   - **MongoDB Cloud Manager** - Cloud-based management\n",
      "   - **MongoDB Ops Manager** - On-premises management\n",
      "   \n",
      "   These solutions maintain atomicity guarantees of transactions across shards and provide coordinated backup and restore processes.\n",
      "\n",
      "2. **File System Snapshots**\n",
      "   - More efficient than MongoDB tools if your system configuration supports it\n",
      "   - Requires stopping the cluster balancer during backup\n",
      "   - Back up each component in the cluster individually\n",
      "\n",
      "3. **mongodump/mongorestore**\n",
      "   - Suitable for backing up individual components\n",
      "   - For sharded clusters, you must:\n",
      "     - Stop the sharded cluster balancer\n",
      "     - Use the `fsync` command or `db.fsyncLock()` method on `mongos` to block writes during backups\n",
      "\n",
      "## Key Best Practices\n",
      "\n",
      "### For Sharded Clusters:\n",
      "- **Stop the balancer** before taking backups to ensure data consistency\n",
      "- **Block writes** during backup operations using `fsync` or `db.fsyncLock()`\n",
      "- **Schedule balancer operations** to provide regular backup windows\n",
      "- Use coordinated backup processes that maintain transaction atomicity across shards\n",
      "\n",
      "### General Recommendations:\n",
      "- Choose file system snapshots over MongoDB tools when possible for better efficiency\n",
      "- For production environments, prefer managed solutions (Atlas, Cloud Manager, or Ops Manager) for their coordinated backup capabilities\n",
      "- Back up each component of a sharded cluster individually\n",
      "\n",
      "Would you like more specific information about any particular backup method or scenario?\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST 3: Technical question - Agent should use memory context\n",
    "# =============================================================================\n",
    "\n",
    "run_agent_with_memory(\n",
    "    thread_id=\"session-00003\",\n",
    "    user_id=\"user-104\",\n",
    "    user_input=\"What are the best practices for MongoDB backups?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: Different User (Memory Isolation)\n",
    "\n",
    "Test with a different user to verify memory isolation.\n",
    "This user should NOT see user-123's memories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Thread: session-0044 | User: user-456\n",
      "Input: What do you know about me? I'm a cloud architect interested in MongoDB Atlas scaling.\n",
      "============================================================\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What do you know about me? I'm a cloud architect interested in MongoDB Atlas scaling.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_memory (toolu_bdrk_01Wamqgg4qqh63SGAEX6mDxR)\n",
      " Call ID: toolu_bdrk_01Wamqgg4qqh63SGAEX6mDxR\n",
      "  Args:\n",
      "    query: cloud architect MongoDB Atlas scaling\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "[]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I don't have any previous information about you in my memory. Thank you for sharing that with me! Let me save this information so I can better assist you in the future.\n",
      "Tool Calls:\n",
      "  manage_memory (toolu_bdrk_0181wSXhJpjyw4jNnxygF29u)\n",
      " Call ID: toolu_bdrk_0181wSXhJpjyw4jNnxygF29u\n",
      "  Args:\n",
      "    action: create\n",
      "    content: User is a cloud architect with interest in MongoDB Atlas scaling\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "created memory 7c5be609-c32c-44b5-909e-eb4339fb4728\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great! I've saved that you're a cloud architect interested in MongoDB Atlas scaling. \n",
      "\n",
      "Since you're focused on Atlas scaling, I can help you with topics like:\n",
      "- **Cluster scaling** (vertical and horizontal scaling options)\n",
      "- **Auto-scaling** configurations\n",
      "- **Sharding** strategies for horizontal scaling\n",
      "- **Performance optimization** for scaled deployments\n",
      "- **Cluster tier** selection and sizing\n",
      "- **Storage and compute scaling**\n",
      "\n",
      "Is there a specific aspect of MongoDB Atlas scaling you'd like to explore or any questions you have about scaling your Atlas deployments?\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST 4: Different user - Should NOT have user-123's memories\n",
    "# =============================================================================\n",
    "\n",
    "run_agent_with_memory(\n",
    "    thread_id=\"session-0044\",\n",
    "    user_id=\"user-456\",  # DIFFERENT user\n",
    "    user_input=\"What do you know about me? I'm a cloud architect interested in MongoDB Atlas scaling.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Thread: session-108 | User: user-456\n",
      "Input: I like Oracle related stuff and Java Programming, tell me about MongoDB \n",
      "============================================================\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like Oracle related stuff and Java Programming, tell me about MongoDB \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_memory (toolu_bdrk_01BaFZaV9epax1JaH1RJu6ZV)\n",
      " Call ID: toolu_bdrk_01BaFZaV9epax1JaH1RJu6ZV\n",
      "  Args:\n",
      "    query: user preferences interests Oracle Java\n",
      "  manage_memory (toolu_bdrk_019SSPveBXpyHkF8hLGiahvt)\n",
      " Call ID: toolu_bdrk_019SSPveBXpyHkF8hLGiahvt\n",
      "  Args:\n",
      "    action: create\n",
      "    content: User is interested in Oracle-related technologies and Java programming\n",
      "  get_information_for_question_answering (toolu_bdrk_01GCXjQtzoAYkfyrkq5qFCQW)\n",
      " Call ID: toolu_bdrk_01GCXjQtzoAYkfyrkq5qFCQW\n",
      "  Args:\n",
      "    user_query: What is MongoDB overview introduction\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "# Administration\n",
      "\n",
      "The administration documentation addresses the ongoing operation and maintenance of MongoDB instances and deployments. This documentation includes both high level overviews of these concerns as well as tutorials that cover specific procedures and processes for operating MongoDB.\n",
      "\n",
      "# Create a MongoDB Deployment\n",
      "\n",
      "You can create a free tier MongoDB deployment on MongoDB Atlas to store and manage your data. MongoDB Atlas hosts and manages your MongoDB database in the cloud.\n",
      "\n",
      "## Create a Free MongoDB deployment on Atlas\n",
      "\n",
      "Complete the Get Started with Atlas guide to set up a new Atlas account and load sample data into a new free tier MongoDB deployment.\n",
      "\n",
      "## Save your Credentials\n",
      "\n",
      "After you create your database user, save that user's username and password to a safe location for use in an upcoming step.\n",
      "\n",
      "After you complete these steps, you have a new free tier MongoDB deployment on Atlas, database user credentials, and sample data loaded in your database.\n",
      "\n",
      "If you run into issues on this step, ask for help in the MongoDB Community Forums or submit feedback by using the Rate this page tab on the right or bottom right side of this page.\n",
      "\n",
      "# The Atlas Search 'cene: Season 1\n",
      "\n",
      "# The Atlas Search 'cene: Season 1\n",
      "\n",
      "Welcome to the first season of a video series dedicated to Atlas Search!  This series of videos is designed to guide you through the journey from getting started and understanding the concepts, to advanced techniques.\n",
      "\n",
      "## What is Atlas Search?\n",
      "\n",
      "[Atlas Search][1] is an embedded full-text search in MongoDB Atlas that gives you a seamless, scalable experience for building relevance-based app features. Built on Apache Lucene, Atlas Search eliminates the need to run a separate search system alongside your database.\n",
      "\n",
      "By integrating the database, search engine, and sync mechanism into a single, unified, and fully managed platform, Atlas Search is the fastest and easiest way to build relevance-based search capabilities directly into applications.\n",
      "\n",
      "# About MongoDB Documentation\n",
      "\n",
      "The MongoDB Manual contains comprehensive documentation on MongoDB. This page describes the manual's licensing, editions, and versions, and describes how to make a change request and how to contribute to the manual.\n",
      "\n",
      "## License\n",
      "\n",
      "This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 3.0 United States License\n",
      "\n",
      "Â© MongoDB, Inc. 2008-2022\n",
      "\n",
      "## Man Pages\n",
      "\n",
      "In addition to the MongoDB Manual, you can access the MongoDB Man Pages, which are also distributed with the official MongoDB Packages.\n",
      "\n",
      "## Version and Revisions\n",
      "\n",
      "This version of the manual reflects version 7.0 of MongoDB.\n",
      "\n",
      "See the MongoDB Documentation Project Page for an overview of all editions and output formats of the MongoDB Manual. You can see the full revision history and track ongoing improvements and additions for all versions of the manual from its GitHub repository.\n",
      "\n",
      "> Hip to the *'cene*\n",
      "> \n",
      "> The name of this video series comes from a contraction of \"Lucene\",\n",
      "> the search engine library leveraged by Atlas. Or it's a short form of \"scene\". \n",
      "\n",
      "## Episode Guide\n",
      "\n",
      "### **[Episode 1: What is Atlas Search & Quick Start][2]**\n",
      "\n",
      "In this first episode of the Atlas Search 'cene, learn what Atlas Search is, and get a quick start introduction to setting up Atlas Search on your data.  Within a few clicks, you can set up a powerful, full-text search index on your Atlas collection data, and leverage the fast, relevant results to your users queries.\n",
      "\n",
      "### **[Episode 2: Configuration / Development Environment][3]**\n",
      "\n",
      "In order to best leverage Atlas Search, configuring it for your querying needs leads to success. In this episode, learn how Atlas Search maps your documents to its index, and discover the configuration control you have.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've saved your interests in Oracle and Java to memory! Let me get you some more comprehensive information about MongoDB that might resonate with your background.\n",
      "Tool Calls:\n",
      "  get_information_for_question_answering (toolu_bdrk_01BawcZhEDtLP5szKdnjLST2)\n",
      " Call ID: toolu_bdrk_01BawcZhEDtLP5szKdnjLST2\n",
      "  Args:\n",
      "    user_query: MongoDB database features document model Java driver\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "The important section here is the MongoDB configuration, of course. Firstly, you will notice the connection string is automatically retrieved from the `application.properties` file, and secondly, you will notice the configuration of the `MongoClient` bean.\n",
      "\n",
      "A `Codec` is the interface that abstracts the processes of decoding a BSON value into a Java object and encoding a Java object into a BSON value.\n",
      "\n",
      "A `CodecRegistry` contains a set of `Codec` instances that are accessed according to the Java classes that they encode from and decode to.\n",
      "\n",
      "The MongoDB driver is capable of encoding and decoding BSON for us, so we do not have to take care of this anymore. All the configuration we need for this project to run is here and nowhere else.\n",
      "\n",
      "You can read [the driver documentation if you want to know more about this topic.\n",
      "\n",
      "## Multi-document ACID transactions\n",
      "\n",
      "The configuration can be found in the MongoDBConfiguration.java class.\n",
      "\n",
      "```java\n",
      "package com.mongodb.starter;\n",
      "\n",
      "import ...]\n",
      "\n",
      "import static org.bson.codecs.configuration.CodecRegistries.fromProviders;\n",
      "import static org.bson.codecs.configuration.CodecRegistries.fromRegistries;\n",
      "\n",
      "@Configuration\n",
      "public class MongoDBConfiguration {\n",
      "\n",
      "    @Value(\"${spring.data.mongodb.uri}\")\n",
      "    private String connectionString;\n",
      "\n",
      "    @Bean\n",
      "    public MongoClient mongoClient() {\n",
      "        CodecRegistry pojoCodecRegistry = fromProviders(PojoCodecProvider.builder().automatic(true).build());\n",
      "        CodecRegistry codecRegistry = fromRegistries(MongoClientSettings.getDefaultCodecRegistry(), pojoCodecRegistry);\n",
      "        return MongoClients.create(MongoClientSettings.builder()\n",
      "                                                      .applyConnectionString(new ConnectionString(connectionString))\n",
      "                                                      .codecRegistry(codecRegistry)\n",
      "                                                      .build());\n",
      "    }\n",
      "\n",
      "}\n",
      "```\n",
      "\n",
      "Just for the sake of it, I also used multi-document ACID transactions in a few methods where it could potentially make sense to use ACID transactions. You can check all the code in the `MongoDBPersonRepository` class.\n",
      "\n",
      "Here is an example:\n",
      "\n",
      "```java\n",
      "private static final TransactionOptions txnOptions = TransactionOptions.builder()\n",
      "    .readPreference(ReadPreference.primary())\n",
      "    .readConcern(ReadConcern.MAJORITY)\n",
      "    .writeConcern(WriteConcern.MAJORITY)\n",
      "    .build();\n",
      "\n",
      "@Override\n",
      "public List saveAll(List personEntities) {\n",
      "    try (ClientSession clientSession = client.startSession()) {\n",
      "        return clientSession.withTransaction(() -> {\n",
      "            personEntities.forEach(p -> p.setId(new ObjectId()));\n",
      "            personCollection.insertMany(clientSession, personEntities);\n",
      "            return personEntities;\n",
      "        }, txnOptions);\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "```java\n",
      "@Override\n",
      "public double getAverageAge() {\n",
      "    List pipeline = List.of(group(new BsonNull(), avg(\"averageAge\", \"$age\")), project(excludeId()));\n",
      "    return personCollection.aggregate(pipeline, AverageAgeDTO.class).first().averageAge();\n",
      "}\n",
      "```\n",
      "\n",
      "Also, you can note here that Iâ€™m using the `personCollection` which was initially instantiated like this:\n",
      "\n",
      "```java\n",
      "private MongoCollection personCollection;\n",
      "\n",
      "@PostConstruct\n",
      "void init() {\n",
      "    personCollection = client.getDatabase(\"test\").getCollection(\"persons\", PersonEntity.class);\n",
      "}\n",
      "```\n",
      "\n",
      "Normally, my personCollection should encode and decode `PersonEntity` object only, but you can overwrite the type of object your collection is manipulating to return something different â€” in my case, `AverageAgeDTO.class` as Iâ€™m not expecting a `PersonEntity` class here but a POJO that contains only the average age of my \"persons\".\n",
      "\n",
      "## Swagger\n",
      "\n",
      "If you are new to MongoDB Atlas, give our Quick Start post a try to get up to speed with MongoDB Atlas in no time.\n",
      "\n",
      "  [1]: https://images.contentstack.io/v3/assets/blt39790b633ee0d5a7/blt876f3404c57aa244/65388189377588ba166497b0/swaggerui.png\n",
      "  [2]: https://images.contentstack.io/v3/assets/blt39790b633ee0d5a7/bltf2f06ba5af19464d/65388188d31953242b0dbc6f/nyancat.png\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Perfect! Now let me give you a comprehensive overview of MongoDB, especially highlighting aspects that will resonate with your Oracle and Java background:\n",
      "\n",
      "## **What is MongoDB?**\n",
      "\n",
      "MongoDB is a **document-oriented NoSQL database** that stores data in flexible, JSON-like documents (BSON format) rather than traditional table-based relational structures you'd find in Oracle. It's designed for scalability, high performance, and developer productivity.\n",
      "\n",
      "## **Key Differences from Oracle:**\n",
      "\n",
      "- **Schema Flexibility**: Unlike Oracle's rigid table schemas, MongoDB uses a flexible document model where each document can have different fields\n",
      "- **Document Model**: Data is stored as documents (similar to JSON objects) rather than rows in tables\n",
      "- **Horizontal Scaling**: Built-in sharding for distributed data across multiple servers\n",
      "- **No SQL**: Uses a rich query language but not traditional SQL (though there are SQL-like interfaces available)\n",
      "\n",
      "## **MongoDB + Java Integration:**\n",
      "\n",
      "Since you're into Java programming, you'll be pleased to know MongoDB has **excellent Java support**:\n",
      "\n",
      "1. **MongoDB Java Driver**: Official driver that handles encoding/decoding between Java objects and BSON\n",
      "   - Uses `Codec` and `CodecRegistry` for automatic Java-BSON conversion\n",
      "   - No manual serialization needed!\n",
      "\n",
      "2. **Spring Data MongoDB**: Seamless integration with Spring framework\n",
      "   - Easy configuration via `application.properties`\n",
      "   - `MongoClient` bean configuration\n",
      "   - Repository pattern support\n",
      "\n",
      "3. **ACID Transactions**: MongoDB supports multi-document ACID transactions (similar to Oracle), with configurable:\n",
      "   - Read/Write concerns\n",
      "   - Transaction options\n",
      "   - Session management\n",
      "\n",
      "## **Key Features:**\n",
      "\n",
      "- **Atlas Search**: Built-in full-text search powered by Apache Lucene\n",
      "- **Cloud-Native**: MongoDB Atlas provides fully managed cloud deployments\n",
      "- **Aggregation Pipeline**: Powerful data processing framework\n",
      "- **High Availability**: Built-in replication and automatic failover\n",
      "\n",
      "Would you like me to dive deeper into any specific aspect, such as Java driver usage, migration considerations from Oracle, or specific MongoDB features?\n"
     ]
    }
   ],
   "source": [
    "run_agent_with_memory(\n",
    "    thread_id=\"session-108\",\n",
    "    user_id=\"user-456\",  # DIFFERENT user\n",
    "    user_input=\"I like Oracle related stuff and Java Programming, tell me about MongoDB \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ALL STORED MEMORIES IN MONGODB\n",
      "============================================================\n",
      "\n",
      "Total memories: 3\n",
      "\n",
      "--- Memory 1 ---\n",
      "Namespace: ['memories', 'user-104']\n",
      "Key: 9d811dbe-e2af-42c9-8732-8ab6ee7ce103\n",
      "Content: User is a senior DBA (Database Administrator) with a focus on disaster recovery and backup strategies\n",
      "\n",
      "--- Memory 2 ---\n",
      "Namespace: ['memories', 'user-456']\n",
      "Key: 7c5be609-c32c-44b5-909e-eb4339fb4728\n",
      "Content: User is a cloud architect with interest in MongoDB Atlas scaling\n",
      "\n",
      "--- Memory 3 ---\n",
      "Namespace: ['memories', 'user-456']\n",
      "Key: eddfd6b8-09b7-4b52-aa29-abb7cb21c540\n",
      "Content: User is interested in Oracle-related technologies and Java programming\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VIEW ALL STORED MEMORIES\n",
    "# =============================================================================\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ALL STORED MEMORIES IN MONGODB\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_memories = list(memory_collection.find({}))\n",
    "print(f\"\\nTotal memories: {len(all_memories)}\\n\")\n",
    "\n",
    "for i, doc in enumerate(all_memories, 1):\n",
    "    print(f\"--- Memory {i} ---\")\n",
    "    print(f\"Namespace: {doc.get('namespace', 'N/A')}\")\n",
    "    print(f\"Key: {doc.get('key', 'N/A')}\")\n",
    "    value = doc.get('value', {})\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"Content: {value.get('content', value)}\")\n",
    "    else:\n",
    "        print(f\"Value: {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run_agent_with_memory(\\n    thread_id=\"session-110000\",\\n    user_id=\"user-456\",  # DIFFERENT user\\n    user_input=\"Tell me about MongoDB backups based on my programming language expertise\"\\n)'"
      ]
     },
     "execution_count": 1277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''run_agent_with_memory(\n",
    "    thread_id=\"session-110000\",\n",
    "    user_id=\"user-456\",  # DIFFERENT user\n",
    "    user_input=\"Tell me about MongoDB backups based on my programming language expertise\"\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x= mongodb_client[\"checkpointing_db\"][\"checkpoints\"].drop()\n",
    "#x= mongodb_client[\"mongodb_genai_devday_agents\"][\"memories\"].drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmem import create_memory_store_manager\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1280,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLD_PATH_INSTRUCTIONS = \"\"\"You are a memory consolidation system. Your job is to MERGE and CLEAN UP memories.\n",
    "\n",
    "STRICT RULES:\n",
    "1. MAXIMUM 1 memory per user - never more\n",
    "2. You MUST DELETE all old memories after merging them\n",
    "3. Create ONE new consolidated memory with ALL information\n",
    "\n",
    "REQUIRED ACTIONS:\n",
    "1. READ all existing memories\n",
    "2. MERGE all information into ONE comprehensive memory  \n",
    "3. DELETE every old memory (use the delete/remove function)\n",
    "4. SAVE the single merged memory\n",
    "\n",
    "FORMAT for the single memory:\n",
    "\"User Profile: [role] at [company]. Works with [technologies]. Preferences: [preferences]. Interests: [interests].\"\n",
    "\n",
    "CRITICAL: If you see 3 existing memories, your output should be:\n",
    "- DELETE mem-001\n",
    "- DELETE mem-002  \n",
    "- DELETE mem-003\n",
    "- CREATE one consolidated memory\n",
    "\n",
    "DO NOT just add a new memory. You MUST delete the old ones.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… CORRECT - create_memory_store_manager has full storage integration\n",
    "memory_store_manager = create_memory_store_manager(\n",
    "    llm,\n",
    "    namespace=(\"memories\", \"{langgraph_user_id}\"),  # âœ… Valid\n",
    "    store=memory_store,                              # âœ… Valid\n",
    "    instructions=COLD_PATH_INSTRUCTIONS,\n",
    "    enable_inserts=True,\n",
    "    enable_deletes=True,\n",
    "    query_model=llm,\n",
    "    query_limit=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "_current_conversation_messages = []\n",
    "_current_user_id = None\n",
    "\n",
    "@tool\n",
    "def queue_memory_consolidation(reason: str = \"conversation_ended\") -> str:\n",
    "    \"\"\"\n",
    "    Consolidate memories for the current user.\n",
    "    Call this tool when the user says goodbye.\n",
    "    \"\"\"\n",
    "    global _current_conversation_messages, _current_user_id\n",
    "    \n",
    "    if not _current_conversation_messages:\n",
    "        return \"No conversation messages to consolidate.\"\n",
    "    \n",
    "    if not _current_user_id:\n",
    "        return \"No user ID available for consolidation.\"\n",
    "    \n",
    "    config = {\"configurable\": {\"langgraph_user_id\": _current_user_id}}\n",
    "    \n",
    "    try:\n",
    "        # Synchronous call - no executor needed\n",
    "        result = memory_store_manager.invoke(\n",
    "            {\n",
    "                \"messages\": _current_conversation_messages,\n",
    "                \"max_steps\": 3\n",
    "            },\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        print(f\"ðŸ“ Consolidation complete for user: {_current_user_id}\")\n",
    "        print(f\"   Memories created/updated: {len(result)}\")\n",
    "        for r in result:\n",
    "            print(f\"   - {r['value']}\")\n",
    "        \n",
    "        return f\"Memory consolidation complete. Updated {len(result)} memories.\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Consolidation failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return f\"Failed: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tools updated. Total: 5\n",
      "   - get_information_for_question_answering\n",
      "   - get_page_content_for_summarization\n",
      "   - manage_memory\n",
      "   - search_memory\n",
      "   - queue_memory_consolidation\n"
     ]
    }
   ],
   "source": [
    "# ADD THE TOOL TO THE LIST - THIS WAS MISSING!\n",
    "tools = tools + [queue_memory_consolidation]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "print(f\"âœ… Tools updated. Total: {len(tools)}\")\n",
    "for t in tools:\n",
    "    print(f\"   - {t.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_aware_prompt_with_goodbye = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a helpful AI assistant with persistent memory capabilities.\n",
    "You can answer questions about MongoDB documentation using your tools.\n",
    "\n",
    "IMPORTANT MEMORY INSTRUCTIONS:\n",
    "1. When a user shares personal information (their role, expertise, preferences, interests),\n",
    "   ALWAYS use the manage_memory tool to save it immediately.\n",
    "2. At the start of conversations, use search_memory to check for relevant user context.\n",
    "3. Tailor your responses based on what you remember about the user.\n",
    "\n",
    "GOODBYE INSTRUCTION:\n",
    "When the user says goodbye, ends the conversation, or uses phrases like:\n",
    "- \"bye\", \"goodbye\", \"see you\", \"thanks bye\", \"that's all\", \"gotta go\", \"talk later\"\n",
    "Call the queue_memory_consolidation tool to consolidate their memories, then say a friendly goodbye.\n",
    "\n",
    "CRITICAL: Use only the information provided by tools to respond to user questions.\n",
    "\n",
    "## Tool Usage Guidelines\n",
    "- Do NOT call the same retrieval tool more than 2 times for a single user question\n",
    "- If consecutive searches return similar content, stop searching and synthesize what you have\n",
    "\n",
    "Available tools: {tool_names}\"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1285,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_aware_prompt_with_goodbye = memory_aware_prompt_with_goodbye.partial(\n",
    "    tool_names=\", \".join([tool.name for tool in tools])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Graph recompiled with LangMem cold path support\n"
     ]
    }
   ],
   "source": [
    "llm_with_tools = memory_aware_prompt_with_goodbye | llm.bind_tools(tools)\n",
    "\n",
    "# Recompile the graph\n",
    "app_with_memory = graph.compile(\n",
    "    checkpointer=checkpointer,\n",
    "    store=memory_store\n",
    ")\n",
    "\n",
    "print(\"âœ… Graph recompiled with LangMem cold path support\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent wrapper updated with cold path tracking\n"
     ]
    }
   ],
   "source": [
    "def run_agent_with_memory_and_coldpath(\n",
    "    thread_id: str,\n",
    "    user_id: str,\n",
    "    user_input: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Run the agent with memory support and cold path tracking.\n",
    "    \n",
    "    This wrapper:\n",
    "    1. Tracks conversation messages for cold path consolidation\n",
    "    2. Passes user_id for proper namespace scoping\n",
    "    3. Streams and displays the response\n",
    "    \"\"\"\n",
    "    global _current_conversation_messages, _current_user_id\n",
    "    \n",
    "    # Set current user for consolidation tool\n",
    "    _current_user_id = user_id\n",
    "    \n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id,\n",
    "            \"langgraph_user_id\": user_id\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    input_message = HumanMessage(content=user_input)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ðŸ§µ Thread: {thread_id}\")\n",
    "    print(f\"ðŸ‘¤ User: {user_id}\")\n",
    "    print(f\"ðŸ’¬ Input: {user_input}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Stream the response\n",
    "    final_response = None\n",
    "    for chunk in app_with_memory.stream(\n",
    "        {\"messages\": [input_message]},\n",
    "        config=config,\n",
    "        stream_mode=\"values\"\n",
    "    ):\n",
    "        if \"messages\" in chunk:\n",
    "            final_response = chunk[\"messages\"][-1]\n",
    "            # Track messages for cold path\n",
    "            _current_conversation_messages = chunk[\"messages\"]\n",
    "    \n",
    "    if final_response:\n",
    "        print(f\"\\nðŸ¤– Assistant: {final_response.content}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\\n\")\n",
    "\n",
    "\n",
    "print(\"âœ… Agent wrapper updated with cold path tracking\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Creating some memories...\n",
      "\n",
      "============================================================\n",
      "ðŸ§µ Thread: session-coldpath-test_1\n",
      "ðŸ‘¤ User: user-coldpath-dem\n",
      "ðŸ’¬ Input: Hi! I'm a senior data engineer at a fintech startup. I work mostly with MongoDB and Kafka.\n",
      "============================================================\n",
      "\n",
      "\n",
      "ðŸ¤– Assistant: Hello! Great to meet you! As a senior data engineer working with MongoDB and Kafka at a fintech startup, you're dealing with some powerful technologies for handling real-time data pipelines and scalable data storage.\n",
      "\n",
      "I'm here to help you with any MongoDB-related questions you might have - whether it's about:\n",
      "- Performance optimization and indexing strategies\n",
      "- Data modeling for financial data\n",
      "- Aggregation pipelines\n",
      "- Replication and sharding\n",
      "- Integration patterns with Kafka\n",
      "- Security and compliance features\n",
      "- Or anything else MongoDB-related!\n",
      "\n",
      "What can I help you with today?\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: TEST - Create some memories first\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 1: Creating some memories...\")\n",
    "\n",
    "run_agent_with_memory_and_coldpath(\n",
    "    thread_id=\"session-coldpath-test_1\",\n",
    "    user_id=\"user-coldpath-dem\",\n",
    "    user_input=\"Hi! I'm a senior data engineer at a fintech startup. I work mostly with MongoDB and Kafka.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Adding more context...\n",
      "\n",
      "============================================================\n",
      "ðŸ§µ Thread: session-coldpath-test_1\n",
      "ðŸ‘¤ User: user-coldpath-dem\n",
      "ðŸ’¬ Input: I'm particularly interested in performance optimization and I prefer detailed technical explanations with code examples.\n",
      "============================================================\n",
      "\n",
      "\n",
      "ðŸ¤– Assistant: Perfect! I've noted that you're focused on performance optimization and prefer detailed technical explanations with code examples. That's exactly the kind of depth that's valuable for a senior data engineer working in fintech where performance and efficiency are critical.\n",
      "\n",
      "I can help you dive deep into topics like:\n",
      "\n",
      "- **Indexing strategies**: Compound indexes, covered queries, index intersection, ESR rule\n",
      "- **Query optimization**: Using explain plans, query shapes, index selectivity\n",
      "- **Aggregation pipeline optimization**: Pipeline stages ordering, $match/$project early, memory limits\n",
      "- **Schema design patterns**: Embedding vs referencing, bucketing patterns, computed patterns\n",
      "- **Connection pooling and driver settings**: For high-throughput scenarios\n",
      "- **Read/write concerns**: Balancing consistency and performance\n",
      "- **Sharding strategies**: Choosing shard keys for even distribution and query isolation\n",
      "\n",
      "What specific performance optimization challenge are you working on, or what area would you like to explore first?\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: TEST - Add more context\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 2: Adding more context...\")\n",
    "\n",
    "run_agent_with_memory_and_coldpath(\n",
    "    thread_id=\"session-coldpath-test_1\",\n",
    "    user_id=\"user-coldpath-dem\",\n",
    "    user_input=\"I'm particularly interested in performance optimization and I prefer detailed technical explanations with code examples.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for background consolidation to complete...\n",
      "\n",
      "ðŸ“‹ User memories after consolidation:\n",
      "==================================================\n",
      "\n",
      "--- Memory 1 ---\n",
      "Key: 27175401-5b74-4124-90b2-cae816447619\n",
      "Value: {'content': 'User is a senior data engineer at a fintech startup'}\n",
      "Score: 0.680\n",
      "\n",
      "--- Memory 2 ---\n",
      "Key: cca3f50b-8bad-444c-8bfe-9071e8b10640\n",
      "Value: {'content': 'User works primarily with MongoDB and Kafka'}\n",
      "Score: 0.677\n",
      "\n",
      "--- Memory 3 ---\n",
      "Key: 4f38e350-da7e-4b95-901f-d05c3d421546\n",
      "Value: {'content': 'User prefers detailed technical explanations with code examples'}\n",
      "Score: 0.663\n",
      "\n",
      "--- Memory 4 ---\n",
      "Key: e29b8dc5-77cf-41a2-a581-e84a79e7ac20\n",
      "Value: {'content': 'User is particularly interested in MongoDB performance optimization'}\n",
      "Score: 0.634\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: VERIFY - Check memories after consolidation\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "print(\"Waiting for background consolidation to complete...\")\n",
    "time.sleep(5)  # Give executor time to process\n",
    "\n",
    "# Check what's in the memory store for this user\n",
    "print(\"\\nðŸ“‹ User memories after consolidation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "namespace = (\"memories\", \"user-coldpath-dem\")\n",
    "\n",
    "# Search for all memories\n",
    "try:\n",
    "    results = list(memory_store.search(namespace, query=\"user profile expertise\", limit=10))\n",
    "    \n",
    "    if results:\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"\\n--- Memory {i} ---\")\n",
    "            print(f\"Key: {result.key}\")\n",
    "            print(f\"Value: {result.value}\")\n",
    "            if hasattr(result, 'score'):\n",
    "                print(f\"Score: {result.score:.3f}\")\n",
    "    else:\n",
    "        print(\"No memories found via search. Checking raw collection...\")\n",
    "        \n",
    "        # Fallback: check MongoDB directly\n",
    "        raw_memories = list(memory_collection.find({\"namespace\": list(namespace)}))\n",
    "        print(f\"Found {len(raw_memories)} memories in MongoDB:\")\n",
    "        for mem in raw_memories[:5]:\n",
    "            print(f\"  - {mem.get('key')}: {str(mem.get('value', {}))[:100]}...\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error searching memories: {e}\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Triggering cold path consolidation...\n",
      "\n",
      "============================================================\n",
      "ðŸ§µ Thread: session-coldpath-test_1\n",
      "ðŸ‘¤ User: user-coldpath-dem\n",
      "ðŸ’¬ Input: Thanks for your help! Goodbye!\n",
      "============================================================\n",
      "\n",
      "âŒ Consolidation failed: 'kind'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1372/1679946423.py\", line 23, in queue_memory_consolidation\n",
      "    result = memory_store_manager.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/langmem/knowledge/extraction.py\", line 1209, in invoke\n",
      "    store_based = [\n",
      "                  ^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/langmem/knowledge/extraction.py\", line 1210, in <listcomp>\n",
      "    (sid, item.value[\"kind\"], item.value[\"content\"])\n",
      "          ~~~~~~~~~~^^^^^^^^\n",
      "KeyError: 'kind'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– Assistant: Goodbye! It was great meeting you. Feel free to come back anytime you have MongoDB performance questions or need help with technical challenges in your fintech data engineering work. Good luck with your projects! ðŸ‘‹\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 10: TEST - Say goodbye to trigger consolidation\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 3: Triggering cold path consolidation...\")\n",
    "\n",
    "run_agent_with_memory_and_coldpath(\n",
    "    thread_id=\"session-coldpath-test_1\",\n",
    "    user_id=\"user-coldpath-dem\",\n",
    "    user_input=\"Thanks for your help! Goodbye!\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for background consolidation to complete...\n",
      "\n",
      "ðŸ“‹ User memories after consolidation:\n",
      "==================================================\n",
      "\n",
      "--- Memory 1 ---\n",
      "Key: 27175401-5b74-4124-90b2-cae816447619\n",
      "Value: {'content': 'User is a senior data engineer at a fintech startup'}\n",
      "Score: 0.680\n",
      "\n",
      "--- Memory 2 ---\n",
      "Key: cca3f50b-8bad-444c-8bfe-9071e8b10640\n",
      "Value: {'content': 'User works primarily with MongoDB and Kafka'}\n",
      "Score: 0.677\n",
      "\n",
      "--- Memory 3 ---\n",
      "Key: 4f38e350-da7e-4b95-901f-d05c3d421546\n",
      "Value: {'content': 'User prefers detailed technical explanations with code examples'}\n",
      "Score: 0.663\n",
      "\n",
      "--- Memory 4 ---\n",
      "Key: e29b8dc5-77cf-41a2-a581-e84a79e7ac20\n",
      "Value: {'content': 'User is particularly interested in MongoDB performance optimization'}\n",
      "Score: 0.634\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: VERIFY - Check memories after consolidation\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "print(\"Waiting for background consolidation to complete...\")\n",
    "time.sleep(5)  # Give executor time to process\n",
    "\n",
    "# Check what's in the memory store for this user\n",
    "print(\"\\nðŸ“‹ User memories after consolidation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "namespace = (\"memories\", \"user-coldpath-dem\")\n",
    "\n",
    "# Search for all memories\n",
    "try:\n",
    "    results = list(memory_store.search(namespace, query=\"user profile expertise\", limit=10))\n",
    "    \n",
    "    if results:\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"\\n--- Memory {i} ---\")\n",
    "            print(f\"Key: {result.key}\")\n",
    "            print(f\"Value: {result.value}\")\n",
    "            if hasattr(result, 'score'):\n",
    "                print(f\"Score: {result.score:.3f}\")\n",
    "    else:\n",
    "        print(\"No memories found via search. Checking raw collection...\")\n",
    "        \n",
    "        # Fallback: check MongoDB directly\n",
    "        raw_memories = list(memory_collection.find({\"namespace\": list(namespace)}))\n",
    "        print(f\"Found {len(raw_memories)} memories in MongoDB:\")\n",
    "        for mem in raw_memories[:5]:\n",
    "            print(f\"  - {mem.get('key')}: {str(mem.get('value', {}))[:100]}...\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error searching memories: {e}\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: memory_vector_index - Status: READY\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#time.sleep(90)  # Wait for index build\n",
    "\n",
    "indexes = list(memory_collection.list_search_indexes())\n",
    "for idx in indexes:\n",
    "    print(f\"Index: {idx.get('name')} - Status: {idx.get('status', 'building...')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Step 1: First conversation - creates initial memories\\nprint(\"Step 1: Initial extraction...\")\\nmessages_1 = [\\n    HumanMessage(content=\"I\\'m a Python developer who loves MongoDB\"),\\n    AIMessage(content=\"Great!\")\\n]\\nconfig = {\"configurable\": {\"langgraph_user_id\": \"consolidation-test-user\"}}\\n\\nresult_1 = memory_store_manager.invoke({\"messages\": messages_1, \"max_steps\": 1}, config=config)\\nprint(f\"Created {len(result_1)} memories\")\\nfor r in result_1:\\n    print(f\"  - {r[\\'value\\']}\")'"
      ]
     },
     "execution_count": 1295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Step 1: First conversation - creates initial memories\n",
    "print(\"Step 1: Initial extraction...\")\n",
    "messages_1 = [\n",
    "    HumanMessage(content=\"I'm a Python developer who loves MongoDB\"),\n",
    "    AIMessage(content=\"Great!\")\n",
    "]\n",
    "config = {\"configurable\": {\"langgraph_user_id\": \"consolidation-test-user\"}}\n",
    "\n",
    "result_1 = memory_store_manager.invoke({\"messages\": messages_1, \"max_steps\": 1}, config=config)\n",
    "print(f\"Created {len(result_1)} memories\")\n",
    "for r in result_1:\n",
    "    print(f\"  - {r['value']}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Step 2: Second conversation - should consolidate with existing\\nprint(\"\\nStep 2: Adding more info (should consolidate)...\")\\nmessages_2 = [\\n    HumanMessage(content=\"I also work with PostgreSQL and I\\'m a senior engineer\"),\\n    AIMessage(content=\"Got it!\")\\n]\\n\\nresult_2 = memory_store_manager.invoke({\"messages\": messages_2, \"max_steps\": 1}, config=config)\\nprint(f\"Result: {len(result_2)} memories\")\\nfor r in result_2:\\n    print(f\"  - {r[\\'value\\']}\")'"
      ]
     },
     "execution_count": 1296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Step 2: Second conversation - should consolidate with existing\n",
    "print(\"\\nStep 2: Adding more info (should consolidate)...\")\n",
    "messages_2 = [\n",
    "    HumanMessage(content=\"I also work with PostgreSQL and I'm a senior engineer\"),\n",
    "    AIMessage(content=\"Got it!\")\n",
    "]\n",
    "\n",
    "result_2 = memory_store_manager.invoke({\"messages\": messages_2, \"max_steps\": 1}, config=config)\n",
    "print(f\"Result: {len(result_2)} memories\")\n",
    "for r in result_2:\n",
    "    print(f\"  - {r['value']}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Step 3: Check final state in MongoDB\\nprint(\"\\nStep 3: Final memories in MongoDB...\")\\nnamespace = [\"memories\", \"consolidation-test-user\"]\\ndocs = list(memory_collection.find({\"namespace\": namespace}))\\nprint(f\"Total: {len(docs)} memories\")\\nfor doc in docs:\\n    print(f\"  - {doc.get(\\'value\\', {})}\")'"
      ]
     },
     "execution_count": 1297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Step 3: Check final state in MongoDB\n",
    "print(\"\\nStep 3: Final memories in MongoDB...\")\n",
    "namespace = [\"memories\", \"consolidation-test-user\"]\n",
    "docs = list(memory_collection.find({\"namespace\": namespace}))\n",
    "print(f\"Total: {len(docs)} memories\")\n",
    "for doc in docs:\n",
    "    print(f\"  - {doc.get('value', {})}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'langmem' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1298], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlangmem\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlangmem: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mlangmem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanggraph: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanggraph\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'langmem' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import langmem\n",
    "import langgraph\n",
    "print(f\"langmem: {langmem.__version__}\")\n",
    "print(f\"langgraph: {langgraph.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langmem: 0.0.30\n",
      "langgraph: 1.0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1372/207404697.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "print(f\"langmem: {pkg_resources.get_distribution('langmem').version}\")\n",
    "print(f\"langgraph: {pkg_resources.get_distribution('langgraph').version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {}
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
